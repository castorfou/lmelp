{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>Here is the <code>README.md</code> of this project</p> <ul> <li>pour developper \ud83d\udcbb</li> <li>environnements de dev python \ud83d\udc0d</li> <li>pre-commit \u23f1\ufe0f</li> <li>config vscode \ud83d\udda5\ufe0f</li> <li>tests unitaires \ud83e\uddea</li> <li>\ud83d\ude00 \u00e0 propos de la doc</li> <li>pour utiliser \ud83d\ude80</li> <li>\ud83d\udcbe base de donn\u00e9es mongodb</li> <li>ffmpeg \ud83c\udf9e\ufe0f</li> <li>locale FR \ud83c\uddeb\ud83c\uddf7</li> <li>ulimit \u2699\ufe0f</li> <li><code>.env</code> \ud83c\udf10<ul> <li>rss info \ud83c\udf99\ufe0f</li> <li>web info \ud83c\udf0d</li> <li>db info \ud83d\uddc4\ufe0f</li> <li>llm, llamaindex, litellm \ud83e\udd16</li> <li>websearch</li> </ul> </li> <li>streamlit \ud83d\uddb1\ufe0f</li> </ul>"},{"location":"#pour-developper","title":"pour developper \ud83d\udcbb","text":""},{"location":"#environnements-de-dev-python","title":"environnements de dev python \ud83d\udc0d","text":"<p>vscode utilisera automatiquement le devcontainer definit dans le repo sous <code>.devcontainer</code></p> <p>je garde quand meme le script de creation d'environnement whisper depuis <code>envs/whisper.txt</code> \u2728  qui contient ce qu il faut pour whisper, feedparser, transformers (huggingface), dotenv, mongo, streamlit \ud83d\udee0\ufe0f</p>"},{"location":"#pre-commit","title":"pre-commit \u23f1\ufe0f","text":"<p>dans devcontainer, pre-commit est deja configure sinon</p> <p><code>pre-commit install</code> \u2705</p>"},{"location":"#config-vscode","title":"config vscode \ud83d\udda5\ufe0f","text":"<p>en cas de message <code>\"Visual Studio Code is unable to watch for file changes in this large workspace\" (error ENOSPC)</code> see vscode linux page \u26a0\ufe0f</p> <pre><code># add fs.inotify.max_user_watches=524288 to /etc/sysctl.d/99-custom-inotify.conf\nsudo sysctl -p # to apply directly\ncat /proc/sys/fs/inotify/max_user_watches # to control it is applied\n</code></pre> <p>or add <code>files.watcherExclude</code> directive in <code>.vscode/settings.json</code> \ud83d\udcc1</p> <p>pour quelques astuces li\u00e9es \u00e0 vscode : Vscode hints (sur github pages)</p>"},{"location":"#tests-unitaires","title":"tests unitaires \ud83e\uddea","text":"<p>Le projet utilise pytest pour les tests unitaires avec une couverture de code \u00e9lev\u00e9e.</p> <p>Infrastructure CI/CD : - \u2705 GitHub Actions : Tests automatiques sur chaque push/PR - \u2705 D\u00e9pendances optimis\u00e9es : <code>tests/requirements.txt</code> (sans PyTorch/ML) - \u2705 Mocking avanc\u00e9 : torch, transformers, dbus mock\u00e9s pour CI/CD - \u2705 Coverage 72%+ : Couverture actuelle avec 214 tests - \u2705 Linting automatique : flake8, black, isort</p> <pre><code># Lancer tous les tests\npytest\n\n# Tests avec couverture \npytest --cov=nbs --cov-report=term-missing\n\n# Tests sp\u00e9cifiques\npytest tests/unit/test_config.py -v\n</code></pre> <p>Structure des tests : - <code>tests/unit/</code> : Tests unitaires par module - <code>tests/fixtures/</code> : Donn\u00e9es de test et utilitaires - <code>tests/requirements.txt</code> : D\u00e9pendances minimales pour tests - <code>tests/conftest.py</code> : Configuration et fixtures globales - <code>.env.test</code> : Variables d'environnement de test - <code>.github/workflows/tests.yml</code> : CI/CD GitHub Actions</p> <p>Documentation compl\u00e8te : Guide des tests unitaires \ud83d\udccb</p>"},{"location":"#a-propos-de-la-doc","title":"\ud83d\ude00 \u00e0 propos de la doc","text":"<p>on change la doc depuis <code>docs</code> (g\u00e9nie) \ud83d\ude0a</p> <ul> <li>APIs \ud83d\ude80</li> <li>Quelques astuces ou choix de conception \ud83d\udd0d</li> </ul> <p>Mkdocs+github actions ramasse tout cela (branche main uniquement) et publie sur le github pages du projet \ud83d\udce6</p> <p>Expliqu\u00e9 \u00e0 https://castorfou.github.io/lmelp/readme_doc/ \ud83d\udc4d</p>"},{"location":"#pour-utiliser","title":"pour utiliser \ud83d\ude80","text":""},{"location":"#deploiement-docker","title":"\ud83d\udc33 D\u00e9ploiement Docker","text":"<p>lmelp peut \u00eatre d\u00e9ploy\u00e9 sous forme de conteneur Docker sur PC local ou NAS Synology.</p>"},{"location":"#quick-start-pc-local","title":"Quick Start - PC Local","text":"<pre><code>cd docker/deployment/\ncp .env.template .env\n# \u00c9diter .env avec vos cl\u00e9s API (au moins une requise)\ndocker compose up -d\n</code></pre> <p>Acc\u00e9der \u00e0 l'application : http://localhost:8501 \ud83c\udf10</p> <p>Pr\u00e9requis : - Docker et Docker Compose install\u00e9s - MongoDB existant (localhost ou autre conteneur) - 4 GB RAM minimum (8 GB recommand\u00e9) - Configurer <code>DB_HOST</code> dans <code>.env</code> selon votre environnement :   - Linux: <code>DB_HOST=172.17.0.1</code> (gateway Docker)   - Mac/Windows: <code>DB_HOST=host.docker.internal</code>   - NAS: <code>DB_HOST=nom_conteneur_mongodb</code></p>"},{"location":"#images-docker","title":"Images Docker","text":"<p>Images publi\u00e9es automatiquement sur GitHub Container Registry :</p> <ul> <li><code>ghcr.io/castorfou/lmelp:latest</code> - Derni\u00e8re version stable</li> <li><code>ghcr.io/castorfou/lmelp:v1.0.0</code> - Versions sp\u00e9cifiques</li> </ul> <p></p>"},{"location":"#commandes-docker","title":"Commandes Docker","text":"<pre><code>cd docker/deployment/\n\n# D\u00e9marrer\ndocker compose up -d\n\n# Arr\u00eater\ndocker compose down\n\n# Mettre \u00e0 jour\ndocker compose pull &amp;&amp; docker compose up -d\n\n# Voir les logs\ndocker compose logs -f\n</code></pre>"},{"location":"#mode-batch-scripts","title":"Mode Batch (Scripts)","text":"<p>Ex\u00e9cuter les scripts de traitement en mode batch :</p> <pre><code># Mise \u00e0 jour RSS\ndocker run --rm --network lmelp-network \\\n  -e DB_HOST=mongodb -e LMELP_MODE=batch-update \\\n  ghcr.io/castorfou/lmelp:latest\n\n# Transcription d'un \u00e9pisode\ndocker run --rm --network lmelp-network \\\n  -v lmelp-audios:/app/audios \\\n  -e DB_HOST=mongodb -e LMELP_MODE=batch-transcribe \\\n  -e EPISODE_ID=20240120 -e GEMINI_API_KEY=$GEMINI_API_KEY \\\n  ghcr.io/castorfou/lmelp:latest\n</code></pre>"},{"location":"#documentation-complete","title":"Documentation Compl\u00e8te","text":"<ul> <li>\ud83d\udcd6 Guide de d\u00e9ploiement Docker - Quick start, configuration, usage avec Portainer</li> <li>\ud83d\udd27 Configuration GitHub Actions - CI/CD automatique</li> <li>\ud83d\udcdd Issue #64 - Plan complet - Sp\u00e9cifications d\u00e9taill\u00e9es</li> </ul>"},{"location":"#specifications-techniques","title":"Sp\u00e9cifications Techniques","text":"<ul> <li>Base : Python 3.11 + uv</li> <li>Taille : ~2.5-3 GB (avec mod\u00e8les ML)</li> <li>Ressources : 4 GB RAM, 2 CPU cores</li> <li>Volumes : audios (50-100 GB), db-backup, logs</li> <li>Healthchecks : Automatiques toutes les 30s</li> </ul>"},{"location":"#base-de-donnees-mongodb","title":"\ud83d\udcbe base de donn\u00e9es mongodb","text":"<p>mongodb est utilis\u00e9e pour conserver toutes les donn\u00e9es de l'application (voir sch\u00e9ma). \ud83d\udcca pour conserver une sauvegarde de la base, lancer depuis devcontainer <code>scripts/backup_mongodb.sh</code> \ud83d\ude80</p> <p>si les liens ont \u00e9t\u00e9 faits dans <code>~/bin/lmelp</code>, alors lancer depuis host <code>~/bin/lmelp/backup_mongodb.sh</code></p> <p>penser \u00e0 le faire r\u00e9guili\u00e9rement, il n'y a aucun rappel.</p>"},{"location":"#ffmpeg","title":"ffmpeg \ud83c\udf9e\ufe0f","text":"<p>ffmpeg is required to load audio files from filename for whisper use (transcription d'un mp3) \ud83c\udfa7</p> <p>install, it is available in snap (4.3.1) \ud83d\udce6</p>"},{"location":"#locale-fr","title":"locale FR \ud83c\uddeb\ud83c\uddf7","text":"<p>en cas d'erreur de type <code>locale.Error: unsupported locale setting</code> \u2757</p> <p>verifier avec <code>locale -a</code> que <code>fr_FR.UTF-8</code> soit install\u00e9e. \ud83d\udd0d</p> <p>Sinon le faire avec </p> <pre><code>sudo apt-get install language-pack-fr-base\nlocale -a\n</code></pre>"},{"location":"#ulimit","title":"ulimit \u2699\ufe0f","text":"<p>j'ai du augmenter l'ulimit de mon systeme pour utiliser whisper pour eviter l'erreur <code>Too many open files</code> \ud83d\udeab</p> <p>Avec ce parametre je n'ai plus le probleme: <code>ulimit -n 4096</code> \u2714\ufe0f Je l'ai ajoute dans <code>.zshrc</code> \ud83d\udcdd</p>"},{"location":"#env","title":"<code>.env</code> \ud83c\udf10","text":"<p>https://pypi.org/project/python-dotenv/ \ud83d\udca1</p> <p>Python-dotenv reads key-value pairs from a .env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles. \ud83d\udccb</p> <p>creer <code>.env</code> \u00e0 la racine du repo avec \ud83c\udfd7\ufe0f</p>"},{"location":"#rss-info","title":"rss info \ud83c\udf99\ufe0f","text":"<p>L'adresse du flux RSS du podcast du Masque et la Plume \ud83c\udfa7</p> <p>si absent <code>https://radiofrance-podcast.net/podcast09/rss_14007.xml</code> est utilis\u00e9 par defaut \ud83d\udd04  </p> <pre><code>RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml\n</code></pre>"},{"location":"#web-info","title":"web info \ud83c\udf0d","text":"<p>Le lien vers la page web stockee du masque listant les episodes \"legacy\" historiques \ud83d\udcdc</p> <p>si absent <code>db/\u00c0 \u00e9couter plus tard I Radio France/\u00c0 \u00e9couter plus tard I Radio France.html</code> est utilis\u00e9 par defaut \ud83d\udd04  </p> <pre><code>WEB_LMELP_FILENAME=db/\u00c0 \u00e9couter plus tard I Radio France/\u00c0 \u00e9couter plus tard I Radio France.html\n</code></pre>"},{"location":"#db-info","title":"db info \ud83d\uddc4\ufe0f","text":"<p>pour tout ce qui concerne la base mongo \ud83d\udee2\ufe0f</p> <pre><code>DB_HOST=localhost # \u00e0 changer avec nas923 par exemple\nDB_NAME=\"masque_et_la_plume\"\nDB_LOGS=true # si pr\u00e9sent et valant true, va enregistrer toutes les operations dans la collection logs\n</code></pre>"},{"location":"#llm-llamaindex-litellm","title":"llm, llamaindex, litellm \ud83e\udd16","text":"<pre><code># gemini \nGEMINI_API_KEY=\n# gemini vertex\nGOOGLE_PROJECT_ID=\nGOOGLE_AUTH_FILE=\n\n# openai\nOPENAI_API_KEY=\n\n# azure openai\nAZURE_API_KEY=\nAZURE_ENDPOINT=\nAZURE_API_VERSION=\n</code></pre> <p>gemini llm, GEMINI_API_KEY dispo \u00e0 \ud83d\ude80</p> <p>from https://console.cloud.google.com/apis/credentials \ud83d\udd11</p> <p>gemini vertex (llamaindex), GOOGLE_PROJECT_ID \ud83e\udded</p> <p>from https://console.cloud.google.com \ud83c\udf10</p> <p>gemini vertex (llamaindex), GOOGLE_AUTH_FILE \ud83d\udcc2</p> <p>follow instructions at https://stackoverflow.com/a/69941050 \ud83d\udcd8</p> <p>Et pour les modeles locaux LiteLLM</p> <pre><code>LITELLM_API_KEY\n</code></pre>"},{"location":"#websearch","title":"websearch","text":"<p>We need these 2 keys.</p> <pre><code>\nSEARCH_ENGINE_ID\n</code></pre> <p>more details at readme Google</p>"},{"location":"#streamlit","title":"streamlit \ud83d\uddb1\ufe0f","text":"<p>3 ways to run it: from vscode, from devcontainer, from host</p> <p>from vscode: palette &gt; run task &gt; run streamlit \ud83d\ude80</p> <p>from devcontainer terminal: <code>ui/lmelp_ui.sh</code> \u26a1</p> <p>from host terminal: </p> <pre><code>#!/bin/bash \n\nsource ~/git/lmelp/scripts/from_host/get_container.sh\n\ncontainer=$(get_container)\necho \"Using container: $container\"\n\n# Execute the UI script in the found container as the user vscode.\ndocker exec -u vscode \"$container\" /workspaces/lmelp/ui/lmelp_ui.sh\n</code></pre>"},{"location":"config/","title":"Module config","text":""},{"location":"config/#config.get_DB_VARS","title":"<code>get_DB_VARS()</code>","text":"<p>Retrieve the database configuration variables from the environment.</p> <p>This function loads the environment variables and retrieves the following database configuration variables:     - DB_HOST: The hostname for the database.     - DB_NAME: The name of the database.     - DB_LOGS: A flag indicating if logging is enabled.</p> <p>Returns:</p> Type Description <code>Tuple[Optional[str], Optional[str], Optional[str]]</code> <p>Tuple[Optional[str], Optional[str], Optional[str]]: A tuple containing (DB_HOST, DB_NAME, DB_LOGS).</p> Source code in <code>nbs/config.py</code> <pre><code>def get_DB_VARS() -&gt; Tuple[Optional[str], Optional[str], Optional[str]]:\n    \"\"\"Retrieve the database configuration variables from the environment.\n\n    This function loads the environment variables and retrieves the following\n    database configuration variables:\n        - DB_HOST: The hostname for the database.\n        - DB_NAME: The name of the database.\n        - DB_LOGS: A flag indicating if logging is enabled.\n\n    Returns:\n        Tuple[Optional[str], Optional[str], Optional[str]]:\n            A tuple containing (DB_HOST, DB_NAME, DB_LOGS).\n    \"\"\"\n    load_env()\n    DB_HOST: Optional[str] = os.getenv(\"DB_HOST\")\n    DB_NAME: Optional[str] = os.getenv(\"DB_NAME\")\n    DB_LOGS: Optional[str] = os.getenv(\"DB_LOGS\")\n    return DB_HOST, DB_NAME, DB_LOGS\n</code></pre>"},{"location":"config/#config.get_RSS_URL","title":"<code>get_RSS_URL()</code>","text":"<p>R\u00e9cup\u00e8re l'URL du flux RSS \u00e0 partir des variables d'environnement.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>L'URL du flux RSS. Si la variable d'environnement <code>RSS_LMELP_URL</code> n'est pas d\u00e9finie,</p> <code>str</code> <p>retourne une URL par d\u00e9faut.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_RSS_URL() -&gt; str:\n    \"\"\"\n    R\u00e9cup\u00e8re l'URL du flux RSS \u00e0 partir des variables d'environnement.\n\n    Returns:\n        str: L'URL du flux RSS. Si la variable d'environnement `RSS_LMELP_URL` n'est pas d\u00e9finie,\n        retourne une URL par d\u00e9faut.\n    \"\"\"\n    load_env()\n    RSS_LMELP_URL = os.getenv(\"RSS_LMELP_URL\")\n    if RSS_LMELP_URL is None:\n        RSS_LMELP_URL = \"https://radiofrance-podcast.net/podcast09/rss_14007.xml\"\n    return RSS_LMELP_URL\n</code></pre>"},{"location":"config/#config.get_WEB_filename","title":"<code>get_WEB_filename()</code>","text":"<p>Get the filename of the WEB_LMELP file.</p> <p>This function loads environment variables and retrieves the value of the <code>WEB_LMELP_FILENAME</code> environment variable. If the variable is not set, it returns a default file path.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The filename of the WEB_LMELP file.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_WEB_filename() -&gt; str:\n    \"\"\"\n    Get the filename of the WEB_LMELP file.\n\n    This function loads environment variables and retrieves the value of the\n    `WEB_LMELP_FILENAME` environment variable. If the variable is not set,\n    it returns a default file path.\n\n    Returns:\n        str: The filename of the WEB_LMELP file.\n    \"\"\"\n    load_env()\n\n    WEB_LMELP_FILENAME = os.getenv(\"WEB_LMELP_FILENAME\")\n    if WEB_LMELP_FILENAME is None:\n        WEB_LMELP_FILENAME = \"db/\u00c0 \u00e9couter plus tard I Radio France/\u00c0 \u00e9couter plus tard I Radio France.html\"\n\n    return str(Path(get_git_root(\"\"), WEB_LMELP_FILENAME))\n</code></pre>"},{"location":"config/#config.get_audio_path","title":"<code>get_audio_path(audio_path=AUDIO_PATH, year='2024')</code>","text":"<p>Returns the full path to the audio files by appending the year as a subdirectory.</p> <p>If the directory does not exist, it is created.</p> <p>Parameters:</p> Name Type Description Default <code>audio_path</code> <code>str</code> <p>Relative path to the audio files.</p> <code>AUDIO_PATH</code> <code>year</code> <code>str</code> <p>The year used as a subdirectory (default \"2024\").</p> <code>'2024'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The full path to the corresponding audio directory.</p> Example <p>path = get_audio_path(\"audios\", \"2024\")</p> Source code in <code>nbs/config.py</code> <pre><code>def get_audio_path(audio_path: str = AUDIO_PATH, year: str = \"2024\") -&gt; str:\n    \"\"\"Returns the full path to the audio files by appending the year as a subdirectory.\n\n    If the directory does not exist, it is created.\n\n    Args:\n        audio_path (str): Relative path to the audio files.\n        year (str): The year used as a subdirectory (default \"2024\").\n\n    Returns:\n        str: The full path to the corresponding audio directory.\n\n    Example:\n        &gt;&gt;&gt; path = get_audio_path(\"audios\", \"2024\")\n    \"\"\"\n\n    project_root: str = get_git_root(os.getcwd())\n    full_audio_path: str = os.path.join(project_root, audio_path, year)\n\n    # Create the directory if it does not exist\n    if not os.path.exists(full_audio_path):\n        os.makedirs(full_audio_path)\n\n    return full_audio_path\n</code></pre>"},{"location":"config/#config.get_azure_openai_keys","title":"<code>get_azure_openai_keys()</code>","text":"<p>Get the Azure OpenAI keys from environment variables.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[str, str, str]</code> <p>A tuple containing the Azure API key, endpoint, and API version.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_azure_openai_keys() -&gt; tuple[str, str, str]:\n    \"\"\"\n    Get the Azure OpenAI keys from environment variables.\n\n    Returns:\n        tuple: A tuple containing the Azure API key, endpoint, and API version.\n    \"\"\"\n    load_env()\n    azure_api_key = os.getenv(\"AZURE_API_KEY\")\n    azure_endpoint = os.getenv(\"AZURE_ENDPOINT\")\n    azure_api_version = os.getenv(\"AZURE_API_VERSION\")\n    return azure_api_key, azure_endpoint, azure_api_version\n</code></pre>"},{"location":"config/#config.get_gemini_api_key","title":"<code>get_gemini_api_key()</code>","text":"<p>Get the Gemini API key from environment variables.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Gemini API key.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_gemini_api_key() -&gt; str:\n    \"\"\"\n    Get the Gemini API key from environment variables.\n\n    Returns:\n        str: The Gemini API key.\n    \"\"\"\n    load_env()\n    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n    return gemini_api_key\n</code></pre>"},{"location":"config/#config.get_git_root","title":"<code>get_git_root(path)</code>","text":"<p>Retrieves the root directory of the Git repository.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The current working directory.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The root directory of the Git repository.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_git_root(path: str) -&gt; str:\n    \"\"\"Retrieves the root directory of the Git repository.\n\n    Args:\n        path (str): The current working directory.\n\n    Returns:\n        str: The root directory of the Git repository.\n    \"\"\"\n    git_repo = Repo(path, search_parent_directories=True)\n    return git_repo.git.rev_parse(\"--show-toplevel\")\n</code></pre>"},{"location":"config/#config.get_google_auth_file","title":"<code>get_google_auth_file()</code>","text":"<p>Get the Google authentication file path from environment variables.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The path to the Google authentication file.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_google_auth_file() -&gt; str:\n    \"\"\"\n    Get the Google authentication file path from environment variables.\n\n    Returns:\n        str: The path to the Google authentication file.\n    \"\"\"\n    load_env()\n    google_auth_file = os.getenv(\"GOOGLE_AUTH_FILE\")\n    return google_auth_file\n</code></pre>"},{"location":"config/#config.get_google_projectID","title":"<code>get_google_projectID()</code>","text":"<p>Get the Google Project ID from environment variables.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Google Project ID.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_google_projectID() -&gt; str:\n    \"\"\"\n    Get the Google Project ID from environment variables.\n\n    Returns:\n        str: The Google Project ID.\n    \"\"\"\n    load_env()\n    google_projectID = os.getenv(\"GOOGLE_PROJECT_ID\")\n    return google_projectID\n</code></pre>"},{"location":"config/#config.get_openai_api_key","title":"<code>get_openai_api_key()</code>","text":"<p>Get the OpenAI API key from environment variables.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The OpenAI API key.</p> Source code in <code>nbs/config.py</code> <pre><code>def get_openai_api_key() -&gt; str:\n    \"\"\"\n    Get the OpenAI API key from environment variables.\n\n    Returns:\n        str: The OpenAI API key.\n    \"\"\"\n    load_env()\n    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n    return openai_api_key\n</code></pre>"},{"location":"config/#config.load_env","title":"<code>load_env()</code>","text":"<p>Charge les variables d'environnement \u00e0 partir d'un fichier .env.</p> Source code in <code>nbs/config.py</code> <pre><code>def load_env() -&gt; None:\n    \"\"\"\n    Charge les variables d'environnement \u00e0 partir d'un fichier .env.\n    \"\"\"\n    _ = load_dotenv(find_dotenv())\n</code></pre>"},{"location":"development-workflow/","title":"Workflow de d\u00e9veloppement avec Docker et Portainer","text":"<p>Ce guide d\u00e9crit le workflow recommand\u00e9 pour d\u00e9velopper lmelp tout en utilisant Portainer pour la production locale.</p>"},{"location":"development-workflow/#vue-densemble","title":"Vue d'ensemble","text":"<p>Le workflow s\u00e9pare clairement deux environnements :</p> <ul> <li>D\u00e9veloppement : devcontainer (VS Code) sur une branche feature</li> <li>Production locale : Stack Portainer (auto-update) sur la branche main</li> </ul> <p>Cette s\u00e9paration \u00e9vite les conflits de ports et permet une mise \u00e0 jour automatique de la version \"production\" locale.</p>"},{"location":"development-workflow/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        MongoDB (h\u00f4te)                        \u2502\n\u2502                    localhost:27017                           \u2502\n\u2502              masque_et_la_plume database                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502                             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   D\u00c9VELOPPEMENT   \u2502         \u2502   PRODUCTION      \u2502\n    \u2502                   \u2502         \u2502     LOCALE        \u2502\n    \u2502  Devcontainer     \u2502         \u2502                   \u2502\n    \u2502  (branche feature)\u2502         \u2502  Stack Portainer  \u2502\n    \u2502                   \u2502         \u2502  (branche main)   \u2502\n    \u2502  Port 8501        \u2502         \u2502  Port 8501        \u2502\n    \u2502  DB: localhost    \u2502         \u2502  DB: 172.17.0.1   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         Actif pendant              Actif le reste\n         le d\u00e9veloppement           du temps\n</code></pre>"},{"location":"development-workflow/#workflow-etape-par-etape","title":"Workflow \u00e9tape par \u00e9tape","text":""},{"location":"development-workflow/#1-demarrer-un-nouveau-developpement","title":"1. D\u00e9marrer un nouveau d\u00e9veloppement","text":"<p>Sur une nouvelle branche feature :</p> <pre><code># Cr\u00e9er la branche feature\ngit checkout -b feature/ma-nouvelle-fonctionnalite\n\n# Dans Portainer Web UI : Arr\u00eater la stack lmelp\n# Stacks \u2192 lmelp \u2192 Stop this stack\n</code></pre> <p>Pourquoi arr\u00eater Portainer ? - Lib\u00e8re le port 8501 pour Streamlit en dev - \u00c9vite les acc\u00e8s concurrents \u00e0 MongoDB (bien que MongoDB les supporte) - Environnement propre pour le d\u00e9veloppement</p>"},{"location":"development-workflow/#2-developper-dans-devcontainer","title":"2. D\u00e9velopper dans devcontainer","text":"<pre><code># Ouvrir VS Code dans le repo\ncode .\n\n# VS Code d\u00e9tecte automatiquement le devcontainer\n# Accept \"Reopen in Container\"\n</code></pre> <p>Dans le devcontainer :</p> <ul> <li>L'application se connecte \u00e0 MongoDB sur l'h\u00f4te (localhost)</li> <li>Streamlit sur port 8501</li> <li>Hot-reload automatique des modifications Python</li> <li>Acc\u00e8s \u00e0 tous les outils de dev (pytest, nbdev, etc.)</li> </ul> <p>Lancer l'interface :</p> <pre><code># Dans le terminal devcontainer\n./ui/lmelp_ui.sh\n\n# Ou via VS Code Tasks\n# Ctrl+Shift+P \u2192 \"Tasks: Run Task\" \u2192 \"run streamlit\"\n</code></pre> <p>Acc\u00e8s : http://localhost:8501</p>"},{"location":"development-workflow/#3-developper-et-tester","title":"3. D\u00e9velopper et tester","text":"<pre><code># Modifier le code (notebooks ou Python)\n# Les changements sont automatiquement refl\u00e9t\u00e9s\n\n# Exporter les notebooks si modifi\u00e9s\nnbdev_export\n\n# Lancer les tests\npytest\n\n# Formatter le code\nblack nbs/ ui/\n\n# Commit r\u00e9guliers\ngit add .\ngit commit -m \"Add: nouvelle fonctionnalit\u00e9\"\ngit push origin feature/ma-nouvelle-fonctionnalite\n</code></pre>"},{"location":"development-workflow/#4-merger-dans-main","title":"4. Merger dans main","text":"<p>Via Pull Request (recommand\u00e9) :</p> <ol> <li>Cr\u00e9er une PR sur GitHub</li> <li>Review du code</li> <li>Merger dans main</li> </ol> <p>Ou directement (si seul d\u00e9veloppeur) :</p> <pre><code>git checkout main\ngit pull origin main\ngit merge feature/ma-nouvelle-fonctionnalite\ngit push origin main\n</code></pre>"},{"location":"development-workflow/#5-mise-a-jour-automatique-de-la-production-locale","title":"5. Mise \u00e0 jour automatique de la production locale","text":"<p>Le workflow CI/CD se d\u00e9clenche automatiquement :</p> <pre><code>Push sur main\n     \u2193\nGitHub Actions build Docker image\n     \u2193\nImage publi\u00e9e sur ghcr.io/castorfou/lmelp:latest\n     \u2193\nPortainer auto-update d\u00e9tecte la nouvelle image\n     \u2193\nPull et red\u00e9ploiement automatique\n     \u2193\nProduction locale \u00e0 jour ! \u2705\n</code></pre> <p>Dur\u00e9e totale : ~20-30 minutes - Build Docker : ~19 minutes (GitHub Actions) - D\u00e9tection Portainer : 0-6 heures (selon config Watchtower) - Pull et red\u00e9ploiement : ~2 minutes</p> <p>Red\u00e9marrer la stack Portainer :</p> <pre><code># Dans Portainer Web UI\n# Stacks \u2192 lmelp \u2192 Start this stack\n\n# Ou forcer l'update imm\u00e9diatement\n# Stacks \u2192 lmelp \u2192 Pull and redeploy\n</code></pre> <p>Acc\u00e8s production locale : http://localhost:8501</p>"},{"location":"development-workflow/#6-nettoyer-la-branche-feature","title":"6. Nettoyer la branche feature","text":"<pre><code># Supprimer la branche locale\ngit branch -d feature/ma-nouvelle-fonctionnalite\n\n# Supprimer la branche distante\ngit push origin --delete feature/ma-nouvelle-fonctionnalite\n</code></pre>"},{"location":"development-workflow/#avantages-de-ce-workflow","title":"Avantages de ce workflow","text":""},{"location":"development-workflow/#separation-devprod-claire","title":"S\u00e9paration dev/prod claire","text":"<ul> <li>Dev : Exp\u00e9rimentation libre, breakpoints, debug</li> <li>Prod locale : Version stable, test\u00e9e, document\u00e9e</li> </ul>"},{"location":"development-workflow/#pas-de-conflits-de-ressources","title":"Pas de conflits de ressources","text":"<ul> <li>Port 8501 utilis\u00e9 par un seul service \u00e0 la fois</li> <li>MongoDB accessible des deux environnements (s\u00e9quentiellement)</li> </ul>"},{"location":"development-workflow/#auto-update-zero-intervention","title":"Auto-update z\u00e9ro intervention","text":"<ul> <li>Push sur main \u2192 Image build\u00e9e \u2192 Portainer update</li> <li>Aucune commande manuelle \u00e0 lancer</li> <li>Reproductible sur NAS Synology</li> </ul>"},{"location":"development-workflow/#donnees-partagees","title":"Donn\u00e9es partag\u00e9es","text":"<ul> <li>M\u00eame base MongoDB pour dev et prod locale</li> <li>Pas besoin de restaurer des backups entre les deux</li> <li>Continuit\u00e9 des donn\u00e9es de test</li> </ul>"},{"location":"development-workflow/#configuration-portainer-auto-update","title":"Configuration Portainer auto-update","text":""},{"location":"development-workflow/#via-watchtower-integre","title":"Via Watchtower int\u00e9gr\u00e9","text":"<p>Si Portainer a Watchtower configur\u00e9 globalement, aucune config n\u00e9cessaire.</p> <p>V\u00e9rifier la configuration :</p> <pre><code># Voir si Watchtower tourne\ndocker ps | grep watchtower\n\n# Voir les logs Watchtower\ndocker logs -f &lt;watchtower-container-id&gt;\n</code></pre>"},{"location":"development-workflow/#via-webhook-portainer","title":"Via webhook Portainer","text":"<p>Pour des updates instantan\u00e9es (optionnel) :</p> <ol> <li>Dans Portainer : Stacks \u2192 lmelp \u2192 Webhooks \u2192 Create webhook</li> <li>Copier l'URL du webhook</li> <li>Dans GitHub : Settings \u2192 Secrets \u2192 Actions \u2192 New secret</li> <li>Name: <code>PORTAINER_WEBHOOK_URL</code></li> <li>Value: URL copi\u00e9e</li> <li>Le workflow GitHub Actions triggera automatiquement le webhook</li> </ol>"},{"location":"development-workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development-workflow/#port-8501-deja-utilise","title":"Port 8501 d\u00e9j\u00e0 utilis\u00e9","text":"<p>Sympt\u00f4me : Impossible de lancer Streamlit en dev</p> <p>Cause : La stack Portainer est toujours active</p> <p>Solution :</p> <pre><code># V\u00e9rifier quel processus utilise le port\nsudo lsof -i :8501\n\n# Arr\u00eater la stack Portainer\n# Via Web UI : Stacks \u2192 lmelp \u2192 Stop\n</code></pre>"},{"location":"development-workflow/#mongodb-connection-refused-en-dev","title":"MongoDB connection refused en dev","text":"<p>Sympt\u00f4me : <code>pymongo.errors.ServerSelectionTimeoutError</code></p> <p>Cause : MongoDB non d\u00e9marr\u00e9 sur l'h\u00f4te</p> <p>Solution :</p> <pre><code># V\u00e9rifier MongoDB\nsudo systemctl status mongod\n\n# D\u00e9marrer MongoDB\nsudo systemctl start mongod\n</code></pre>"},{"location":"development-workflow/#portainer-nauto-update-pas","title":"Portainer n'auto-update pas","text":"<p>Sympt\u00f4me : Nouvelle version push\u00e9e mais Portainer reste sur l'ancienne</p> <p>Causes possibles :</p> <ol> <li>Watchtower non configur\u00e9 : Configurer Watchtower ou utiliser webhook</li> <li>D\u00e9lai de polling : Watchtower v\u00e9rifie toutes les 6h par d\u00e9faut</li> <li>Image tag incorrect : V\u00e9rifier que le compose utilise <code>:latest</code></li> </ol> <p>Solutions :</p> <pre><code># Forcer l'update manuellement\n# Portainer \u2192 Stacks \u2192 lmelp \u2192 Pull and redeploy\n\n# Ou v\u00e9rifier les logs Watchtower\ndocker logs watchtower | grep lmelp\n</code></pre>"},{"location":"development-workflow/#image-docker-pas-a-jour-apres-le-build","title":"Image Docker pas \u00e0 jour apr\u00e8s le build","text":"<p>Sympt\u00f4me : GitHub Actions build OK mais image pas mise \u00e0 jour</p> <p>Cause : GitHub Actions en cours ou \u00e9chou\u00e9</p> <p>Solution :</p> <pre><code># V\u00e9rifier le statut du build\n# https://github.com/castorfou/lmelp/actions/workflows/docker-publish.yml\n\n# Attendre la fin du build (~19 minutes)\n# V\u00e9rifier l'image publi\u00e9e\n# https://github.com/castorfou/lmelp/pkgs/container/lmelp\n</code></pre>"},{"location":"development-workflow/#cas-dusage-avances","title":"Cas d'usage avanc\u00e9s","text":""},{"location":"development-workflow/#developper-sur-plusieurs-branches-en-parallele","title":"D\u00e9velopper sur plusieurs branches en parall\u00e8le","text":"<p>Probl\u00e8me : Besoin de tester deux features simultan\u00e9ment</p> <p>Solution : Utiliser diff\u00e9rents ports</p> <pre><code># Feature 1 : port 8501\nstreamlit run ui/lmelp.py --server.port 8501\n\n# Feature 2 : port 8502 (autre terminal)\nstreamlit run ui/lmelp.py --server.port 8502\n</code></pre>"},{"location":"development-workflow/#tester-limage-docker-localement-avant-le-merge","title":"Tester l'image Docker localement avant le merge","text":"<pre><code># Builder l'image localement\ncd /path/to/lmelp\ndocker build -f docker/Dockerfile -t lmelp:test .\n\n# Arr\u00eater Portainer\n# Dans Portainer Web UI : Stop stack lmelp\n\n# Lancer l'image de test\ndocker run --rm -p 8501:8501 \\\n  -e DB_HOST=172.17.0.1 \\\n  -e DB_NAME=masque_et_la_plume \\\n  --env-file .env \\\n  lmelp:test\n\n# Acc\u00e8s : http://localhost:8501\n</code></pre>"},{"location":"development-workflow/#reproduire-le-workflow-sur-nas-synology","title":"Reproduire le workflow sur NAS Synology","text":"<p>Identique au PC, avec ces diff\u00e9rences :</p> <pre><code># DB_HOST diff\u00e9rent dans .env Portainer\nDB_HOST=mongo  # Nom du conteneur MongoDB sur le NAS\n\n# Pas de devcontainer sur le NAS (d\u00e9veloppement sur PC uniquement)\n\n# M\u00eame auto-update via Portainer\n</code></pre>"},{"location":"development-workflow/#ressources","title":"Ressources","text":"<ul> <li>Guide Docker complet</li> <li>D\u00e9ploiement Portainer</li> <li>CI/CD GitHub Actions</li> <li>CLAUDE.md - Vue d'ensemble projet</li> </ul>"},{"location":"development-workflow/#resume-du-cycle-complet","title":"R\u00e9sum\u00e9 du cycle complet","text":"<pre><code>1. Stop Portainer\n2. Dev dans devcontainer (branche feature)\n3. Test, commit, push\n4. Merge vers main (PR ou direct)\n5. CI/CD build image (auto)\n6. Portainer pull image (auto)\n7. Start Portainer \u2192 Prod locale \u00e0 jour \u2705\n8. R\u00e9p\u00e9ter pour la prochaine feature\n</code></pre> <p>Dur\u00e9e du cycle : 20-30 minutes (principalement build Docker)</p> <p>Intervention manuelle : Stop/Start Portainer uniquement</p>"},{"location":"llm/","title":"Module llm","text":""},{"location":"llm/#llm.get_azure_llm","title":"<code>get_azure_llm(engine='gpt-4o')</code>","text":"<p>Get the Azure OpenAI language model.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>str</code> <p>The engine to use for the Azure OpenAI model. Default is \"gpt-4o\".</p> <code>'gpt-4o'</code> <p>Returns:</p> Name Type Description <code>AzureOpenAI</code> <code>AzureOpenAI</code> <p>An instance of the AzureOpenAI language model.</p> Source code in <code>nbs/llm.py</code> <pre><code>def get_azure_llm(engine=\"gpt-4o\") -&gt; AzureOpenAI:\n    \"\"\"\n    Get the Azure OpenAI language model.\n\n    Args:\n        engine (str): The engine to use for the Azure OpenAI model. Default is \"gpt-4o\".\n\n    Returns:\n        AzureOpenAI: An instance of the AzureOpenAI language model.\n    \"\"\"\n    AZURE_API_KEY, AZURE_ENDPOINT, AZURE_API_VERSION = get_azure_openai_keys()\n    llm = AzureOpenAI(\n        engine=engine,\n        api_key=AZURE_API_KEY,\n        azure_endpoint=AZURE_ENDPOINT,\n        api_version=AZURE_API_VERSION,\n        # increase timeout to 300 seconds (5 minutes) to avoid timeout on long transcriptions\n        timeout=300.0,\n    )\n    Settings.llm = llm\n    return llm\n</code></pre>"},{"location":"llm/#llm.get_gemini_llm","title":"<code>get_gemini_llm(model='gemini-1.5-flash')</code>","text":"<p>Get the Gemini language model.</p> <p>This function configures the Gemini API using the API key obtained from the environment variables and returns an instance of the GenerativeModel.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for the Gemini language model. Default is \"gemini-1.5-flash\".</p> <code>'gemini-1.5-flash'</code> <p>Returns:</p> Name Type Description <code>GenerativeModel</code> <code>GenerativeModel</code> <p>An instance of the GenerativeModel.</p> Source code in <code>nbs/llm.py</code> <pre><code>def get_gemini_llm(model=\"gemini-1.5-flash\") -&gt; genai.GenerativeModel:\n    \"\"\"\n    Get the Gemini language model.\n\n    This function configures the Gemini API using the API key obtained from the environment variables\n    and returns an instance of the GenerativeModel.\n\n    Args:\n        model (str): The model to use for the Gemini language model. Default is \"gemini-1.5-flash\".\n\n    Returns:\n        GenerativeModel: An instance of the GenerativeModel.\n    \"\"\"\n    genai.configure(api_key=get_gemini_api_key())\n    llm = genai.GenerativeModel(model)\n    return llm\n</code></pre>"},{"location":"llm/#llm.get_vertex_llm","title":"<code>get_vertex_llm(model='gemini-1.5-flash-001')</code>","text":"<p>Get the Vertex language model.</p> <p>This function configures the Vertex API using the project ID and API key obtained from the environment variables and returns an instance of the Vertex model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for the Vertex language model. Default is \"gemini-1.5-flash-001\".</p> <code>'gemini-1.5-flash-001'</code> <p>Returns:</p> Name Type Description <code>Vertex</code> <code>Vertex</code> <p>An instance of the Vertex language model.</p> Source code in <code>nbs/llm.py</code> <pre><code>def get_vertex_llm(model=\"gemini-1.5-flash-001\") -&gt; Vertex:\n    \"\"\"\n    Get the Vertex language model.\n\n    This function configures the Vertex API using the project ID and API key obtained from the environment variables\n    and returns an instance of the Vertex model.\n\n    Args:\n        model (str): The model to use for the Vertex language model. Default is \"gemini-1.5-flash-001\".\n\n    Returns:\n        Vertex: An instance of the Vertex language model.\n    \"\"\"\n    # Set up necessary variables\n    credentials = {\n        \"project_id\": get_google_projectID(),\n        \"api_key\": get_gemini_api_key(),\n    }\n\n    # filename = get_google_auth_file()\n    # credentials_service: service_account.Credentials = (\n    #     service_account.Credentials.from_service_account_file(filename)\n    # )\n\n    # Create an instance of the Vertex class\n    llm = Vertex(\n        model=model,\n        project=credentials[\"project_id\"],\n        credentials=credentials,\n        context_window=100000,\n    )\n    # llm = Vertex(\n    #     model=model,\n    #     project=credentials_service.project_id,\n    #     credentials=credentials_service,\n    #     context_window=100000,    )\n    Settings.llm = llm\n    return llm\n</code></pre>"},{"location":"mongo/","title":"Module mongo","text":""},{"location":"mongo/#mongo.BaseEntity","title":"<code>BaseEntity</code>","text":"Source code in <code>nbs/mongo.py</code> <pre><code>class BaseEntity:\n    def __init__(self, nom: str, collection_name: str) -&gt; None:\n        \"\"\"Initializes a new BaseEntity instance.\n\n        Args:\n            nom (str): The name of the entity.\n            collection_name (str): The name of the collection.\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        self.collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n        )\n        self.nom = nom\n\n    def exists(self) -&gt; bool:\n        \"\"\"Checks if the entity exists in the database.\n\n        Returns:\n            bool: True if the entity exists, False otherwise.\n        \"\"\"\n        return self.collection.find_one({\"nom\": self.nom}) is not None\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        S\u00e9rialise l'instance en dictionnaire en excluant les attributs non d\u00e9sir\u00e9s.\n        On exclut ici 'collection' par exemple.\n        \"\"\"\n        # On r\u00e9cup\u00e8re l'ensemble des attributs de l'objet\n        data = self.__dict__.copy()\n        # On retire attributes non serialisables\n        data.pop(\"collection\", None)\n        return data\n\n    def keep(self) -&gt; None:\n        \"\"\"\n        Insert ou met \u00e0 jour l'entit\u00e9 dans la base.\n        Utilise la s\u00e9rialisation via to_dict() pour conserver tous les attributs serialisables.\n        \"\"\"\n        data = self.to_dict()\n        if not self.exists():\n            mongolog(\"insert\", self.collection.name, self.nom)\n            self.collection.insert_one(data)\n        else:\n            mongolog(\"update\", self.collection.name, self.nom)\n            self.collection.replace_one({\"nom\": self.nom}, data)\n\n    def remove(self) -&gt; None:\n        \"\"\"Removes the entity from the database.\"\"\"\n        self.collection.delete_one({\"nom\": self.nom})\n        mongolog(\"delete\", self.collection.name, self.nom)\n\n    def get_oid(self) -&gt; Optional[ObjectId]:\n        \"\"\"Retrieves the ObjectId of the entity from the database.\n\n        Returns:\n            Optional[ObjectId]: The ObjectId of the entity if found, otherwise None.\n        \"\"\"\n        document = self.collection.find_one({\"nom\": self.nom})\n        if document:\n            return document[\"_id\"]\n        else:\n            return None\n\n    @classmethod\n    def from_oid(cls: Type[T], oid: ObjectId) -&gt; T:\n        \"\"\"Creates an instance of the derived class from a MongoDB ObjectId.\n        Returns None if the ObjectId is not found in the database or is None.\n\n        Args:\n            oid (ObjectId): The MongoDB ObjectId.\n\n        Returns:\n            T: An instance of the derived class.\n        \"\"\"\n        if oid is None:\n            return None\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n        )\n        document = collection.find_one({\"_id\": oid})\n        if document is None:\n            return None\n        inst = cls(document.get(\"nom\"))\n        return inst\n\n    @classmethod\n    def get_entries(cls: Type[T], request: str = \"\") -&gt; List[T]:\n        \"\"\"Retrieves a list of entries matching the query.\n\n        Args:\n            request (str, optional): A substring of the name to filter results\n                (case-insensitive). Defaults to an empty string.\n\n        Returns:\n            List[T]: A list of instances of the derived class.\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n        )\n        query = {\n            \"nom\": {\n                \"$regex\": request,\n                \"$options\": \"i\",\n            }\n        }\n        result = collection.find(query)\n        list_baseentity = [cls.from_oid(entry.get(\"_id\")) for entry in result]\n        return list_baseentity\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Official string representation of the entity.\n\n        Returns:\n            str: The name of the entity.\n        \"\"\"\n        return self.nom\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation of the entity.\n\n        Returns:\n            str: The name of the entity.\n        \"\"\"\n        return self.nom\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.__init__","title":"<code>__init__(nom, collection_name)</code>","text":"<p>Initializes a new BaseEntity instance.</p> <p>Parameters:</p> Name Type Description Default <code>nom</code> <code>str</code> <p>The name of the entity.</p> required <code>collection_name</code> <code>str</code> <p>The name of the collection.</p> required Source code in <code>nbs/mongo.py</code> <pre><code>def __init__(self, nom: str, collection_name: str) -&gt; None:\n    \"\"\"Initializes a new BaseEntity instance.\n\n    Args:\n        nom (str): The name of the entity.\n        collection_name (str): The name of the collection.\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    self.collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n    )\n    self.nom = nom\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.__repr__","title":"<code>__repr__()</code>","text":"<p>Official string representation of the entity.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the entity.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Official string representation of the entity.\n\n    Returns:\n        str: The name of the entity.\n    \"\"\"\n    return self.nom\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation of the entity.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the entity.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation of the entity.\n\n    Returns:\n        str: The name of the entity.\n    \"\"\"\n    return self.nom\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.exists","title":"<code>exists()</code>","text":"<p>Checks if the entity exists in the database.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entity exists, False otherwise.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"Checks if the entity exists in the database.\n\n    Returns:\n        bool: True if the entity exists, False otherwise.\n    \"\"\"\n    return self.collection.find_one({\"nom\": self.nom}) is not None\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.from_oid","title":"<code>from_oid(oid)</code>  <code>classmethod</code>","text":"<p>Creates an instance of the derived class from a MongoDB ObjectId. Returns None if the ObjectId is not found in the database or is None.</p> <p>Parameters:</p> Name Type Description Default <code>oid</code> <code>ObjectId</code> <p>The MongoDB ObjectId.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>An instance of the derived class.</p> Source code in <code>nbs/mongo.py</code> <pre><code>@classmethod\ndef from_oid(cls: Type[T], oid: ObjectId) -&gt; T:\n    \"\"\"Creates an instance of the derived class from a MongoDB ObjectId.\n    Returns None if the ObjectId is not found in the database or is None.\n\n    Args:\n        oid (ObjectId): The MongoDB ObjectId.\n\n    Returns:\n        T: An instance of the derived class.\n    \"\"\"\n    if oid is None:\n        return None\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n    )\n    document = collection.find_one({\"_id\": oid})\n    if document is None:\n        return None\n    inst = cls(document.get(\"nom\"))\n    return inst\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.get_entries","title":"<code>get_entries(request='')</code>  <code>classmethod</code>","text":"<p>Retrieves a list of entries matching the query.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>str</code> <p>A substring of the name to filter results (case-insensitive). Defaults to an empty string.</p> <code>''</code> <p>Returns:</p> Type Description <code>List[T]</code> <p>List[T]: A list of instances of the derived class.</p> Source code in <code>nbs/mongo.py</code> <pre><code>@classmethod\ndef get_entries(cls: Type[T], request: str = \"\") -&gt; List[T]:\n    \"\"\"Retrieves a list of entries matching the query.\n\n    Args:\n        request (str, optional): A substring of the name to filter results\n            (case-insensitive). Defaults to an empty string.\n\n    Returns:\n        List[T]: A list of instances of the derived class.\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n    )\n    query = {\n        \"nom\": {\n            \"$regex\": request,\n            \"$options\": \"i\",\n        }\n    }\n    result = collection.find(query)\n    list_baseentity = [cls.from_oid(entry.get(\"_id\")) for entry in result]\n    return list_baseentity\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.get_oid","title":"<code>get_oid()</code>","text":"<p>Retrieves the ObjectId of the entity from the database.</p> <p>Returns:</p> Type Description <code>Optional[ObjectId]</code> <p>Optional[ObjectId]: The ObjectId of the entity if found, otherwise None.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def get_oid(self) -&gt; Optional[ObjectId]:\n    \"\"\"Retrieves the ObjectId of the entity from the database.\n\n    Returns:\n        Optional[ObjectId]: The ObjectId of the entity if found, otherwise None.\n    \"\"\"\n    document = self.collection.find_one({\"nom\": self.nom})\n    if document:\n        return document[\"_id\"]\n    else:\n        return None\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.keep","title":"<code>keep()</code>","text":"<p>Insert ou met \u00e0 jour l'entit\u00e9 dans la base. Utilise la s\u00e9rialisation via to_dict() pour conserver tous les attributs serialisables.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def keep(self) -&gt; None:\n    \"\"\"\n    Insert ou met \u00e0 jour l'entit\u00e9 dans la base.\n    Utilise la s\u00e9rialisation via to_dict() pour conserver tous les attributs serialisables.\n    \"\"\"\n    data = self.to_dict()\n    if not self.exists():\n        mongolog(\"insert\", self.collection.name, self.nom)\n        self.collection.insert_one(data)\n    else:\n        mongolog(\"update\", self.collection.name, self.nom)\n        self.collection.replace_one({\"nom\": self.nom}, data)\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.remove","title":"<code>remove()</code>","text":"<p>Removes the entity from the database.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def remove(self) -&gt; None:\n    \"\"\"Removes the entity from the database.\"\"\"\n    self.collection.delete_one({\"nom\": self.nom})\n    mongolog(\"delete\", self.collection.name, self.nom)\n</code></pre>"},{"location":"mongo/#mongo.BaseEntity.to_dict","title":"<code>to_dict()</code>","text":"<p>S\u00e9rialise l'instance en dictionnaire en excluant les attributs non d\u00e9sir\u00e9s. On exclut ici 'collection' par exemple.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    S\u00e9rialise l'instance en dictionnaire en excluant les attributs non d\u00e9sir\u00e9s.\n    On exclut ici 'collection' par exemple.\n    \"\"\"\n    # On r\u00e9cup\u00e8re l'ensemble des attributs de l'objet\n    data = self.__dict__.copy()\n    # On retire attributes non serialisables\n    data.pop(\"collection\", None)\n    return data\n</code></pre>"},{"location":"mongo/#mongo.Critique","title":"<code>Critique</code>","text":"<p>               Bases: <code>BaseEntity</code></p> <p>Class representing a review (Critique) entity stored in the 'critiques' MongoDB collection.</p> <p>Attributes:</p> Name Type Description <code>collection</code> <code>str</code> <p>MongoDB collection name used to store critiques.</p> Source code in <code>nbs/mongo.py</code> <pre><code>class Critique(BaseEntity):\n    \"\"\"\n    Class representing a review (Critique) entity stored in the 'critiques' MongoDB collection.\n\n    Attributes:\n        collection (str): MongoDB collection name used to store critiques.\n    \"\"\"\n\n    collection: str = \"critiques\"\n\n    def __init__(self, nom: str) -&gt; None:\n        \"\"\"\n        Initializes a Critique instance.\n\n        Args:\n            nom (str): Name of the critique.\n        \"\"\"\n        super().__init__(nom, self.collection)\n</code></pre>"},{"location":"mongo/#mongo.Critique.__init__","title":"<code>__init__(nom)</code>","text":"<p>Initializes a Critique instance.</p> <p>Parameters:</p> Name Type Description Default <code>nom</code> <code>str</code> <p>Name of the critique.</p> required Source code in <code>nbs/mongo.py</code> <pre><code>def __init__(self, nom: str) -&gt; None:\n    \"\"\"\n    Initializes a Critique instance.\n\n    Args:\n        nom (str): Name of the critique.\n    \"\"\"\n    super().__init__(nom, self.collection)\n</code></pre>"},{"location":"mongo/#mongo.Editeur","title":"<code>Editeur</code>","text":"<p>               Bases: <code>BaseEntity</code></p> <p>Represents a publisher stored in the 'editeurs' MongoDB collection.</p> <p>Attributes:</p> Name Type Description <code>collection</code> <code>str</code> <p>The name of the MongoDB collection.</p> Source code in <code>nbs/mongo.py</code> <pre><code>class Editeur(BaseEntity):\n    \"\"\"\n    Represents a publisher stored in the 'editeurs' MongoDB collection.\n\n    Attributes:\n        collection (str): The name of the MongoDB collection.\n    \"\"\"\n\n    collection: str = \"editeurs\"\n\n    def __init__(self, nom: str) -&gt; None:\n        \"\"\"\n        Initialize an Editeur instance.\n\n        Args:\n            nom (str): The name of the publisher.\n        \"\"\"\n        super().__init__(nom, self.collection)\n</code></pre>"},{"location":"mongo/#mongo.Editeur.__init__","title":"<code>__init__(nom)</code>","text":"<p>Initialize an Editeur instance.</p> <p>Parameters:</p> Name Type Description Default <code>nom</code> <code>str</code> <p>The name of the publisher.</p> required Source code in <code>nbs/mongo.py</code> <pre><code>def __init__(self, nom: str) -&gt; None:\n    \"\"\"\n    Initialize an Editeur instance.\n\n    Args:\n        nom (str): The name of the publisher.\n    \"\"\"\n    super().__init__(nom, self.collection)\n</code></pre>"},{"location":"mongo/#mongo.get_collection","title":"<code>get_collection(target_db='localhost', client_name='masque_et_la_plume', collection_name='episodes')</code>","text":"<p>Retrieve a MongoDB collection.</p> <p>This function connects to a MongoDB database using the provided database host, client name (database name), and collection name, and returns the collection object.</p> <p>Parameters:</p> Name Type Description Default <code>target_db</code> <code>str</code> <p>The database host address (e.g., \"localhost\" or \"nas923\").</p> <code>'localhost'</code> <code>client_name</code> <code>str</code> <p>The name of the MongoDB client/database.</p> <code>'masque_et_la_plume'</code> <code>collection_name</code> <code>str</code> <p>The name of the collection to retrieve.</p> <code>'episodes'</code> <p>Returns:</p> Name Type Description <code>Collection</code> <code>Collection</code> <p>The MongoDB collection object.</p> Source code in <code>nbs/mongo.py</code> <pre><code>def get_collection(\n    target_db: str = \"localhost\",\n    client_name: str = \"masque_et_la_plume\",\n    collection_name: str = \"episodes\",\n) -&gt; Collection:\n    \"\"\"Retrieve a MongoDB collection.\n\n    This function connects to a MongoDB database using the provided database host,\n    client name (database name), and collection name, and returns the collection object.\n\n    Args:\n        target_db (str): The database host address (e.g., \"localhost\" or \"nas923\").\n        client_name (str): The name of the MongoDB client/database.\n        collection_name (str): The name of the collection to retrieve.\n\n    Returns:\n        Collection: The MongoDB collection object.\n    \"\"\"\n    client = pymongo.MongoClient(f\"mongodb://{target_db}:27017/\")\n    db = client[client_name]\n    collection = db[collection_name]\n    return collection\n</code></pre>"},{"location":"mongo/#mongo.mongolog","title":"<code>mongolog(operation, entite, desc)</code>","text":"<p>Enregistre une op\u00e9ration de log dans la collection 'logs' si la configuration autorise les logs.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>L'op\u00e9ration effectu\u00e9e (par exemple, \"insert\", \"update\", \"delete\").</p> required <code>entite</code> <code>str</code> <p>Le nom de l'entit\u00e9 concern\u00e9e.</p> required <code>desc</code> <code>str</code> <p>Une description d\u00e9taill\u00e9e de l'op\u00e9ration.</p> required Source code in <code>nbs/mongo.py</code> <pre><code>def mongolog(operation: str, entite: str, desc: str) -&gt; None:\n    \"\"\"Enregistre une op\u00e9ration de log dans la collection 'logs' si la configuration autorise les logs.\n\n    Args:\n        operation (str): L'op\u00e9ration effectu\u00e9e (par exemple, \"insert\", \"update\", \"delete\").\n        entite (str): Le nom de l'entit\u00e9 concern\u00e9e.\n        desc (str): Une description d\u00e9taill\u00e9e de l'op\u00e9ration.\n    \"\"\"\n    DB_HOST, DB_NAME, DB_LOGS = get_DB_VARS()\n    if DB_LOGS in [\"true\", \"True\"]:\n        coll_logs = get_collection(DB_HOST, DB_NAME, \"logs\")\n        coll_logs.insert_one(\n            {\n                \"operation\": operation,\n                \"entite\": entite,\n                \"desc\": desc,\n                \"date\": datetime.now(),\n            }\n        )\n</code></pre>"},{"location":"mongo/#mongo.print_logs","title":"<code>print_logs(n=10)</code>","text":"<p>Affiche les n derniers logs de la collection 'logs', tri\u00e9s par date d\u00e9croissante.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Le nombre maximum de logs \u00e0 afficher. Par d\u00e9faut \u00e0 10.</p> <code>10</code> Source code in <code>nbs/mongo.py</code> <pre><code>def print_logs(n: int = 10) -&gt; None:\n    \"\"\"Affiche les n derniers logs de la collection 'logs', tri\u00e9s par date d\u00e9croissante.\n\n    Args:\n        n (int, optional): Le nombre maximum de logs \u00e0 afficher. Par d\u00e9faut \u00e0 10.\n    \"\"\"\n    DB_HOST, DB_NAME, DB_LOGS = get_DB_VARS()\n    coll_logs = get_collection(DB_HOST, DB_NAME, \"logs\")\n    for i, log in enumerate(coll_logs.find().sort(\"date\", pymongo.DESCENDING)):\n        if i == n:\n            break\n        print(log)\n</code></pre>"},{"location":"mongo_auteur/","title":"Module mongo_auteur","text":""},{"location":"mongo_auteur/#mongo_auteur.Auteur","title":"<code>Auteur</code>","text":"<p>               Bases: <code>BaseEntity</code></p> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>class Auteur(BaseEntity):\n    collection: str = \"auteurs\"\n\n    def __init__(self, nom: str) -&gt; None:\n        \"\"\"Initialise une instance d'Auteur.\n\n        Args:\n            nom (str): Le nom de l'auteur.\n        \"\"\"\n        super().__init__(nom, self.collection)\n\n    def some_method(self):\n        fmt_date = format_date(self.episode.date, \"%Y/%m/%d\")\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.Auteur.__init__","title":"<code>__init__(nom)</code>","text":"<p>Initialise une instance d'Auteur.</p> <p>Parameters:</p> Name Type Description Default <code>nom</code> <code>str</code> <p>Le nom de l'auteur.</p> required Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def __init__(self, nom: str) -&gt; None:\n    \"\"\"Initialise une instance d'Auteur.\n\n    Args:\n        nom (str): Le nom de l'auteur.\n    \"\"\"\n    super().__init__(nom, self.collection)\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorChecker","title":"<code>AuthorChecker</code>","text":"<p>Class to verify and correct an author's name using multiple data sources.</p> This class verifies an author in an episode through sources including <ul> <li>RSS metadata (title, description)</li> <li>MongoDB database of known authors</li> <li>LLM suggestions</li> <li>Web search analysis</li> </ul> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>class AuthorChecker:\n    \"\"\"Class to verify and correct an author's name using multiple data sources.\n\n    This class verifies an author in an episode through sources including:\n      - RSS metadata (title, description)\n      - MongoDB database of known authors\n      - LLM suggestions\n      - Web search analysis\n    \"\"\"\n\n    def __init__(self, episode: Episode) -&gt; None:\n        \"\"\"Initializes the AuthorChecker with an episode.\n\n        Args:\n            episode (Episode): An episode instance containing title and description.\n        \"\"\"\n        self.episode = episode\n        self.llm_structured_output = get_azure_llm(\"gpt-4o\")\n        self.authors_titre_description = self._get_authors_from_titre_description()\n\n    def _get_filtered_titre_description(self, titre_or_description: str) -&gt; str:\n        \"\"\"Filter the given titre or description to avoid Error 400.\n\n        Filters out substrings that may trigger Azure OpenAI's content management policy (resulting in a 400 error).\n        Specifically, for certain dates, predefined terms are replaced as specified in the filter mapping.\n\n        For more details, see:\n            https://github.com/castorfou/lmelp/issues/21\n\n        Args:\n            titre_or_description (str): 'titre' or 'description'depending on what to filter.\n\n        Returns:\n            str: The filtered titre or description.\n        \"\"\"\n        filtering = {\n            \"2020/11/15\": {\"fossoyeur\": \"rigolo\"},\n        }\n        fmt_date = self.episode.date.strftime(\"%Y/%m/%d\")\n        replacements = filtering.get(fmt_date)\n\n        text = (\n            self.episode.titre\n            if titre_or_description == \"titre\"\n            else self.episode.description\n        )\n        if replacements:\n            for key, value in replacements.items():\n                text = text.replace(key, value)\n        return text\n\n    def _get_authors_from_titre_description(self) -&gt; List[str]:\n        \"\"\"Retrieves a list of author names extracted from the episode title and description using LLM.\n\n        Returns:\n            List[str]: A list of author names extracted from the title and description.\n        \"\"\"\n        response_schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"AuthorTitreDescriptionList\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"Authors_TitreDescription\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\",\n                                \"description\": \"A list of names from title and description\",\n                            },\n                        }\n                    },\n                    \"required\": [\"Authors_TitreDescription\"],\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n        try:\n            titre = self._get_filtered_titre_description(\"titre\")\n            description = self._get_filtered_titre_description(\"description\")\n            response = self.llm_structured_output.chat(\n                messages=[\n                    ChatMessage(\n                        role=\"system\",\n                        content=\"Tu es un assistant utile qui retourne une liste JSON de noms.\",\n                    ),\n                    ChatMessage(\n                        role=\"user\",\n                        content=f\"Est-ce que tu peux me lister tous les noms qui sont cit\u00e9s dans le titre et la description de l'\u00e9pisode suivant : {titre} {description}. \",\n                    ),\n                ],\n                response_format=response_schema,\n            )\n        except Exception as e:\n            print(f\"Error getting authors from titre/description: {e}\")\n            print(f\"prompt: {titre} {description}\")\n            return []\n        try:\n            json_dict = json.loads(response.message.content)\n        except json.JSONDecodeError as e:\n            print(\"Error parsing JSON:\", e)\n            print(\"Raw response:\", response.message.content)\n            return []  # Return an empty list if parsing fails\n        return json_dict[\"Authors_TitreDescription\"]\n\n    def _get_authors_from_llm(self, autor: str) -&gt; List[str]:\n        \"\"\"Queries the LLM to retrieve a list of potential author names based on a provided name.\n\n        Args:\n            autor (str): The author name to query.\n\n        Returns:\n            List[str]: A list of author names suggested by the LLM.\n        \"\"\"\n        response_schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"AuthorList\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"Authors_LLM\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\",\n                                \"description\": \"A list of authors' names\",\n                            },\n                        }\n                    },\n                    \"required\": [\"Authors_LLM\"],\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n\n        prompt = (\n            \"\"\"\n        Tu es un agent expert en litt\u00e9rature.\n        Donne moi quelques auteurs dont le nom s'approche de celui-ci : \"\"\"\n            + autor\n            + \"\"\"\n\n        S'il s'agit deja d'un auteur connu, retourne moi juste son nom. S'il y a une erreur dans le nom que je t'ai donne, corrige moi en me donnant le nom de l'auteur que tu penses que j'ai voulu dire.\n\n        Je veux que tu me donnes le prenom puis le nom dans cet ordre. Par exemple \"Marcel Pagnol\" ou \"Victor Hugo\".\n        Ces auteurs sont susceptibles d'etre discutes dans \"Le Masque et la Plume\".\n\n        Si tu me retournes plusieurs auteurs, fais le sous forme de liste par exemple si tu as identifie \"auteur 1\" et \"auteur 2\" alors retourne [\"auteur 1\", \"auteur 2\"]\n        \"\"\"\n        )\n\n        response = self.llm_structured_output.chat(\n            messages=[\n                ChatMessage(\n                    role=\"system\",\n                    content=\"Tu es un agent litteraire qui connait parfaitement les auteurs.\",\n                ),\n                ChatMessage(role=\"user\", content=f\"{prompt}. \"),\n            ],\n            response_format=response_schema,\n        )\n\n        try:\n            json_dict = json.loads(response.message.content)\n        except json.JSONDecodeError as e:\n            print(\"Error parsing JSON:\", e)\n            print(\"Raw response:\", response.message.content)\n            return []\n        return json_dict[\"Authors_LLM\"]\n\n    def _get_author_from_web(self, author: str) -&gt; Dict[str, Union[str, int]]:\n        \"\"\"Analyzes a Google search result to verify if a given name corresponds to an author.\n\n        Args:\n            author (str): The author name to verify.\n\n        Returns:\n            Dict[str, Union[str, int]]: A dictionary containing:\n                - \"auteur\": The corrected author name if applicable.\n                - \"certitude\": An integer between 0 and 100 indicating the confidence.\n                - \"analyse\": A textual analysis of the Google search query.\n        \"\"\"\n        result_google = google_search(author)\n\n        prompt_incertitude_auteur = f\"\"\"\n        Voici le resultat d'une requete google concernant un probable auteur inconnu de mon llm : {author}\n        La requete est au format dict avec du json a l'interieur.\n        Est-ce que tu peux analyser le contenu de cette requete et me dire si oui ou non {author} est un auteur de livres, \n        et accompagner ta reponse d'un pourcentage de certitude :\n        * 100% de certitude signifie que tu es certain que {author} est un auteur de livres\n        *  50% tu es ni sure ni pas sure que {author} est un auteur de livres\n        *   0% tu es certain que {author} n'est pas un auteur de livres\n\n        Voici le contenu de la requete google : {result_google}\n\n        Tu repondras uniquement avec un dictionnaire qui va contenir 3 entrees :\n\n        - \"auteur\" : le nom de l'auteur, eventuellement corrige si j'ai oublie des accents ou une faute de frappe\n        - \"certitude\" : le pourcentage de certitude de 0 \u00e0 100, un entier\n        - \"analyse\" : une analyse de la requete Google concernant l'auteur.\n        \"\"\"\n        response_schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"AuteurSchema\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"auteur\": {\n                            \"type\": \"string\",\n                            \"description\": \"Le nom de l'auteur \u00e9ventuellement corrig\u00e9 (accents, fautes de frappe).\",\n                        },\n                        \"certitude\": {\n                            \"type\": \"integer\",\n                            \"description\": \"Pourcentage de certitude (0 \u00e0 100).\",\n                            \"minimum\": 0,\n                            \"maximum\": 100,\n                        },\n                        \"analyse\": {\n                            \"type\": \"string\",\n                            \"description\": \"Analyse de la requ\u00eate Google concernant l'auteur.\",\n                        },\n                    },\n                    \"required\": [\"auteur\", \"certitude\", \"analyse\"],\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n\n        response = self.llm_structured_output.chat(\n            messages=[\n                ChatMessage(\n                    role=\"system\",\n                    content=\"Tu es un assistant utile qui analyse des requetes Google pour y deceler si un auteur de livre s'y cache.\",\n                ),\n                ChatMessage(\n                    role=\"user\",\n                    content=prompt_incertitude_auteur,\n                ),\n            ],\n            response_format=response_schema,\n        )\n        try:\n            json_dict = json.loads(response.message.content)\n        except json.JSONDecodeError as e:\n            print(\"Error parsing JSON:\", e)\n            print(\"Raw response:\", response.message.content)\n            return {}\n        return json_dict\n\n    def _check_author_source(\n        self, author: str, authors_list: List[str]\n    ) -&gt; Optional[str]:\n        \"\"\"Determines the best matching author from a provided list using fuzzy matching.\n\n        Args:\n            author (str): The author name to match.\n            authors_list (List[str]): A list of author names to check against.\n\n        Returns:\n            Optional[str]: The best matching author name if the match score is above the threshold, otherwise None.\n        \"\"\"\n        matcher = AuthorFuzzMatcher(authors_list)\n        best_match, score = matcher.find_best_match(author)\n        if score &gt;= score_fuzz_threshold:\n            return best_match\n        else:\n            return None\n\n    def check_author(\n        self, author: str, return_details: bool = False, verbose: bool = False\n    ) -&gt; Union[str, Dict[str, Union[str, int]], None]:\n        \"\"\"Verifies an author's name through various sources and returns the corrected name.\n\n        It checks in the following order:\n          1. RSS metadata (title, description)\n          2. MongoDB list of known authors\n          3. LLM suggested names\n          4. Web search analysis\n\n        Args:\n            author (str): The author name to verify.\n            return_details (bool, optional): If True, returns a detailed dictionary with source and analysis. Defaults to False.\n            verbose (bool, optional): If True, prints debug messages. Defaults to False.\n\n        Returns:\n            Union[str, Dict[str, Union[str, int]], None]: The corrected author name as a string if return_details is False;\n                a detailed dict if return_details is True; or None if no match is found.\n        \"\"\"\n        details = {\"author_original\": author, \"author_corrected\": None, \"source\": None}\n\n        # 1. V\u00e9rification dans rss:metadata (titre, description)\n        match = self._check_author_source(author, self.authors_titre_description)\n        if match:\n            details[\"author_corrected\"] = match\n            details[\"source\"] = \"rss:metadata\"\n            if verbose:\n                print(f\"Trouv\u00e9 avec rss:metadata: {match}\")\n            return details if return_details else match\n\n        # 2. V\u00e9rification dans la base de donn\u00e9es (mongodb:auteurs)\n        list_db_auteurs = [auteur.nom for auteur in Auteur.get_entries()]\n        match = self._check_author_source(author, list_db_auteurs)\n        if match:\n            details[\"author_corrected\"] = match\n            details[\"source\"] = \"mongodb:auteurs\"\n            if verbose:\n                print(f\"Trouv\u00e9 avec mongodb:auteurs: {match}\")\n            return details if return_details else match\n\n        # 3. V\u00e9rification via llm\n        list_llm_auteurs = self._get_authors_from_llm(author)\n        match = self._check_author_source(author, list_llm_auteurs)\n        if match:\n            details[\"author_corrected\"] = match\n            details[\"source\"] = \"llm\"\n            if verbose:\n                print(f\"Trouv\u00e9 avec llm: {match}\")\n            return details if return_details else match\n\n        # 4. V\u00e9rification via web search\n        web_result_dict = self._get_author_from_web(author)\n        match = web_result_dict.get(\"auteur\")\n        score = web_result_dict.get(\"certitude\", 0)\n        details.update(\n            {\n                \"author_corrected\": match,\n                \"score\": score,\n                \"analyse\": web_result_dict.get(\"analyse\", \"\"),\n                \"source\": \"web search\",\n            }\n        )\n        if score &gt;= score_fuzz_threshold:\n            if verbose:\n                print(f\"Trouv\u00e9 avec web search: {match}\")\n            return details if return_details else match\n        else:\n            if verbose:\n                print(\n                    f\"Score insuffisant {score} avec web search: {web_result_dict.get('analyse', '')}\"\n                )\n            details[\"author_corrected\"] = None\n            return details if return_details else None\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorChecker.__init__","title":"<code>__init__(episode)</code>","text":"<p>Initializes the AuthorChecker with an episode.</p> <p>Parameters:</p> Name Type Description Default <code>episode</code> <code>Episode</code> <p>An episode instance containing title and description.</p> required Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def __init__(self, episode: Episode) -&gt; None:\n    \"\"\"Initializes the AuthorChecker with an episode.\n\n    Args:\n        episode (Episode): An episode instance containing title and description.\n    \"\"\"\n    self.episode = episode\n    self.llm_structured_output = get_azure_llm(\"gpt-4o\")\n    self.authors_titre_description = self._get_authors_from_titre_description()\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorChecker.check_author","title":"<code>check_author(author, return_details=False, verbose=False)</code>","text":"<p>Verifies an author's name through various sources and returns the corrected name.</p> It checks in the following order <ol> <li>RSS metadata (title, description)</li> <li>MongoDB list of known authors</li> <li>LLM suggested names</li> <li>Web search analysis</li> </ol> <p>Parameters:</p> Name Type Description Default <code>author</code> <code>str</code> <p>The author name to verify.</p> required <code>return_details</code> <code>bool</code> <p>If True, returns a detailed dictionary with source and analysis. Defaults to False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, prints debug messages. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[str, Dict[str, Union[str, int]], None]</code> <p>Union[str, Dict[str, Union[str, int]], None]: The corrected author name as a string if return_details is False; a detailed dict if return_details is True; or None if no match is found.</p> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def check_author(\n    self, author: str, return_details: bool = False, verbose: bool = False\n) -&gt; Union[str, Dict[str, Union[str, int]], None]:\n    \"\"\"Verifies an author's name through various sources and returns the corrected name.\n\n    It checks in the following order:\n      1. RSS metadata (title, description)\n      2. MongoDB list of known authors\n      3. LLM suggested names\n      4. Web search analysis\n\n    Args:\n        author (str): The author name to verify.\n        return_details (bool, optional): If True, returns a detailed dictionary with source and analysis. Defaults to False.\n        verbose (bool, optional): If True, prints debug messages. Defaults to False.\n\n    Returns:\n        Union[str, Dict[str, Union[str, int]], None]: The corrected author name as a string if return_details is False;\n            a detailed dict if return_details is True; or None if no match is found.\n    \"\"\"\n    details = {\"author_original\": author, \"author_corrected\": None, \"source\": None}\n\n    # 1. V\u00e9rification dans rss:metadata (titre, description)\n    match = self._check_author_source(author, self.authors_titre_description)\n    if match:\n        details[\"author_corrected\"] = match\n        details[\"source\"] = \"rss:metadata\"\n        if verbose:\n            print(f\"Trouv\u00e9 avec rss:metadata: {match}\")\n        return details if return_details else match\n\n    # 2. V\u00e9rification dans la base de donn\u00e9es (mongodb:auteurs)\n    list_db_auteurs = [auteur.nom for auteur in Auteur.get_entries()]\n    match = self._check_author_source(author, list_db_auteurs)\n    if match:\n        details[\"author_corrected\"] = match\n        details[\"source\"] = \"mongodb:auteurs\"\n        if verbose:\n            print(f\"Trouv\u00e9 avec mongodb:auteurs: {match}\")\n        return details if return_details else match\n\n    # 3. V\u00e9rification via llm\n    list_llm_auteurs = self._get_authors_from_llm(author)\n    match = self._check_author_source(author, list_llm_auteurs)\n    if match:\n        details[\"author_corrected\"] = match\n        details[\"source\"] = \"llm\"\n        if verbose:\n            print(f\"Trouv\u00e9 avec llm: {match}\")\n        return details if return_details else match\n\n    # 4. V\u00e9rification via web search\n    web_result_dict = self._get_author_from_web(author)\n    match = web_result_dict.get(\"auteur\")\n    score = web_result_dict.get(\"certitude\", 0)\n    details.update(\n        {\n            \"author_corrected\": match,\n            \"score\": score,\n            \"analyse\": web_result_dict.get(\"analyse\", \"\"),\n            \"source\": \"web search\",\n        }\n    )\n    if score &gt;= score_fuzz_threshold:\n        if verbose:\n            print(f\"Trouv\u00e9 avec web search: {match}\")\n        return details if return_details else match\n    else:\n        if verbose:\n            print(\n                f\"Score insuffisant {score} avec web search: {web_result_dict.get('analyse', '')}\"\n            )\n        details[\"author_corrected\"] = None\n        return details if return_details else None\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorFuzzMatcher","title":"<code>AuthorFuzzMatcher</code>","text":"Source code in <code>nbs/mongo_auteur.py</code> <pre><code>class AuthorFuzzMatcher:\n    def __init__(self, reference_authors: Optional[List[str]] = None) -&gt; None:\n        \"\"\"Initializes an AuthorFuzzMatcher with a list of known author names.\n\n        Args:\n            reference_authors (Optional[List[str]]): A list of known author names. Defaults to None.\n        \"\"\"\n        self.reference_authors = set(reference_authors) if reference_authors else set()\n\n    def add_reference_author(self, author: str) -&gt; None:\n        \"\"\"Adds a new reference author to the set.\n\n        Args:\n            author (str): The author name to be added.\n        \"\"\"\n        self.reference_authors.add(author.strip())\n\n    def find_best_match(\n        self, name: str, min_score: int = 80\n    ) -&gt; Tuple[Optional[str], int]:\n        \"\"\"Finds the best matching reference author for a given name using token set ratio.\n\n        Args:\n            name (str): The name to match against the reference authors.\n            min_score (int, optional): The minimal score required for a match. Defaults to 80.\n\n        Returns:\n            Tuple[Optional[str], int]: A tuple with the best matching author's name (or None if no match satisfies the minimum score) and the matching score.\n        \"\"\"\n        if not name or not self.reference_authors:\n            return None, 0\n        best_match, score = process.extractOne(\n            name, self.reference_authors, scorer=fuzz.token_set_ratio\n        )\n        if score &gt;= min_score:\n            return best_match, score\n        return None, score\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorFuzzMatcher.__init__","title":"<code>__init__(reference_authors=None)</code>","text":"<p>Initializes an AuthorFuzzMatcher with a list of known author names.</p> <p>Parameters:</p> Name Type Description Default <code>reference_authors</code> <code>Optional[List[str]]</code> <p>A list of known author names. Defaults to None.</p> <code>None</code> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def __init__(self, reference_authors: Optional[List[str]] = None) -&gt; None:\n    \"\"\"Initializes an AuthorFuzzMatcher with a list of known author names.\n\n    Args:\n        reference_authors (Optional[List[str]]): A list of known author names. Defaults to None.\n    \"\"\"\n    self.reference_authors = set(reference_authors) if reference_authors else set()\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorFuzzMatcher.add_reference_author","title":"<code>add_reference_author(author)</code>","text":"<p>Adds a new reference author to the set.</p> <p>Parameters:</p> Name Type Description Default <code>author</code> <code>str</code> <p>The author name to be added.</p> required Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def add_reference_author(self, author: str) -&gt; None:\n    \"\"\"Adds a new reference author to the set.\n\n    Args:\n        author (str): The author name to be added.\n    \"\"\"\n    self.reference_authors.add(author.strip())\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.AuthorFuzzMatcher.find_best_match","title":"<code>find_best_match(name, min_score=80)</code>","text":"<p>Finds the best matching reference author for a given name using token set ratio.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to match against the reference authors.</p> required <code>min_score</code> <code>int</code> <p>The minimal score required for a match. Defaults to 80.</p> <code>80</code> <p>Returns:</p> Type Description <code>Tuple[Optional[str], int]</code> <p>Tuple[Optional[str], int]: A tuple with the best matching author's name (or None if no match satisfies the minimum score) and the matching score.</p> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def find_best_match(\n    self, name: str, min_score: int = 80\n) -&gt; Tuple[Optional[str], int]:\n    \"\"\"Finds the best matching reference author for a given name using token set ratio.\n\n    Args:\n        name (str): The name to match against the reference authors.\n        min_score (int, optional): The minimal score required for a match. Defaults to 80.\n\n    Returns:\n        Tuple[Optional[str], int]: A tuple with the best matching author's name (or None if no match satisfies the minimum score) and the matching score.\n    \"\"\"\n    if not name or not self.reference_authors:\n        return None, 0\n    best_match, score = process.extractOne(\n        name, self.reference_authors, scorer=fuzz.token_set_ratio\n    )\n    if score &gt;= min_score:\n        return best_match, score\n    return None, score\n</code></pre>"},{"location":"mongo_auteur/#mongo_auteur.google_search","title":"<code>google_search(query)</code>","text":"<p>Effectue une recherche Google en utilisant l'API Custom Search et retourne les r\u00e9sultats.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>La requ\u00eate de recherche.</p> required <p>Returns:</p> Type Description <code>Optional[List[Dict[str, Optional[str]]]]</code> <p>Optional[List[Dict[str, Optional[str]]]]: Une liste de dictionnaires repr\u00e9sentant les r\u00e9sultats de la recherche, chaque dictionnaire contenant les cl\u00e9s 'title', 'snippet' et 'link'. Retourne None en cas d'erreur.</p> <p>Raises:     ValueError: Si les variables d'environnement GOOGLE_CUSTOM_SEARCH_API_KEY ou SEARCH_ENGINE_ID                 ne sont pas d\u00e9finies.</p> Source code in <code>nbs/mongo_auteur.py</code> <pre><code>def google_search(query: str) -&gt; Optional[List[Dict[str, Optional[str]]]]:\n    \"\"\"Effectue une recherche Google en utilisant l'API Custom Search et retourne les r\u00e9sultats.\n\n    Args:\n        query (str): La requ\u00eate de recherche.\n\n    Returns:\n        Optional[List[Dict[str, Optional[str]]]]:\n            Une liste de dictionnaires repr\u00e9sentant les r\u00e9sultats de la recherche, chaque dictionnaire contenant\n            les cl\u00e9s 'title', 'snippet' et 'link'. Retourne None en cas d'erreur.\n    Raises:\n        ValueError: Si les variables d'environnement GOOGLE_CUSTOM_SEARCH_API_KEY ou SEARCH_ENGINE_ID\n                    ne sont pas d\u00e9finies.\n    \"\"\"\n    if not api_key or not cse_id:\n        raise ValueError(\n            \"Les variables d'environnement GOOGLE_CUSTOM_SEARCH_API_KEY et SEARCH_ENGINE_ID doivent \u00eatre d\u00e9finies pour utiliser la recherche Google.\"\n        )\n    try:\n        service = build(\"customsearch\", \"v1\", developerKey=api_key)\n        res = service.cse().list(q=query, cx=cse_id).execute()\n\n        results: List[Dict[str, Optional[str]]] = []\n        for item in res.get(\"items\", []):\n            title: Optional[str] = item.get(\"title\")\n            snippet: Optional[str] = item.get(\"snippet\")\n            link: Optional[str] = item.get(\"link\")\n            results.append({\"title\": title, \"snippet\": snippet, \"link\": link})\n        return results\n    except Exception as e:\n        print(f\"Erreur lors de la recherche Google: {e}\")\n        return None\n</code></pre>"},{"location":"mongo_episode/","title":"Module mongo_episode","text":""},{"location":"mongo_episode/#mongo_episode.Episode","title":"<code>Episode</code>","text":"Source code in <code>nbs/mongo_episode.py</code> <pre><code>class Episode:\n    def __init__(\n        self, date: str, titre: str, collection_name: str = \"episodes\"\n    ) -&gt; None:\n        \"\"\"Initialise une instance d'Episode.\n\n        Args:\n            date (str): La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\" conforme \u00e0 DATE_FORMAT.\n            titre (str): Le titre de l'\u00e9pisode.\n            collection_name (str, optional): Le nom de la collection dans la base de donn\u00e9es. D\u00e9faut: \"episodes\".\n\n        Notes:\n            Si l'\u00e9pisode existe d\u00e9j\u00e0 en base, ses attributs seront charg\u00e9s.\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        self.collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n        )\n        self.date: datetime = Episode.get_date_from_string(date)\n        self.titre: str = titre\n\n        if self.exists():\n            episode = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n            self.description: Optional[str] = episode.get(\"description\")\n            self.url_telechargement: Optional[str] = episode.get(\"url\")\n            self.audio_rel_filename: Optional[str] = episode.get(\"audio_rel_filename\")\n            self.transcription: Optional[str] = episode.get(\"transcription\")\n            self.type: Optional[str] = episode.get(\"type\")\n            self.duree: int = episode.get(\"duree\", -1)\n            self.masked: bool = episode.get(\"masked\", False)\n        else:\n            self.description = None\n            self.url_telechargement = None\n            self.audio_rel_filename = None\n            self.transcription = None\n            self.type = None\n            self.duree = -1  # en secondes\n            self.masked = False\n\n    @classmethod\n    def from_oid(cls, oid: ObjectId, collection_name: str = \"episodes\") -&gt; \"Episode\":\n        \"\"\"Cr\u00e9e un \u00e9pisode \u00e0 partir d'un ObjectId dans la base de donn\u00e9es.\n\n        Args:\n            oid (ObjectId): L'identifiant de l'\u00e9pisode dans Mongo.\n            collection_name (str, optional): Le nom de la collection. D\u00e9faut: \"episodes\".\n\n        Returns:\n            Episode: L'instance d'Episode correspondante.\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n        )\n        document = collection.find_one({\"_id\": oid})\n        date_doc_str = cls.get_string_from_date(document.get(\"date\"), DATE_FORMAT)\n        instance = cls(date=date_doc_str, titre=document.get(\"titre\"))\n        return instance\n\n    @classmethod\n    def from_date(\n        cls, date: datetime, collection_name: str = \"episodes\"\n    ) -&gt; Optional[\"Episode\"]:\n        \"\"\"Cr\u00e9e un \u00e9pisode \u00e0 partir d'une date dans la base de donn\u00e9es.\n\n        Args:\n            date (datetime): La date recherch\u00e9e.\n            collection_name (str, optional): Le nom de la collection. D\u00e9faut: \"episodes\".\n\n        Returns:\n            Optional[Episode]: L'instance d'Episode si trouv\u00e9e, sinon None.\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n        )\n        start_date = datetime(date.year, date.month, date.day)\n        end_date = datetime(date.year, date.month, date.day, 23, 59, 59)\n        document = collection.find_one({\"date\": {\"$gte\": start_date, \"$lte\": end_date}})\n        if document:\n            date_doc_str = cls.get_string_from_date(document.get(\"date\"), DATE_FORMAT)\n            instance = cls(date=date_doc_str, titre=document.get(\"titre\"))\n            return instance\n        else:\n            return None\n\n    def exists(self) -&gt; bool:\n        \"\"\"V\u00e9rifie si l'\u00e9pisode existe dans la base de donn\u00e9es.\n\n        Returns:\n            bool: True si l'\u00e9pisode existe, False sinon.\n        \"\"\"\n        return (\n            self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n            is not None\n        )\n\n    def keep(self) -&gt; int:\n        \"\"\"T\u00e9l\u00e9charge le fichier audio si n\u00e9cessaire et conserve l'\u00e9pisode dans la base de donn\u00e9es.\n\n        Returns:\n            int: 1 si une nouvelle entr\u00e9e est cr\u00e9\u00e9e en base, 0 sinon.\n        \"\"\"\n        message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n        if not self.exists():\n            print(\n                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} nouveau: Duree: {self.duree}, Type: {self.type}\"\n            )\n            mongolog(\"insert\", self.collection.name, message_log)\n            self.download_audio(verbose=True)\n            self.collection.insert_one(\n                {\n                    \"titre\": self.titre,\n                    \"date\": self.date,\n                    \"description\": self.description,\n                    \"url\": self.url_telechargement,\n                    \"audio_rel_filename\": self.audio_rel_filename,\n                    \"transcription\": self.transcription,\n                    \"type\": self.type,\n                    \"duree\": self.duree,\n                    \"masked\": self.masked,\n                }\n            )\n            return 1\n        else:\n            print(\n                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} deja existant\"\n            )\n            mongolog(\"update\", self.collection.name, message_log)\n            return 0\n\n    def update_date(self, new_date: datetime) -&gt; None:\n        \"\"\"Met \u00e0 jour la date de l'\u00e9pisode dans la base de donn\u00e9es.\n\n        Args:\n            new_date (datetime): La nouvelle date de l'\u00e9pisode.\n        \"\"\"\n        self.collection.update_one(\n            {\"_id\": self.get_oid()}, {\"$set\": {\"date\": new_date}}\n        )\n        message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre} -&gt; {Episode.get_string_from_date(new_date, format=LOG_DATE_FORMAT)}\"\n        self.date = new_date\n        mongolog(\"force_update\", self.collection.name, message_log)\n\n    def remove(self) -&gt; None:\n        \"\"\"Supprime l'\u00e9pisode de la base de donn\u00e9es.\"\"\"\n        message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n        self.collection.delete_one({\"titre\": self.titre, \"date\": self.date})\n        mongolog(\"delete\", self.collection.name, message_log)\n\n    def get_oid(self) -&gt; Optional[ObjectId]:\n        \"\"\"R\u00e9cup\u00e8re l'identifiant Mongo (_id) de l'\u00e9pisode.\n\n        Returns:\n            Optional[ObjectId]: L'ObjectId de l'\u00e9pisode s'il existe, sinon None.\n        \"\"\"\n        document = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n        if document:\n            return document[\"_id\"]\n        else:\n            return None\n\n    @staticmethod\n    def get_date_from_string(date: str, DATE_FORMAT: str = DATE_FORMAT) -&gt; datetime:\n        \"\"\"Convertit une cha\u00eene de caract\u00e8res en objet datetime.\n\n        Args:\n            date (str): La cha\u00eene repr\u00e9sentant la date.\n            DATE_FORMAT (str, optional): Le format de la date. D\u00e9faut est DATE_FORMAT.\n\n        Returns:\n            datetime: L'objet datetime correspondant.\n        \"\"\"\n        return datetime.strptime(date, DATE_FORMAT)\n\n    @staticmethod\n    def get_string_from_date(date: datetime, format: Optional[str] = None) -&gt; str:\n        \"\"\"Convertit un objet datetime en cha\u00eene de caract\u00e8res.\n\n        Args:\n            date (datetime): L'objet datetime.\n            format (Optional[str], optional): Le format de sortie. Si None, DATE_FORMAT est utilis\u00e9.\n\n        Returns:\n            str: La cha\u00eene repr\u00e9sentant la date.\n        \"\"\"\n        if format is not None:\n            return date.strftime(format)\n        else:\n            return date.strftime(DATE_FORMAT)\n\n    @staticmethod\n    def format_duration(seconds: int) -&gt; str:\n        \"\"\"Convertit une dur\u00e9e en secondes au format HH:MM:SS.\n\n        Args:\n            seconds (int): La dur\u00e9e en secondes.\n\n        Returns:\n            str: La dur\u00e9e format\u00e9e en cha\u00eene de caract\u00e8res.\n        \"\"\"\n        if seconds &lt; 0:\n            return f\"-{Episode.format_duration(-seconds)}\"\n        hours = seconds // 3600\n        minutes = (seconds % 3600) // 60\n        seconds = seconds % 60\n        return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Renvoie une repr\u00e9sentation textuelle de l'\u00e9pisode.\n\n        Returns:\n            str: Les informations de l'\u00e9pisode sous forme de cha\u00eene de caract\u00e8res.\n        \"\"\"\n        return (\n            f\"_oid: {self.get_oid()}\\n\"\n            f\"Date: {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)}\\n\"\n            f\"Titre: {self.titre}\\n\"\n            f\"Description: {self.description}\\n\"\n            f\"URL de t\u00e9l\u00e9chargement: {self.url_telechargement}\\n\"\n            f\"Fichier audio: {self.audio_rel_filename}\\n\"\n            f\"Duree: {self.duree} en secondes ({Episode.format_duration(self.duree)})\\n\"\n            f\"Transcription: {self.transcription[:100] if self.transcription else 'No transcription yet available'}...\"\n        )\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Renvoie une repr\u00e9sentation officielle de l'objet.\n\n        Returns:\n            str: La repr\u00e9sentation de l'objet (\u00e9quivalente \u00e0 __str__).\n        \"\"\"\n        return self.__str__()\n\n    def download_audio(self, verbose: bool = False) -&gt; None:\n        \"\"\"T\u00e9l\u00e9charge le fichier audio \u00e0 partir de l'URL de t\u00e9l\u00e9chargement et le sauvegarde localement.\n\n        Args:\n            verbose (bool, optional): Si True, affiche des messages d'information. D\u00e9faut False.\n        \"\"\"\n        if self.url_telechargement is None:\n            return\n        year = str(self.date.year)\n        full_audio_path = get_audio_path(AUDIO_PATH, year)\n        full_filename = os.path.join(\n            full_audio_path, os.path.basename(self.url_telechargement)\n        )\n        self.audio_rel_filename = os.path.relpath(\n            full_filename, get_audio_path(AUDIO_PATH, year=\"\")\n        )\n        if not os.path.exists(full_filename):\n            if verbose:\n                print(\n                    f\"T\u00e9l\u00e9chargement de {self.url_telechargement} vers {full_filename}\"\n                )\n            response = requests.get(self.url_telechargement)\n            with open(full_filename, \"wb\") as file:\n                file.write(response.content)\n        else:\n            if verbose:\n                print(f\"Le fichier {full_filename} existe d\u00e9j\u00e0. Ignor\u00e9.\")\n\n    def set_transcription(self, verbose: bool = False, keep_cache: bool = True) -&gt; None:\n        \"\"\"Extrait et sauvegarde la transcription de l'audio en utilisant un mod\u00e8le Whisper.\n\n        Utilise le cache si disponible ou extrait la transcription de l'audio.\n\n        Args:\n            verbose (bool, optional): Si True, affiche des messages d'information. D\u00e9faut False.\n            keep_cache (bool, optional): Si True, sauvegarde la transcription dans un fichier cache. D\u00e9faut True.\n        \"\"\"\n        if self.transcription is not None:\n            if verbose:\n                print(\"Transcription existe deja\")\n            return\n        mp3_fullfilename = get_audio_path(AUDIO_PATH, year=\"\") + self.audio_rel_filename\n        cache_transcription_filename = f\"{os.path.splitext(mp3_fullfilename)[0]}.txt\"\n        if os.path.exists(cache_transcription_filename):\n            if verbose:\n                print(f\"Transcription cachee trouvee: {cache_transcription_filename}\")\n            with open(cache_transcription_filename, \"r\") as file:\n                self.transcription = file.read()\n            self.collection.update_one(\n                {\"_id\": self.get_oid()},\n                {\"$set\": {\"transcription\": self.transcription}},\n            )\n            return\n\n        self.transcription = extract_whisper(mp3_fullfilename)\n        if keep_cache:\n            with open(cache_transcription_filename, \"w\") as f:\n                f.write(self.transcription)\n        self.collection.update_one(\n            {\"_id\": self.get_oid()}, {\"$set\": {\"transcription\": self.transcription}}\n        )\n\n    def to_dict(self) -&gt; Dict[str, Union[str, datetime, int, None, bool]]:\n        \"\"\"Convertit l'\u00e9pisode en dictionnaire.\n\n        Returns:\n            Dict[str, Union[str, datetime, int, None, bool]]: Dictionnaire contenant les informations de l'\u00e9pisode.\n                Les cl\u00e9s sont ['date', 'titre', 'description', 'url_telechargement', 'audio_rel_filename', 'transcription', 'type', 'duree', 'masked'].\n        \"\"\"\n        return {\n            \"date\": self.date,\n            \"titre\": self.titre,\n            \"description\": self.description,\n            \"url_telechargement\": self.url_telechargement,\n            \"audio_rel_filename\": self.audio_rel_filename,\n            \"transcription\": self.transcription,\n            \"type\": self.type,\n            \"duree\": self.duree,\n            \"masked\": self.masked,\n        }\n\n    def get_all_auteurs(self) -&gt; List[str]:\n        \"\"\"Extrait la liste de tous les auteurs mentionn\u00e9s dans la transcription.\n\n        Notes:\n            Utilise le mod\u00e8le GPT-4 via Azure LLM pour extraire une liste JSON de noms d'auteurs.\n\n        Returns:\n            List[str]: La liste des auteurs d\u00e9tect\u00e9s.\n        \"\"\"\n        if self.transcription is None:\n            return []\n\n        llm_structured_output = get_azure_llm(\"gpt-4o\")\n        response_schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"AuthorList\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"Authors\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\",\n                                \"description\": \"Une liste des auteurs extraits de la transcription\",\n                            },\n                        }\n                    },\n                    \"required\": [\"Authors\"],\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n        response = llm_structured_output.chat(\n            messages=[\n                ChatMessage(\n                    role=\"system\",\n                    content=\"Tu es un assistant utile qui retourne une liste JSON de noms d'auteurs.\",\n                ),\n                ChatMessage(\n                    role=\"user\",\n                    content=f\"Est-ce que tu peux me lister tous les noms d'auteurs dont on parle des oeuvres \\\ndans cette transcription d'un \u00e9pisode du masque et la plume \\\ndiffuse le {self.date.strftime('%d %b %Y')}. \\\nJe veux toujours avoir le pr\u00e9nom et le nom complet de chaque auteur. \\\nVoici cette transcription : {self.transcription} \",\n                ),\n            ],\n            response_format=response_schema,\n        )\n        try:\n            json_dict = json.loads(response.message.content)\n        except json.JSONDecodeError as e:\n            print(\"Error parsing JSON:\", e)\n            print(\"Raw response:\", response.message.content)\n            return []\n        return json_dict[\"Authors\"]\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.__init__","title":"<code>__init__(date, titre, collection_name='episodes')</code>","text":"<p>Initialise une instance d'Episode.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>str</code> <p>La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\" conforme \u00e0 DATE_FORMAT.</p> required <code>titre</code> <code>str</code> <p>Le titre de l'\u00e9pisode.</p> required <code>collection_name</code> <code>str</code> <p>Le nom de la collection dans la base de donn\u00e9es. D\u00e9faut: \"episodes\".</p> <code>'episodes'</code> Notes <p>Si l'\u00e9pisode existe d\u00e9j\u00e0 en base, ses attributs seront charg\u00e9s.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __init__(\n    self, date: str, titre: str, collection_name: str = \"episodes\"\n) -&gt; None:\n    \"\"\"Initialise une instance d'Episode.\n\n    Args:\n        date (str): La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\" conforme \u00e0 DATE_FORMAT.\n        titre (str): Le titre de l'\u00e9pisode.\n        collection_name (str, optional): Le nom de la collection dans la base de donn\u00e9es. D\u00e9faut: \"episodes\".\n\n    Notes:\n        Si l'\u00e9pisode existe d\u00e9j\u00e0 en base, ses attributs seront charg\u00e9s.\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    self.collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n    )\n    self.date: datetime = Episode.get_date_from_string(date)\n    self.titre: str = titre\n\n    if self.exists():\n        episode = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n        self.description: Optional[str] = episode.get(\"description\")\n        self.url_telechargement: Optional[str] = episode.get(\"url\")\n        self.audio_rel_filename: Optional[str] = episode.get(\"audio_rel_filename\")\n        self.transcription: Optional[str] = episode.get(\"transcription\")\n        self.type: Optional[str] = episode.get(\"type\")\n        self.duree: int = episode.get(\"duree\", -1)\n        self.masked: bool = episode.get(\"masked\", False)\n    else:\n        self.description = None\n        self.url_telechargement = None\n        self.audio_rel_filename = None\n        self.transcription = None\n        self.type = None\n        self.duree = -1  # en secondes\n        self.masked = False\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.__repr__","title":"<code>__repr__()</code>","text":"<p>Renvoie une repr\u00e9sentation officielle de l'objet.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>La repr\u00e9sentation de l'objet (\u00e9quivalente \u00e0 str).</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Renvoie une repr\u00e9sentation officielle de l'objet.\n\n    Returns:\n        str: La repr\u00e9sentation de l'objet (\u00e9quivalente \u00e0 __str__).\n    \"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.__str__","title":"<code>__str__()</code>","text":"<p>Renvoie une repr\u00e9sentation textuelle de l'\u00e9pisode.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Les informations de l'\u00e9pisode sous forme de cha\u00eene de caract\u00e8res.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Renvoie une repr\u00e9sentation textuelle de l'\u00e9pisode.\n\n    Returns:\n        str: Les informations de l'\u00e9pisode sous forme de cha\u00eene de caract\u00e8res.\n    \"\"\"\n    return (\n        f\"_oid: {self.get_oid()}\\n\"\n        f\"Date: {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)}\\n\"\n        f\"Titre: {self.titre}\\n\"\n        f\"Description: {self.description}\\n\"\n        f\"URL de t\u00e9l\u00e9chargement: {self.url_telechargement}\\n\"\n        f\"Fichier audio: {self.audio_rel_filename}\\n\"\n        f\"Duree: {self.duree} en secondes ({Episode.format_duration(self.duree)})\\n\"\n        f\"Transcription: {self.transcription[:100] if self.transcription else 'No transcription yet available'}...\"\n    )\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.download_audio","title":"<code>download_audio(verbose=False)</code>","text":"<p>T\u00e9l\u00e9charge le fichier audio \u00e0 partir de l'URL de t\u00e9l\u00e9chargement et le sauvegarde localement.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Si True, affiche des messages d'information. D\u00e9faut False.</p> <code>False</code> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def download_audio(self, verbose: bool = False) -&gt; None:\n    \"\"\"T\u00e9l\u00e9charge le fichier audio \u00e0 partir de l'URL de t\u00e9l\u00e9chargement et le sauvegarde localement.\n\n    Args:\n        verbose (bool, optional): Si True, affiche des messages d'information. D\u00e9faut False.\n    \"\"\"\n    if self.url_telechargement is None:\n        return\n    year = str(self.date.year)\n    full_audio_path = get_audio_path(AUDIO_PATH, year)\n    full_filename = os.path.join(\n        full_audio_path, os.path.basename(self.url_telechargement)\n    )\n    self.audio_rel_filename = os.path.relpath(\n        full_filename, get_audio_path(AUDIO_PATH, year=\"\")\n    )\n    if not os.path.exists(full_filename):\n        if verbose:\n            print(\n                f\"T\u00e9l\u00e9chargement de {self.url_telechargement} vers {full_filename}\"\n            )\n        response = requests.get(self.url_telechargement)\n        with open(full_filename, \"wb\") as file:\n            file.write(response.content)\n    else:\n        if verbose:\n            print(f\"Le fichier {full_filename} existe d\u00e9j\u00e0. Ignor\u00e9.\")\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.exists","title":"<code>exists()</code>","text":"<p>V\u00e9rifie si l'\u00e9pisode existe dans la base de donn\u00e9es.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True si l'\u00e9pisode existe, False sinon.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def exists(self) -&gt; bool:\n    \"\"\"V\u00e9rifie si l'\u00e9pisode existe dans la base de donn\u00e9es.\n\n    Returns:\n        bool: True si l'\u00e9pisode existe, False sinon.\n    \"\"\"\n    return (\n        self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n        is not None\n    )\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.format_duration","title":"<code>format_duration(seconds)</code>  <code>staticmethod</code>","text":"<p>Convertit une dur\u00e9e en secondes au format HH:MM:SS.</p> <p>Parameters:</p> Name Type Description Default <code>seconds</code> <code>int</code> <p>La dur\u00e9e en secondes.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>La dur\u00e9e format\u00e9e en cha\u00eene de caract\u00e8res.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@staticmethod\ndef format_duration(seconds: int) -&gt; str:\n    \"\"\"Convertit une dur\u00e9e en secondes au format HH:MM:SS.\n\n    Args:\n        seconds (int): La dur\u00e9e en secondes.\n\n    Returns:\n        str: La dur\u00e9e format\u00e9e en cha\u00eene de caract\u00e8res.\n    \"\"\"\n    if seconds &lt; 0:\n        return f\"-{Episode.format_duration(-seconds)}\"\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.from_date","title":"<code>from_date(date, collection_name='episodes')</code>  <code>classmethod</code>","text":"<p>Cr\u00e9e un \u00e9pisode \u00e0 partir d'une date dans la base de donn\u00e9es.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>datetime</code> <p>La date recherch\u00e9e.</p> required <code>collection_name</code> <code>str</code> <p>Le nom de la collection. D\u00e9faut: \"episodes\".</p> <code>'episodes'</code> <p>Returns:</p> Type Description <code>Optional[Episode]</code> <p>Optional[Episode]: L'instance d'Episode si trouv\u00e9e, sinon None.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@classmethod\ndef from_date(\n    cls, date: datetime, collection_name: str = \"episodes\"\n) -&gt; Optional[\"Episode\"]:\n    \"\"\"Cr\u00e9e un \u00e9pisode \u00e0 partir d'une date dans la base de donn\u00e9es.\n\n    Args:\n        date (datetime): La date recherch\u00e9e.\n        collection_name (str, optional): Le nom de la collection. D\u00e9faut: \"episodes\".\n\n    Returns:\n        Optional[Episode]: L'instance d'Episode si trouv\u00e9e, sinon None.\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n    )\n    start_date = datetime(date.year, date.month, date.day)\n    end_date = datetime(date.year, date.month, date.day, 23, 59, 59)\n    document = collection.find_one({\"date\": {\"$gte\": start_date, \"$lte\": end_date}})\n    if document:\n        date_doc_str = cls.get_string_from_date(document.get(\"date\"), DATE_FORMAT)\n        instance = cls(date=date_doc_str, titre=document.get(\"titre\"))\n        return instance\n    else:\n        return None\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.from_oid","title":"<code>from_oid(oid, collection_name='episodes')</code>  <code>classmethod</code>","text":"<p>Cr\u00e9e un \u00e9pisode \u00e0 partir d'un ObjectId dans la base de donn\u00e9es.</p> <p>Parameters:</p> Name Type Description Default <code>oid</code> <code>ObjectId</code> <p>L'identifiant de l'\u00e9pisode dans Mongo.</p> required <code>collection_name</code> <code>str</code> <p>Le nom de la collection. D\u00e9faut: \"episodes\".</p> <code>'episodes'</code> <p>Returns:</p> Name Type Description <code>Episode</code> <code>Episode</code> <p>L'instance d'Episode correspondante.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@classmethod\ndef from_oid(cls, oid: ObjectId, collection_name: str = \"episodes\") -&gt; \"Episode\":\n    \"\"\"Cr\u00e9e un \u00e9pisode \u00e0 partir d'un ObjectId dans la base de donn\u00e9es.\n\n    Args:\n        oid (ObjectId): L'identifiant de l'\u00e9pisode dans Mongo.\n        collection_name (str, optional): Le nom de la collection. D\u00e9faut: \"episodes\".\n\n    Returns:\n        Episode: L'instance d'Episode correspondante.\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n    )\n    document = collection.find_one({\"_id\": oid})\n    date_doc_str = cls.get_string_from_date(document.get(\"date\"), DATE_FORMAT)\n    instance = cls(date=date_doc_str, titre=document.get(\"titre\"))\n    return instance\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.get_all_auteurs","title":"<code>get_all_auteurs()</code>","text":"<p>Extrait la liste de tous les auteurs mentionn\u00e9s dans la transcription.</p> Notes <p>Utilise le mod\u00e8le GPT-4 via Azure LLM pour extraire une liste JSON de noms d'auteurs.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: La liste des auteurs d\u00e9tect\u00e9s.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>    def get_all_auteurs(self) -&gt; List[str]:\n        \"\"\"Extrait la liste de tous les auteurs mentionn\u00e9s dans la transcription.\n\n        Notes:\n            Utilise le mod\u00e8le GPT-4 via Azure LLM pour extraire une liste JSON de noms d'auteurs.\n\n        Returns:\n            List[str]: La liste des auteurs d\u00e9tect\u00e9s.\n        \"\"\"\n        if self.transcription is None:\n            return []\n\n        llm_structured_output = get_azure_llm(\"gpt-4o\")\n        response_schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"AuthorList\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"Authors\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\",\n                                \"description\": \"Une liste des auteurs extraits de la transcription\",\n                            },\n                        }\n                    },\n                    \"required\": [\"Authors\"],\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n        response = llm_structured_output.chat(\n            messages=[\n                ChatMessage(\n                    role=\"system\",\n                    content=\"Tu es un assistant utile qui retourne une liste JSON de noms d'auteurs.\",\n                ),\n                ChatMessage(\n                    role=\"user\",\n                    content=f\"Est-ce que tu peux me lister tous les noms d'auteurs dont on parle des oeuvres \\\ndans cette transcription d'un \u00e9pisode du masque et la plume \\\ndiffuse le {self.date.strftime('%d %b %Y')}. \\\nJe veux toujours avoir le pr\u00e9nom et le nom complet de chaque auteur. \\\nVoici cette transcription : {self.transcription} \",\n                ),\n            ],\n            response_format=response_schema,\n        )\n        try:\n            json_dict = json.loads(response.message.content)\n        except json.JSONDecodeError as e:\n            print(\"Error parsing JSON:\", e)\n            print(\"Raw response:\", response.message.content)\n            return []\n        return json_dict[\"Authors\"]\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.get_date_from_string","title":"<code>get_date_from_string(date, DATE_FORMAT=DATE_FORMAT)</code>  <code>staticmethod</code>","text":"<p>Convertit une cha\u00eene de caract\u00e8res en objet datetime.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>str</code> <p>La cha\u00eene repr\u00e9sentant la date.</p> required <code>DATE_FORMAT</code> <code>str</code> <p>Le format de la date. D\u00e9faut est DATE_FORMAT.</p> <code>DATE_FORMAT</code> <p>Returns:</p> Name Type Description <code>datetime</code> <code>datetime</code> <p>L'objet datetime correspondant.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@staticmethod\ndef get_date_from_string(date: str, DATE_FORMAT: str = DATE_FORMAT) -&gt; datetime:\n    \"\"\"Convertit une cha\u00eene de caract\u00e8res en objet datetime.\n\n    Args:\n        date (str): La cha\u00eene repr\u00e9sentant la date.\n        DATE_FORMAT (str, optional): Le format de la date. D\u00e9faut est DATE_FORMAT.\n\n    Returns:\n        datetime: L'objet datetime correspondant.\n    \"\"\"\n    return datetime.strptime(date, DATE_FORMAT)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.get_oid","title":"<code>get_oid()</code>","text":"<p>R\u00e9cup\u00e8re l'identifiant Mongo (_id) de l'\u00e9pisode.</p> <p>Returns:</p> Type Description <code>Optional[ObjectId]</code> <p>Optional[ObjectId]: L'ObjectId de l'\u00e9pisode s'il existe, sinon None.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def get_oid(self) -&gt; Optional[ObjectId]:\n    \"\"\"R\u00e9cup\u00e8re l'identifiant Mongo (_id) de l'\u00e9pisode.\n\n    Returns:\n        Optional[ObjectId]: L'ObjectId de l'\u00e9pisode s'il existe, sinon None.\n    \"\"\"\n    document = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n    if document:\n        return document[\"_id\"]\n    else:\n        return None\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.get_string_from_date","title":"<code>get_string_from_date(date, format=None)</code>  <code>staticmethod</code>","text":"<p>Convertit un objet datetime en cha\u00eene de caract\u00e8res.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>datetime</code> <p>L'objet datetime.</p> required <code>format</code> <code>Optional[str]</code> <p>Le format de sortie. Si None, DATE_FORMAT est utilis\u00e9.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>La cha\u00eene repr\u00e9sentant la date.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@staticmethod\ndef get_string_from_date(date: datetime, format: Optional[str] = None) -&gt; str:\n    \"\"\"Convertit un objet datetime en cha\u00eene de caract\u00e8res.\n\n    Args:\n        date (datetime): L'objet datetime.\n        format (Optional[str], optional): Le format de sortie. Si None, DATE_FORMAT est utilis\u00e9.\n\n    Returns:\n        str: La cha\u00eene repr\u00e9sentant la date.\n    \"\"\"\n    if format is not None:\n        return date.strftime(format)\n    else:\n        return date.strftime(DATE_FORMAT)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.keep","title":"<code>keep()</code>","text":"<p>T\u00e9l\u00e9charge le fichier audio si n\u00e9cessaire et conserve l'\u00e9pisode dans la base de donn\u00e9es.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>1 si une nouvelle entr\u00e9e est cr\u00e9\u00e9e en base, 0 sinon.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def keep(self) -&gt; int:\n    \"\"\"T\u00e9l\u00e9charge le fichier audio si n\u00e9cessaire et conserve l'\u00e9pisode dans la base de donn\u00e9es.\n\n    Returns:\n        int: 1 si une nouvelle entr\u00e9e est cr\u00e9\u00e9e en base, 0 sinon.\n    \"\"\"\n    message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n    if not self.exists():\n        print(\n            f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} nouveau: Duree: {self.duree}, Type: {self.type}\"\n        )\n        mongolog(\"insert\", self.collection.name, message_log)\n        self.download_audio(verbose=True)\n        self.collection.insert_one(\n            {\n                \"titre\": self.titre,\n                \"date\": self.date,\n                \"description\": self.description,\n                \"url\": self.url_telechargement,\n                \"audio_rel_filename\": self.audio_rel_filename,\n                \"transcription\": self.transcription,\n                \"type\": self.type,\n                \"duree\": self.duree,\n                \"masked\": self.masked,\n            }\n        )\n        return 1\n    else:\n        print(\n            f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} deja existant\"\n        )\n        mongolog(\"update\", self.collection.name, message_log)\n        return 0\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.remove","title":"<code>remove()</code>","text":"<p>Supprime l'\u00e9pisode de la base de donn\u00e9es.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def remove(self) -&gt; None:\n    \"\"\"Supprime l'\u00e9pisode de la base de donn\u00e9es.\"\"\"\n    message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n    self.collection.delete_one({\"titre\": self.titre, \"date\": self.date})\n    mongolog(\"delete\", self.collection.name, message_log)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.set_transcription","title":"<code>set_transcription(verbose=False, keep_cache=True)</code>","text":"<p>Extrait et sauvegarde la transcription de l'audio en utilisant un mod\u00e8le Whisper.</p> <p>Utilise le cache si disponible ou extrait la transcription de l'audio.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Si True, affiche des messages d'information. D\u00e9faut False.</p> <code>False</code> <code>keep_cache</code> <code>bool</code> <p>Si True, sauvegarde la transcription dans un fichier cache. D\u00e9faut True.</p> <code>True</code> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def set_transcription(self, verbose: bool = False, keep_cache: bool = True) -&gt; None:\n    \"\"\"Extrait et sauvegarde la transcription de l'audio en utilisant un mod\u00e8le Whisper.\n\n    Utilise le cache si disponible ou extrait la transcription de l'audio.\n\n    Args:\n        verbose (bool, optional): Si True, affiche des messages d'information. D\u00e9faut False.\n        keep_cache (bool, optional): Si True, sauvegarde la transcription dans un fichier cache. D\u00e9faut True.\n    \"\"\"\n    if self.transcription is not None:\n        if verbose:\n            print(\"Transcription existe deja\")\n        return\n    mp3_fullfilename = get_audio_path(AUDIO_PATH, year=\"\") + self.audio_rel_filename\n    cache_transcription_filename = f\"{os.path.splitext(mp3_fullfilename)[0]}.txt\"\n    if os.path.exists(cache_transcription_filename):\n        if verbose:\n            print(f\"Transcription cachee trouvee: {cache_transcription_filename}\")\n        with open(cache_transcription_filename, \"r\") as file:\n            self.transcription = file.read()\n        self.collection.update_one(\n            {\"_id\": self.get_oid()},\n            {\"$set\": {\"transcription\": self.transcription}},\n        )\n        return\n\n    self.transcription = extract_whisper(mp3_fullfilename)\n    if keep_cache:\n        with open(cache_transcription_filename, \"w\") as f:\n            f.write(self.transcription)\n    self.collection.update_one(\n        {\"_id\": self.get_oid()}, {\"$set\": {\"transcription\": self.transcription}}\n    )\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.to_dict","title":"<code>to_dict()</code>","text":"<p>Convertit l'\u00e9pisode en dictionnaire.</p> <p>Returns:</p> Type Description <code>Dict[str, Union[str, datetime, int, None, bool]]</code> <p>Dict[str, Union[str, datetime, int, None, bool]]: Dictionnaire contenant les informations de l'\u00e9pisode. Les cl\u00e9s sont ['date', 'titre', 'description', 'url_telechargement', 'audio_rel_filename', 'transcription', 'type', 'duree', 'masked'].</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Union[str, datetime, int, None, bool]]:\n    \"\"\"Convertit l'\u00e9pisode en dictionnaire.\n\n    Returns:\n        Dict[str, Union[str, datetime, int, None, bool]]: Dictionnaire contenant les informations de l'\u00e9pisode.\n            Les cl\u00e9s sont ['date', 'titre', 'description', 'url_telechargement', 'audio_rel_filename', 'transcription', 'type', 'duree', 'masked'].\n    \"\"\"\n    return {\n        \"date\": self.date,\n        \"titre\": self.titre,\n        \"description\": self.description,\n        \"url_telechargement\": self.url_telechargement,\n        \"audio_rel_filename\": self.audio_rel_filename,\n        \"transcription\": self.transcription,\n        \"type\": self.type,\n        \"duree\": self.duree,\n        \"masked\": self.masked,\n    }\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episode.update_date","title":"<code>update_date(new_date)</code>","text":"<p>Met \u00e0 jour la date de l'\u00e9pisode dans la base de donn\u00e9es.</p> <p>Parameters:</p> Name Type Description Default <code>new_date</code> <code>datetime</code> <p>La nouvelle date de l'\u00e9pisode.</p> required Source code in <code>nbs/mongo_episode.py</code> <pre><code>def update_date(self, new_date: datetime) -&gt; None:\n    \"\"\"Met \u00e0 jour la date de l'\u00e9pisode dans la base de donn\u00e9es.\n\n    Args:\n        new_date (datetime): La nouvelle date de l'\u00e9pisode.\n    \"\"\"\n    self.collection.update_one(\n        {\"_id\": self.get_oid()}, {\"$set\": {\"date\": new_date}}\n    )\n    message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre} -&gt; {Episode.get_string_from_date(new_date, format=LOG_DATE_FORMAT)}\"\n    self.date = new_date\n    mongolog(\"force_update\", self.collection.name, message_log)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes","title":"<code>Episodes</code>","text":"<p>Classe pour rechercher et g\u00e9rer la qualit\u00e9 des donn\u00e9es des \u00e9pisodes.</p> <p>Cette classe permet par exemple de r\u00e9cup\u00e9rer de nouvelles transcriptions en se connectant \u00e0 la base de donn\u00e9es MongoDB.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>class Episodes:\n    \"\"\"Classe pour rechercher et g\u00e9rer la qualit\u00e9 des donn\u00e9es des \u00e9pisodes.\n\n    Cette classe permet par exemple de r\u00e9cup\u00e9rer de nouvelles transcriptions\n    en se connectant \u00e0 la base de donn\u00e9es MongoDB.\n    \"\"\"\n\n    def __init__(self, collection_name: str = \"episodes\") -&gt; None:\n        \"\"\"Initialise une instance du gestionnaire d'\u00e9pisodes.\n\n        Se connecte \u00e0 la base de donn\u00e9es et charge les \u00e9pisodes.\n\n        Args:\n            collection_name (str): Nom de la collection \u00e0 utiliser. Par d\u00e9faut \"episodes\".\n        \"\"\"\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        self.collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n        )\n        # je ne charge plus par defaut tous les episodes c'est inefficace\n        self.oid_episodes = []\n\n    # def _load_all_episodes(self) -&gt; List[\"Episode\"]:\n    #     \"\"\"Charge tous les \u00e9pisodes depuis la base de donn\u00e9es.\n\n    #     Returns:\n    #         List[Episode]: Liste des \u00e9pisodes charg\u00e9s.\n    #     \"\"\"\n    #     return self.get_entries()\n\n    def get_entries(\n        self, request: Any = \"\", limit: int = -1, include_masked: bool = False\n    ):\n        \"\"\"\n        Mets dans self.oid_episodes les oids correspondant \u00e0 une requ\u00eate sp\u00e9cifique, tri\u00e9s par date d\u00e9croissante.\n        Si limit est sp\u00e9cifi\u00e9, seuls les limit premiers r\u00e9sultats sont conserv\u00e9s.\n        Args:\n            request (Any): Requ\u00eate MongoDB \u00e0 ex\u00e9cuter. Exemples:\n                {\"$or\": [{\"transcription\": \"\"}, {\"transcription\": None}]}.\n                Par d\u00e9faut, une requ\u00eate vide qui retourne tous les \u00e9pisodes.\n            include_masked (bool): Si False (par d\u00e9faut), exclut les \u00e9pisodes avec masked=True.\n                Si True, inclut tous les \u00e9pisodes y compris les masqu\u00e9s.\n        \"\"\"\n        # Construire la requ\u00eate finale en combinant request et le filtre masked\n        if not include_masked:\n            # Ajouter le filtre pour exclure les \u00e9pisodes masqu\u00e9s\n            masked_filter = {\n                \"$or\": [{\"masked\": {\"$ne\": True}}, {\"masked\": {\"$exists\": False}}]\n            }\n\n            if request and request != \"\":\n                # Combiner la requ\u00eate existante avec le filtre masked\n                final_request = {\"$and\": [request, masked_filter]}\n            else:\n                # Utiliser uniquement le filtre masked\n                final_request = masked_filter\n        else:\n            # Utiliser la requ\u00eate telle quelle sans filtrer masked\n            final_request = request if request != \"\" else {}\n\n        if limit == -1:\n            results = self.collection.find(final_request, {\"_id\": 1}).sort({\"date\": -1})\n        else:\n            results = (\n                self.collection.find(final_request, {\"_id\": 1})\n                .sort({\"date\": -1})\n                .limit(limit)\n            )\n        self.oid_episodes = [document[\"_id\"] for document in results]\n\n    def len_total_entries(self, include_masked: bool = False) -&gt; int:\n        \"\"\"\n        Retourne le nombre total d'\u00e9pisodes dans la collection.\n\n        Args:\n            include_masked (bool): Si False (par d\u00e9faut), exclut les \u00e9pisodes masqu\u00e9s du comptage.\n                Si True, compte tous les \u00e9pisodes y compris les masqu\u00e9s.\n        \"\"\"\n        if not include_masked:\n            # Compter uniquement les \u00e9pisodes non masqu\u00e9s\n            masked_filter = {\n                \"$or\": [{\"masked\": {\"$ne\": True}}, {\"masked\": {\"$exists\": False}}]\n            }\n            return self.collection.count_documents(masked_filter)\n        else:\n            # Compter tous les \u00e9pisodes\n            return self.collection.estimated_document_count()\n\n    def get_missing_transcriptions(self):\n        \"\"\"\n        Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes sans transcription.\n        \"\"\"\n        self.get_entries({\"$or\": [{\"transcription\": \"\"}, {\"transcription\": None}]})\n\n    def get_transcriptions(self):\n        \"\"\"\n        Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes qui poss\u00e8dent une transcription.\n        \"\"\"\n        self.get_entries(\n            {\"$and\": [{\"transcription\": {\"$ne\": None}}, {\"transcription\": {\"$ne\": \"\"}}]}\n        )\n\n    def __getitem__(self, index: int) -&gt; \"Episode\":\n        \"\"\"Permet l'acc\u00e8s aux \u00e9pisodes par indexation.\n\n        Args:\n            index (int): Position de l'\u00e9pisode dans la liste.\n\n        Returns:\n            Episode: L'\u00e9pisode \u00e0 la position donn\u00e9e.\n        \"\"\"\n        return Episode.from_oid(self.oid_episodes[index])\n\n    def __len__(self) -&gt; int:\n        \"\"\"Retourne le nombre total d'\u00e9pisodes dans oid_episodes.\n\n        Returns:\n            int: Nombre d'\u00e9pisodes.\n        \"\"\"\n        return len(self.oid_episodes)\n\n    def __iter__(self) -&gt; Iterator[\"Episode\"]:\n        \"\"\"Permet d'it\u00e9rer sur les \u00e9pisodes.\n\n        Returns:\n            Iterator[Episode]: It\u00e9rateur sur la liste des \u00e9pisodes.\n        \"\"\"\n        return iter(self.oid_episodes)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Permet l'acc\u00e8s aux \u00e9pisodes par indexation.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Position de l'\u00e9pisode dans la liste.</p> required <p>Returns:</p> Name Type Description <code>Episode</code> <code>Episode</code> <p>L'\u00e9pisode \u00e0 la position donn\u00e9e.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __getitem__(self, index: int) -&gt; \"Episode\":\n    \"\"\"Permet l'acc\u00e8s aux \u00e9pisodes par indexation.\n\n    Args:\n        index (int): Position de l'\u00e9pisode dans la liste.\n\n    Returns:\n        Episode: L'\u00e9pisode \u00e0 la position donn\u00e9e.\n    \"\"\"\n    return Episode.from_oid(self.oid_episodes[index])\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.__init__","title":"<code>__init__(collection_name='episodes')</code>","text":"<p>Initialise une instance du gestionnaire d'\u00e9pisodes.</p> <p>Se connecte \u00e0 la base de donn\u00e9es et charge les \u00e9pisodes.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>Nom de la collection \u00e0 utiliser. Par d\u00e9faut \"episodes\".</p> <code>'episodes'</code> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __init__(self, collection_name: str = \"episodes\") -&gt; None:\n    \"\"\"Initialise une instance du gestionnaire d'\u00e9pisodes.\n\n    Se connecte \u00e0 la base de donn\u00e9es et charge les \u00e9pisodes.\n\n    Args:\n        collection_name (str): Nom de la collection \u00e0 utiliser. Par d\u00e9faut \"episodes\".\n    \"\"\"\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    self.collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n    )\n    # je ne charge plus par defaut tous les episodes c'est inefficace\n    self.oid_episodes = []\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.__iter__","title":"<code>__iter__()</code>","text":"<p>Permet d'it\u00e9rer sur les \u00e9pisodes.</p> <p>Returns:</p> Type Description <code>Iterator[Episode]</code> <p>Iterator[Episode]: It\u00e9rateur sur la liste des \u00e9pisodes.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __iter__(self) -&gt; Iterator[\"Episode\"]:\n    \"\"\"Permet d'it\u00e9rer sur les \u00e9pisodes.\n\n    Returns:\n        Iterator[Episode]: It\u00e9rateur sur la liste des \u00e9pisodes.\n    \"\"\"\n    return iter(self.oid_episodes)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.__len__","title":"<code>__len__()</code>","text":"<p>Retourne le nombre total d'\u00e9pisodes dans oid_episodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Nombre d'\u00e9pisodes.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Retourne le nombre total d'\u00e9pisodes dans oid_episodes.\n\n    Returns:\n        int: Nombre d'\u00e9pisodes.\n    \"\"\"\n    return len(self.oid_episodes)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.get_entries","title":"<code>get_entries(request='', limit=-1, include_masked=False)</code>","text":"<p>Mets dans self.oid_episodes les oids correspondant \u00e0 une requ\u00eate sp\u00e9cifique, tri\u00e9s par date d\u00e9croissante. Si limit est sp\u00e9cifi\u00e9, seuls les limit premiers r\u00e9sultats sont conserv\u00e9s. Args:     request (Any): Requ\u00eate MongoDB \u00e0 ex\u00e9cuter. Exemples:         {\"$or\": [{\"transcription\": \"\"}, {\"transcription\": None}]}.         Par d\u00e9faut, une requ\u00eate vide qui retourne tous les \u00e9pisodes.     include_masked (bool): Si False (par d\u00e9faut), exclut les \u00e9pisodes avec masked=True.         Si True, inclut tous les \u00e9pisodes y compris les masqu\u00e9s.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def get_entries(\n    self, request: Any = \"\", limit: int = -1, include_masked: bool = False\n):\n    \"\"\"\n    Mets dans self.oid_episodes les oids correspondant \u00e0 une requ\u00eate sp\u00e9cifique, tri\u00e9s par date d\u00e9croissante.\n    Si limit est sp\u00e9cifi\u00e9, seuls les limit premiers r\u00e9sultats sont conserv\u00e9s.\n    Args:\n        request (Any): Requ\u00eate MongoDB \u00e0 ex\u00e9cuter. Exemples:\n            {\"$or\": [{\"transcription\": \"\"}, {\"transcription\": None}]}.\n            Par d\u00e9faut, une requ\u00eate vide qui retourne tous les \u00e9pisodes.\n        include_masked (bool): Si False (par d\u00e9faut), exclut les \u00e9pisodes avec masked=True.\n            Si True, inclut tous les \u00e9pisodes y compris les masqu\u00e9s.\n    \"\"\"\n    # Construire la requ\u00eate finale en combinant request et le filtre masked\n    if not include_masked:\n        # Ajouter le filtre pour exclure les \u00e9pisodes masqu\u00e9s\n        masked_filter = {\n            \"$or\": [{\"masked\": {\"$ne\": True}}, {\"masked\": {\"$exists\": False}}]\n        }\n\n        if request and request != \"\":\n            # Combiner la requ\u00eate existante avec le filtre masked\n            final_request = {\"$and\": [request, masked_filter]}\n        else:\n            # Utiliser uniquement le filtre masked\n            final_request = masked_filter\n    else:\n        # Utiliser la requ\u00eate telle quelle sans filtrer masked\n        final_request = request if request != \"\" else {}\n\n    if limit == -1:\n        results = self.collection.find(final_request, {\"_id\": 1}).sort({\"date\": -1})\n    else:\n        results = (\n            self.collection.find(final_request, {\"_id\": 1})\n            .sort({\"date\": -1})\n            .limit(limit)\n        )\n    self.oid_episodes = [document[\"_id\"] for document in results]\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.get_missing_transcriptions","title":"<code>get_missing_transcriptions()</code>","text":"<p>Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes sans transcription.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def get_missing_transcriptions(self):\n    \"\"\"\n    Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes sans transcription.\n    \"\"\"\n    self.get_entries({\"$or\": [{\"transcription\": \"\"}, {\"transcription\": None}]})\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.get_transcriptions","title":"<code>get_transcriptions()</code>","text":"<p>Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes qui poss\u00e8dent une transcription.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def get_transcriptions(self):\n    \"\"\"\n    Mets dans self.oid_episodes les oids correspondant aux \u00e9pisodes qui poss\u00e8dent une transcription.\n    \"\"\"\n    self.get_entries(\n        {\"$and\": [{\"transcription\": {\"$ne\": None}}, {\"transcription\": {\"$ne\": \"\"}}]}\n    )\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.Episodes.len_total_entries","title":"<code>len_total_entries(include_masked=False)</code>","text":"<p>Retourne le nombre total d'\u00e9pisodes dans la collection.</p> <p>Parameters:</p> Name Type Description Default <code>include_masked</code> <code>bool</code> <p>Si False (par d\u00e9faut), exclut les \u00e9pisodes masqu\u00e9s du comptage. Si True, compte tous les \u00e9pisodes y compris les masqu\u00e9s.</p> <code>False</code> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def len_total_entries(self, include_masked: bool = False) -&gt; int:\n    \"\"\"\n    Retourne le nombre total d'\u00e9pisodes dans la collection.\n\n    Args:\n        include_masked (bool): Si False (par d\u00e9faut), exclut les \u00e9pisodes masqu\u00e9s du comptage.\n            Si True, compte tous les \u00e9pisodes y compris les masqu\u00e9s.\n    \"\"\"\n    if not include_masked:\n        # Compter uniquement les \u00e9pisodes non masqu\u00e9s\n        masked_filter = {\n            \"$or\": [{\"masked\": {\"$ne\": True}}, {\"masked\": {\"$exists\": False}}]\n        }\n        return self.collection.count_documents(masked_filter)\n    else:\n        # Compter tous les \u00e9pisodes\n        return self.collection.estimated_document_count()\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode","title":"<code>RSS_episode</code>","text":"<p>               Bases: <code>Episode</code></p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>class RSS_episode(Episode):\n    def __init__(self, date: str, titre: str) -&gt; None:\n        \"\"\"\n        Initialize an RSS_episode instance.\n\n        Args:\n            date (str): The episode date in the format \"2024-12-22T09:59:39\".\n            titre (str): The title of the episode.\n        \"\"\"\n        super().__init__(date, titre)\n\n    @classmethod\n    def from_feed_entry(cls, feed_entry: FeedParserDict) -&gt; \"RSS_episode\":\n        \"\"\"\n        Create an RSS_episode instance from an RSS feed entry.\n\n        Args:\n            feed_entry (FeedParserDict): The entry from the RSS feed.\n\n        Returns:\n            RSS_episode: The created RSS_episode instance.\n        \"\"\"\n        locale.setlocale(locale.LC_TIME, \"en_US.UTF-8\")\n        date_rss: datetime = datetime.strptime(feed_entry.published, RSS_DATE_FORMAT)\n        date_rss_str: str = cls.get_string_from_date(date_rss, DATE_FORMAT)\n        inst = cls(\n            date=date_rss_str,\n            titre=feed_entry.title,\n        )\n        inst.description = feed_entry.summary\n\n        for link in feed_entry.links:\n            if link.type == \"audio/mpeg\":\n                inst.url_telechargement = link.href\n                break\n\n        inst.type = cls.set_titre(inst.titre + \" \" + inst.description)\n        inst.duree = cls.get_duree_in_seconds(feed_entry.itunes_duration)  # in seconds\n\n        return inst\n\n    @staticmethod\n    def get_duree_in_seconds(duree: str) -&gt; int:\n        \"\"\"\n        Convert a duration string into total seconds.\n\n        The duration can be in formats \"HH:MM:SS\", \"HH:MM\", or simply seconds.\n\n        Args:\n            duree (str): The duration as a string.\n\n        Returns:\n            int: The duration expressed in total seconds.\n        \"\"\"\n        duree_parts = duree.split(\":\")\n        if len(duree_parts) == 3:\n            return (\n                int(duree_parts[0]) * 3600\n                + int(duree_parts[1]) * 60\n                + int(duree_parts[2])\n            )\n        elif len(duree_parts) == 2:\n            return int(duree_parts[0]) * 60 + int(duree_parts[1])\n        else:\n            return int(duree_parts[0])\n\n    def keep(self) -&gt; int:\n        \"\"\"\n        Save the episode to the database if conditions are met.\n\n        The episode is saved if:\n            - The duration is greater than RSS_DUREE_MINI_MINUTES * 60 seconds.\n            - The type is equal to \"livres\".\n\n        Returns:\n            int: 1 if an entry is created in the database, 0 otherwise.\n        \"\"\"\n        if (self.duree &gt; RSS_DUREE_MINI_MINUTES * 60) and (self.type == \"livres\"):\n            return super().keep()\n        else:\n            print(\n                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} ignored: Duree: {self.duree}, Type: {self.type}\"\n            )\n            return 0\n\n    @staticmethod\n    def set_titre(description: str) -&gt; str:\n        \"\"\"\n        Classify the episode by using a zero-shot classification model from HuggingFace based on the provided description.\n\n        Args:\n            description (str): The description combining the title and summary.\n\n        Returns:\n            str: The label with the highest score among [\"livres\", \"films\", \"pi\u00e8ces de th\u00e9\u00e2tre\"].\n        \"\"\"\n        classifier = pipeline(\n            \"zero-shot-classification\", model=\"facebook/bart-large-mnli\"\n        )\n        labels = [\"livres\", \"films\", \"pi\u00e8ces de th\u00e9\u00e2tre\"]\n\n        result = classifier(description, labels)\n        return result[\"labels\"][0]\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode.__init__","title":"<code>__init__(date, titre)</code>","text":"<p>Initialize an RSS_episode instance.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>str</code> <p>The episode date in the format \"2024-12-22T09:59:39\".</p> required <code>titre</code> <code>str</code> <p>The title of the episode.</p> required Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __init__(self, date: str, titre: str) -&gt; None:\n    \"\"\"\n    Initialize an RSS_episode instance.\n\n    Args:\n        date (str): The episode date in the format \"2024-12-22T09:59:39\".\n        titre (str): The title of the episode.\n    \"\"\"\n    super().__init__(date, titre)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode.from_feed_entry","title":"<code>from_feed_entry(feed_entry)</code>  <code>classmethod</code>","text":"<p>Create an RSS_episode instance from an RSS feed entry.</p> <p>Parameters:</p> Name Type Description Default <code>feed_entry</code> <code>FeedParserDict</code> <p>The entry from the RSS feed.</p> required <p>Returns:</p> Name Type Description <code>RSS_episode</code> <code>RSS_episode</code> <p>The created RSS_episode instance.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@classmethod\ndef from_feed_entry(cls, feed_entry: FeedParserDict) -&gt; \"RSS_episode\":\n    \"\"\"\n    Create an RSS_episode instance from an RSS feed entry.\n\n    Args:\n        feed_entry (FeedParserDict): The entry from the RSS feed.\n\n    Returns:\n        RSS_episode: The created RSS_episode instance.\n    \"\"\"\n    locale.setlocale(locale.LC_TIME, \"en_US.UTF-8\")\n    date_rss: datetime = datetime.strptime(feed_entry.published, RSS_DATE_FORMAT)\n    date_rss_str: str = cls.get_string_from_date(date_rss, DATE_FORMAT)\n    inst = cls(\n        date=date_rss_str,\n        titre=feed_entry.title,\n    )\n    inst.description = feed_entry.summary\n\n    for link in feed_entry.links:\n        if link.type == \"audio/mpeg\":\n            inst.url_telechargement = link.href\n            break\n\n    inst.type = cls.set_titre(inst.titre + \" \" + inst.description)\n    inst.duree = cls.get_duree_in_seconds(feed_entry.itunes_duration)  # in seconds\n\n    return inst\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode.get_duree_in_seconds","title":"<code>get_duree_in_seconds(duree)</code>  <code>staticmethod</code>","text":"<p>Convert a duration string into total seconds.</p> <p>The duration can be in formats \"HH:MM:SS\", \"HH:MM\", or simply seconds.</p> <p>Parameters:</p> Name Type Description Default <code>duree</code> <code>str</code> <p>The duration as a string.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The duration expressed in total seconds.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@staticmethod\ndef get_duree_in_seconds(duree: str) -&gt; int:\n    \"\"\"\n    Convert a duration string into total seconds.\n\n    The duration can be in formats \"HH:MM:SS\", \"HH:MM\", or simply seconds.\n\n    Args:\n        duree (str): The duration as a string.\n\n    Returns:\n        int: The duration expressed in total seconds.\n    \"\"\"\n    duree_parts = duree.split(\":\")\n    if len(duree_parts) == 3:\n        return (\n            int(duree_parts[0]) * 3600\n            + int(duree_parts[1]) * 60\n            + int(duree_parts[2])\n        )\n    elif len(duree_parts) == 2:\n        return int(duree_parts[0]) * 60 + int(duree_parts[1])\n    else:\n        return int(duree_parts[0])\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode.keep","title":"<code>keep()</code>","text":"<p>Save the episode to the database if conditions are met.</p> The episode is saved if <ul> <li>The duration is greater than RSS_DUREE_MINI_MINUTES * 60 seconds.</li> <li>The type is equal to \"livres\".</li> </ul> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>1 if an entry is created in the database, 0 otherwise.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>def keep(self) -&gt; int:\n    \"\"\"\n    Save the episode to the database if conditions are met.\n\n    The episode is saved if:\n        - The duration is greater than RSS_DUREE_MINI_MINUTES * 60 seconds.\n        - The type is equal to \"livres\".\n\n    Returns:\n        int: 1 if an entry is created in the database, 0 otherwise.\n    \"\"\"\n    if (self.duree &gt; RSS_DUREE_MINI_MINUTES * 60) and (self.type == \"livres\"):\n        return super().keep()\n    else:\n        print(\n            f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} ignored: Duree: {self.duree}, Type: {self.type}\"\n        )\n        return 0\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.RSS_episode.set_titre","title":"<code>set_titre(description)</code>  <code>staticmethod</code>","text":"<p>Classify the episode by using a zero-shot classification model from HuggingFace based on the provided description.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>The description combining the title and summary.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The label with the highest score among [\"livres\", \"films\", \"pi\u00e8ces de th\u00e9\u00e2tre\"].</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@staticmethod\ndef set_titre(description: str) -&gt; str:\n    \"\"\"\n    Classify the episode by using a zero-shot classification model from HuggingFace based on the provided description.\n\n    Args:\n        description (str): The description combining the title and summary.\n\n    Returns:\n        str: The label with the highest score among [\"livres\", \"films\", \"pi\u00e8ces de th\u00e9\u00e2tre\"].\n    \"\"\"\n    classifier = pipeline(\n        \"zero-shot-classification\", model=\"facebook/bart-large-mnli\"\n    )\n    labels = [\"livres\", \"films\", \"pi\u00e8ces de th\u00e9\u00e2tre\"]\n\n    result = classifier(description, labels)\n    return result[\"labels\"][0]\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.WEB_episode","title":"<code>WEB_episode</code>","text":"<p>               Bases: <code>Episode</code></p> <p>Repr\u00e9sente un \u00e9pisode web avec ses attributs et m\u00e9thodes de conversion et r\u00e9cup\u00e9ration des donn\u00e9es.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>class WEB_episode(Episode):\n    \"\"\"Repr\u00e9sente un \u00e9pisode web avec ses attributs et m\u00e9thodes de conversion et r\u00e9cup\u00e9ration des donn\u00e9es.\"\"\"\n\n    def __init__(self, date: str, titre: str) -&gt; None:\n        \"\"\"Initialise une instance de WEB_episode.\n\n        Args:\n            date (str): La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\".\n            titre (str): Le titre de l'\u00e9pisode.\n        \"\"\"\n        super().__init__(date, titre)\n\n    @staticmethod\n    def parse_web_date(\n        web_date: str, web_date_format: str = WEB_DATE_FORMAT\n    ) -&gt; Optional[datetime]:\n        \"\"\"Convertit une date en fran\u00e7ais extraite d'une page web en un objet datetime.\n\n        Corrige les abr\u00e9viations non standard pour certains mois (exemple : \"f\u00e9v.\" devient \"f\u00e9vr.\", \"juill.\" devient \"juil.\").\n\n        Args:\n            web_date (str): La cha\u00eene repr\u00e9sentant la date en fran\u00e7ais.\n            web_date_format (str, optional): Le format de la date utilis\u00e9 par la page web. Defaults to WEB_DATE_FORMAT.\n\n        Returns:\n            Optional[datetime]: L'objet datetime si la conversion r\u00e9ussit, sinon None.\n        \"\"\"\n        locale.setlocale(locale.LC_TIME, \"fr_FR.UTF-8\")\n\n        def corrige_date(date_str: str) -&gt; str:\n            \"\"\"Corrige les abr\u00e9viations non standard dans la cha\u00eene de date.\n\n            Args:\n                date_str (str): La cha\u00eene de date originale.\n\n            Returns:\n                str: La cha\u00eene de date corrig\u00e9e.\n            \"\"\"\n            month_replacements = {\n                \"f\u00e9v.\": \"f\u00e9vr.\",\n                \"juill.\": \"juil.\",\n            }\n            for fr_month, fr_month_norm in month_replacements.items():\n                date_str = date_str.replace(fr_month, fr_month_norm)\n            return date_str\n\n        try:\n            dt: datetime = datetime.strptime(corrige_date(web_date), web_date_format)\n            return dt\n        except ValueError as e:\n            print(f\"Erreur de conversion pour la date '{web_date}': {e}\")\n            return None\n\n    @staticmethod\n    def get_audio_url(url: str) -&gt; Optional[str]:\n        \"\"\"R\u00e9cup\u00e8re l'URL du fichier audio (.m4a ou .mp3) \u00e0 partir de la page d'un \u00e9pisode.\n\n        Recherche dans une balise &lt;script&gt; contenant la cl\u00e9 \"contentUrl\".\n\n        Args:\n            url (str): L'URL de la page de l'\u00e9pisode.\n\n        Returns:\n            Optional[str]: L'URL du fichier audio si trouv\u00e9e, sinon None.\n        \"\"\"\n        try:\n            response: requests.Response = requests.get(url)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            print(f\"Erreur lors de la requ\u00eate HTTP: {e}\")\n            return None\n\n        soup: BeautifulSoup = BeautifulSoup(response.content, \"html.parser\")\n        script_tag = soup.find(\"script\", string=lambda t: t and \"contentUrl\" in t)\n\n        if script_tag:\n            try:\n                json_text: str = script_tag.string  # type: ignore\n                json_data: Dict[str, Any] = json.loads(json_text)\n                audio_url: Optional[str] = None\n                for item in json_data.get(\"@graph\", []):\n                    if item.get(\"@type\") == \"RadioEpisode\":\n                        main_entity: Dict[str, Any] = item.get(\"mainEntity\", {})\n                        audio_url = main_entity.get(\"contentUrl\")\n                        break\n                return audio_url\n            except (json.JSONDecodeError, KeyError, TypeError) as e:\n                print(f\"Erreur lors de l'analyse du JSON: {e}\")\n                return None\n\n        print(\"Balise &lt;script&gt; contenant 'contentUrl' non trouv\u00e9e\")\n        return None\n\n    @classmethod\n    def from_webpage_entry(cls, dict_web_episode: Dict[str, Any]) -&gt; \"WEB_episode\":\n        \"\"\"Cr\u00e9e une instance de WEB_episode \u00e0 partir d'un dictionnaire repr\u00e9sentant une entr\u00e9e de page web.\n\n        Le dictionnaire doit contenir les cl\u00e9s : 'title', 'url', 'description', 'date', 'duration'.\n        La variable DATE_FORMAT et la m\u00e9thode get_string_from_date doivent \u00eatre d\u00e9finies ailleurs dans le code.\n\n        Args:\n            dict_web_episode (Dict[str, Any]): Dictionnaire contenant les informations de l'\u00e9pisode.\n\n        Returns:\n            WEB_episode: Une instance de WEB_episode initialis\u00e9e avec les donn\u00e9es fournies.\n        \"\"\"\n        date_web: Optional[datetime] = cls.parse_web_date(dict_web_episode[\"date\"])\n        date_web_str: str = cls.get_string_from_date(\n            date_web, DATE_FORMAT\n        )  # DATE_FORMAT doit \u00eatre d\u00e9fini en amont\n        inst: WEB_episode = cls(\n            date=date_web_str,\n            titre=dict_web_episode[\"title\"],\n        )\n        inst.description = dict_web_episode[\"description\"]\n        inst.type = \"livres\"\n        inst.url_telechargement = cls.get_audio_url(dict_web_episode[\"url\"])\n        inst.duree = cls.get_duree_in_seconds(dict_web_episode[\"duration\"])\n        return inst\n\n    @staticmethod\n    def get_duree_in_seconds(duree: str) -&gt; int:\n        \"\"\"Convertit une dur\u00e9e exprim\u00e9e en minutes (\"MM min\") en secondes.\n\n        Args:\n            duree (str): La dur\u00e9e sous forme de cha\u00eene.\n\n        Returns:\n            int: La dur\u00e9e convertie en secondes. Retourne 0 si le format n'est pas correct.\n        \"\"\"\n        parts = duree.split(\" \")\n        if len(parts) == 2:\n            return int(parts[0]) * 60\n        return 0\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.WEB_episode.__init__","title":"<code>__init__(date, titre)</code>","text":"<p>Initialise une instance de WEB_episode.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>str</code> <p>La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\".</p> required <code>titre</code> <code>str</code> <p>Le titre de l'\u00e9pisode.</p> required Source code in <code>nbs/mongo_episode.py</code> <pre><code>def __init__(self, date: str, titre: str) -&gt; None:\n    \"\"\"Initialise une instance de WEB_episode.\n\n    Args:\n        date (str): La date de l'\u00e9pisode au format \"2024-12-22T09:59:39\".\n        titre (str): Le titre de l'\u00e9pisode.\n    \"\"\"\n    super().__init__(date, titre)\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.WEB_episode.from_webpage_entry","title":"<code>from_webpage_entry(dict_web_episode)</code>  <code>classmethod</code>","text":"<p>Cr\u00e9e une instance de WEB_episode \u00e0 partir d'un dictionnaire repr\u00e9sentant une entr\u00e9e de page web.</p> <p>Le dictionnaire doit contenir les cl\u00e9s : 'title', 'url', 'description', 'date', 'duration'. La variable DATE_FORMAT et la m\u00e9thode get_string_from_date doivent \u00eatre d\u00e9finies ailleurs dans le code.</p> <p>Parameters:</p> Name Type Description Default <code>dict_web_episode</code> <code>Dict[str, Any]</code> <p>Dictionnaire contenant les informations de l'\u00e9pisode.</p> required <p>Returns:</p> Name Type Description <code>WEB_episode</code> <code>WEB_episode</code> <p>Une instance de WEB_episode initialis\u00e9e avec les donn\u00e9es fournies.</p> Source code in <code>nbs/mongo_episode.py</code> <pre><code>@classmethod\ndef from_webpage_entry(cls, dict_web_episode: Dict[str, Any]) -&gt; \"WEB_episode\":\n    \"\"\"Cr\u00e9e une instance de WEB_episode \u00e0 partir d'un dictionnaire repr\u00e9sentant une entr\u00e9e de page web.\n\n    Le dictionnaire doit contenir les cl\u00e9s : 'title', 'url', 'description', 'date', 'duration'.\n    La variable DATE_FORMAT et la m\u00e9thode get_string_from_date doivent \u00eatre d\u00e9finies ailleurs dans le code.\n\n    Args:\n        dict_web_episode (Dict[str, Any]): Dictionnaire contenant les informations de l'\u00e9pisode.\n\n    Returns:\n        WEB_episode: Une instance de WEB_episode initialis\u00e9e avec les donn\u00e9es fournies.\n    \"\"\"\n    date_web: Optional[datetime] = cls.parse_web_date(dict_web_episode[\"date\"])\n    date_web_str: str = cls.get_string_from_date(\n        date_web, DATE_FORMAT\n    )  # DATE_FORMAT doit \u00eatre d\u00e9fini en amont\n    inst: WEB_episode = cls(\n        date=date_web_str,\n        titre=dict_web_episode[\"title\"],\n    )\n    inst.description = dict_web_episode[\"description\"]\n    inst.type = \"livres\"\n    inst.url_telechargement = cls.get_audio_url(dict_web_episode[\"url\"])\n    inst.duree = cls.get_duree_in_seconds(dict_web_episode[\"duration\"])\n    return inst\n</code></pre>"},{"location":"mongo_episode/#mongo_episode.WEB_episode.get_audio_url","title":"<code>get_audio_url(url)</code>  <code>staticmethod</code>","text":"<p>R\u00e9cup\u00e8re l'URL du fichier audio (.m4a ou .mp3) \u00e0 partir de la page d'un \u00e9pisode.</p> <p>Recherche dans une balise"},{"location":"mongo_livre/","title":"Module mongo_livre","text":""},{"location":"mongo_livre/#mongo_livre.Livre","title":"<code>Livre</code>","text":"<p>               Bases: <code>BaseEntity</code></p> Source code in <code>nbs/mongo_livre.py</code> <pre><code>class Livre(BaseEntity):\n    collection: str = \"livres\"\n\n    def __init__(self, titre: str) -&gt; None:\n        \"\"\"Initialise une instance de livre.\n\n        Args:\n            nom (str): Le titre du livre.\n        \"\"\"\n        super().__init__(titre, self.collection)\n        self.titre = titre  # je le duplique pour la comprehension du concept de livre\n        self.auteur = None  # on mettra l'oid de l'auteur\n        self.editeur = None  # on mettra l'oid de l'editeur\n\n    def add_auteur(self, auteur: Auteur):\n        if auteur is not None:\n            self.auteur = auteur.get_oid()\n\n    def add_editeur(self, editeur: Editeur):\n        if editeur is not None:\n            self.editeur = editeur.get_oid()\n\n    @classmethod\n    def with_details(cls, titre: str, auteur: Auteur, editeur: Editeur):\n        \"\"\"Alternative constructor to instantiate a Livre with title, auteur and editeur.\n\n        Args:\n            titre (str): The title of the book.\n            auteur (Auteur): Instance of Auteur.\n            editeur (Editeur): Instance of Editeur.\n        Returns:\n            Livre: An instance of Livre.\n        \"\"\"\n        instance = cls(titre)\n        instance.add_auteur(auteur)\n        instance.add_editeur(editeur)\n        return instance\n\n    @classmethod\n    def from_oid(cls: Type[T], oid: ObjectId) -&gt; T:\n        \"\"\"Creates an instance of Livre class from a MongoDB ObjectId.\n        Returns None if the ObjectId is not found in the database or is None.\n\n        Args:\n            oid (ObjectId): The MongoDB ObjectId.\n\n        Returns:\n            T: An instance of the derived class.\n        \"\"\"\n        if oid is None:\n            return None\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n        )\n        document = collection.find_one({\"_id\": oid})\n        if document is None:\n            return None\n        inst = cls.with_details(\n            document.get(\"titre\"),\n            Auteur.from_oid(document.get(\"auteur\")),\n            Editeur.from_oid(document.get(\"editeur\")),\n        )\n        return inst\n\n    def __str__(self) -&gt; str:\n        \"\"\"Official string representation of the entity.\n\n        Returns:\n            str: The name of the entity: Titre, Auteur, Editeur.\n        \"\"\"\n        return f\"\"\"\n        Titre: {self.titre}\n        Auteur: {Auteur.from_oid(self.auteur) if self.auteur is not None else None}\n        Editeur: {Editeur.from_oid(self.editeur) if self.editeur is not None else None}\n        \"\"\"\n</code></pre>"},{"location":"mongo_livre/#mongo_livre.Livre.__init__","title":"<code>__init__(titre)</code>","text":"<p>Initialise une instance de livre.</p> <p>Parameters:</p> Name Type Description Default <code>nom</code> <code>str</code> <p>Le titre du livre.</p> required Source code in <code>nbs/mongo_livre.py</code> <pre><code>def __init__(self, titre: str) -&gt; None:\n    \"\"\"Initialise une instance de livre.\n\n    Args:\n        nom (str): Le titre du livre.\n    \"\"\"\n    super().__init__(titre, self.collection)\n    self.titre = titre  # je le duplique pour la comprehension du concept de livre\n    self.auteur = None  # on mettra l'oid de l'auteur\n    self.editeur = None  # on mettra l'oid de l'editeur\n</code></pre>"},{"location":"mongo_livre/#mongo_livre.Livre.__str__","title":"<code>__str__()</code>","text":"<p>Official string representation of the entity.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the entity: Titre, Auteur, Editeur.</p> Source code in <code>nbs/mongo_livre.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Official string representation of the entity.\n\n    Returns:\n        str: The name of the entity: Titre, Auteur, Editeur.\n    \"\"\"\n    return f\"\"\"\n    Titre: {self.titre}\n    Auteur: {Auteur.from_oid(self.auteur) if self.auteur is not None else None}\n    Editeur: {Editeur.from_oid(self.editeur) if self.editeur is not None else None}\n    \"\"\"\n</code></pre>"},{"location":"mongo_livre/#mongo_livre.Livre.from_oid","title":"<code>from_oid(oid)</code>  <code>classmethod</code>","text":"<p>Creates an instance of Livre class from a MongoDB ObjectId. Returns None if the ObjectId is not found in the database or is None.</p> <p>Parameters:</p> Name Type Description Default <code>oid</code> <code>ObjectId</code> <p>The MongoDB ObjectId.</p> required <p>Returns:</p> Name Type Description <code>T</code> <code>T</code> <p>An instance of the derived class.</p> Source code in <code>nbs/mongo_livre.py</code> <pre><code>@classmethod\ndef from_oid(cls: Type[T], oid: ObjectId) -&gt; T:\n    \"\"\"Creates an instance of Livre class from a MongoDB ObjectId.\n    Returns None if the ObjectId is not found in the database or is None.\n\n    Args:\n        oid (ObjectId): The MongoDB ObjectId.\n\n    Returns:\n        T: An instance of the derived class.\n    \"\"\"\n    if oid is None:\n        return None\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=cls.collection\n    )\n    document = collection.find_one({\"_id\": oid})\n    if document is None:\n        return None\n    inst = cls.with_details(\n        document.get(\"titre\"),\n        Auteur.from_oid(document.get(\"auteur\")),\n        Editeur.from_oid(document.get(\"editeur\")),\n    )\n    return inst\n</code></pre>"},{"location":"mongo_livre/#mongo_livre.Livre.with_details","title":"<code>with_details(titre, auteur, editeur)</code>  <code>classmethod</code>","text":"<p>Alternative constructor to instantiate a Livre with title, auteur and editeur.</p> <p>Parameters:</p> Name Type Description Default <code>titre</code> <code>str</code> <p>The title of the book.</p> required <code>auteur</code> <code>Auteur</code> <p>Instance of Auteur.</p> required <code>editeur</code> <code>Editeur</code> <p>Instance of Editeur.</p> required <p>Returns:     Livre: An instance of Livre.</p> Source code in <code>nbs/mongo_livre.py</code> <pre><code>@classmethod\ndef with_details(cls, titre: str, auteur: Auteur, editeur: Editeur):\n    \"\"\"Alternative constructor to instantiate a Livre with title, auteur and editeur.\n\n    Args:\n        titre (str): The title of the book.\n        auteur (Auteur): Instance of Auteur.\n        editeur (Editeur): Instance of Editeur.\n    Returns:\n        Livre: An instance of Livre.\n    \"\"\"\n    instance = cls(titre)\n    instance.add_auteur(auteur)\n    instance.add_editeur(editeur)\n    return instance\n</code></pre>"},{"location":"readme_data_model/","title":"data model","text":""},{"location":"readme_data_model/#data-model","title":"\ud83c\udfa8 Data model","text":"<p>Here is the data model used for this application \ud83d\udd0d</p> <p> \ud83d\uddbc\ufe0f</p>"},{"location":"readme_data_model/#edit","title":"\ud83d\uddbc\ufe0f Edit","text":"<p>To edit it, I use drawio: lmelp.drawio \u270f\ufe0f</p>"},{"location":"readme_doc/","title":"manage doc","text":"<ul> <li>\ud83d\udcda \u00c9tapes \u00e0 suivre</li> <li>\ud83d\udd27 Installer les d\u00e9pendances</li> <li>\ud83d\ude80 Initialiser le projet MkDocs</li> <li>\u2699\ufe0f Configurer le fichier <code>mkdocs.yml</code></li> <li>\ud83d\udcdd Cr\u00e9er les pages Markdown pour int\u00e9grer la doc extraite</li> <li>\u270f\ufe0f Modifier les docstrings</li> <li>\ud83d\udda5\ufe0f Lancer le serveur de d\u00e9veloppement</li> <li>\ud83c\udfd7\ufe0f G\u00e9n\u00e9rer la documentation statique</li> <li>\ud83d\udea2 Pousser sous github pages</li> <li>\ud83e\udd16 automatisation complete avec github-actions github-pages</li> <li>\ud83d\udcc4 R\u00e9sum\u00e9</li> </ul> <p>Voici une solution compl\u00e8te pour cr\u00e9er une documentation avec MkDocs et le th\u00e8me Material, en incluant l'extraction automatique de la doc de vos fichiers .py gr\u00e2ce \u00e0 l'extension mkdocstrings. \ud83d\udca1</p>"},{"location":"readme_doc/#etapes-a-suivre","title":"\ud83d\udcda \u00c9tapes \u00e0 suivre","text":""},{"location":"readme_doc/#installer-les-dependances","title":"\ud83d\udd27 Installer les d\u00e9pendances","text":"<p>Voici les requirements \u00e0 installer : MkDocs, mkdocs-material, mkdocstrings[python] et mkdocs-include-markdown-plugin. \ud83d\udca1</p> <pre><code>mkdocs \nmkdocs-material \nmkdocstrings[python]\nmkdocs-include-markdown-plugin\n</code></pre>"},{"location":"readme_doc/#initialiser-le-projet-mkdocs","title":"\ud83d\ude80 Initialiser le projet MkDocs","text":"<p>Dans la racine de votre repo, initialisez MkDocs (si vous n\u2019avez pas d\u00e9j\u00e0 de fichier mkdocs.yml) : \ud83d\udca1</p> <pre><code># avec uv\nuv run mkdocs new .\n# avec conda/pip\nmkdocs new .\n</code></pre> <p>Cela cr\u00e9e un fichier <code>mkdocs.yml</code> et un dossier <code>docs/</code>. \ud83d\udca1</p>"},{"location":"readme_doc/#configurer-le-fichier-mkdocsyml","title":"\u2699\ufe0f Configurer le fichier <code>mkdocs.yml</code>","text":"<p>Modifiez le fichier mkdocs.yml pour d\u00e9finir le nom du site, la navigation, le th\u00e8me et la configuration de mkdocstrings. Par exemple : \ud83d\udca1</p> <pre><code>site_name: Documentation des APIs du repo lmelp\nnav:\n  - Accueil: index.md\n  - Modules:\n      - Module config: config.md\n      - Module llm: llm.md\n      - Module whisper: whisper.md\n      - Module web: web.md\n      - Module rss: rss.md\n      - Module mongo: mongo.md\n      - Module mongo_episode: mongo_episode.md\n      - Module mongo_auteur: mongo_auteur.md\n      - Module mongo_livre: mongo_livre.md\n  - Other kind of docs:\n      - manage doc: readme_doc.md\n      - write markdown: readme_markdown.md\n      - some vs_code hints: readme_vscode_hints.md\n      - about Google services: readme_google.md\n      - data model: readme_data_model.md\ntheme:\n  name: material\n\n# Configuration de mkdocstrings pour extraire la documentation de vos .py\nmarkdown_extensions:\n  - toc:\n      permalink: true\n\nplugins:\n  - search\n  - include-markdown\n  - mkdocstrings:\n      default_handler: python\n      handlers:\n        python:\n          paths: [nbs]\n</code></pre> <p>Quelques points \u00e0 noter : \u2b50 - Vous pouvez organiser votre navigation comme vous le souhaitez. \u2b50 - La section <code>plugins</code> avec mkdocstrings permet d'extraire la doc des fichiers Python. \u2b50  </p>"},{"location":"readme_doc/#creer-les-pages-markdown-pour-integrer-la-doc-extraite","title":"\ud83d\udcdd Cr\u00e9er les pages Markdown pour int\u00e9grer la doc extraite","text":"<p>Dans le dossier <code>docs/</code>, cr\u00e9ez par exemple un fichier <code>mongo_auteur.md</code> pour documenter le module <code>mongo_auteur.py</code> : \ud83d\udca1</p> <pre><code># Module mongo_auteur\n\n::: mongo_auteur\n    rendering:\n      show_root_full_path: false\n</code></pre> <p>De m\u00eame, cr\u00e9ez un fichier <code>mongo_episode.md</code> pour documenter <code>mongo_episode.py</code> : \ud83d\udca1</p> <pre><code># Module mongo_episode\n\n::: mongo_episode\n    rendering:\n      show_root_full_path: false\n</code></pre> <p>L'op\u00e9rateur <code>:::</code> indique \u00e0 mkdocstrings (via la syntaxe Python) d'extraire automatiquement les docstrings du module nomm\u00e9 (<code>mongo_auteur</code> ou <code>mongo_episode</code>). \ud83d\udca1 Assurez-vous que ces modules soient dans votre <code>PYTHONPATH</code> ou que vous sp\u00e9cifiiez leur chemin relatif si besoin. \ud83d\udca1</p>"},{"location":"readme_doc/#modifier-les-docstrings","title":"\u270f\ufe0f Modifier les docstrings","text":"<p>J'utilise copilot avec le prompt suivant : \ud83d\udca1</p> <pre><code>peux-tu ajouter des docstrings au format Google style utilisables par mkdocs ou les modifier pour qu'ils soient utilisables par mkdocs et t'assurer qu'ils soient au format Google style ?\nprecise egalement les bons types dans la signature des methodes/fonctions ainsi que le type de sortie s'il y a lieu.\n</code></pre>"},{"location":"readme_doc/#lancer-le-serveur-de-developpement","title":"\ud83d\udda5\ufe0f Lancer le serveur de d\u00e9veloppement","text":"<p>Pour visualiser la documentation, ex\u00e9cutez : \ud83d\udca1</p> <pre><code>mkdocs serve\n</code></pre> <p>ou avec uv  </p> <pre><code>uv run mkdocs serve\n</code></pre> <p>Vous pourrez alors acc\u00e9der \u00e0 l\u2019interface web sur http://127.0.0.1:8000. \ud83d\udca1</p>"},{"location":"readme_doc/#generer-la-documentation-statique","title":"\ud83c\udfd7\ufe0f G\u00e9n\u00e9rer la documentation statique","text":"<p>Quand vous \u00eates satisfait, g\u00e9n\u00e9rez le site statique : \ud83d\udca1</p> <pre><code>mkdocs build\n</code></pre> <p>ou avec uv  </p> <pre><code>uv run mkdocs build\n</code></pre> <p>Le site sera cr\u00e9\u00e9 dans le dossier <code>site/</code>, pr\u00eat \u00e0 \u00eatre d\u00e9ploy\u00e9. \ud83d\udca1</p>"},{"location":"readme_doc/#pousser-sous-github-pages","title":"\ud83d\udea2 Pousser sous github pages","text":"<pre><code>mkdocs gh-deploy\n</code></pre> <p>ou avec uv  </p> <pre><code>uv run mkdocs gh-deploy\n</code></pre>"},{"location":"readme_doc/#automatisation-complete-avec-github-actions-github-pages","title":"\ud83e\udd16 automatisation complete avec github-actions github-pages","text":"<p>doc Material for MkDocs: Publishing your site\u00b6 \ud83d\udca1</p> <p>Several steps: \ud83d\udca1 - copy/paste <code>.github/workflows/ci.yml</code> \u2b50 - at each commit/push (in main), this fires, builds and deploys doc \u2b50 - it is accessible in https://castorfou.github.io/lmelp \u2b50 - display a link to doc from repo GitHub page: <code>Edit repository details</code> &gt; Check <code>Use your GitHub Pages website</code> \u2b50  </p>"},{"location":"readme_doc/#resume","title":"\ud83d\udcc4 R\u00e9sum\u00e9","text":"<ul> <li>Vous installez MkDocs, Material, et mkdocstrings. \u2b50  </li> <li>Vous configurez <code>mkdocs.yml</code> pour int\u00e9grer mkdocstrings et vous indiquez dans la navigation les pages souhait\u00e9es. \u2b50  </li> <li>Dans vos pages Markdown, vous utilisez la syntaxe <code>:::</code> pour extraire automatiquement la doc de vos fichiers Python. \u2b50  </li> <li>Vous lancez le serveur MkDocs pour v\u00e9rifier l'interface web moderne et bien organis\u00e9e. \u2b50  </li> </ul> <p>Cette approche vous permettra d'avoir une documentation conviviale et rapidement mise \u00e0 jour \u00e0 partir de vos docstrings. \ud83d\udca1</p>"},{"location":"readme_github/","title":"github","text":"<ul> <li>\ud83d\ude80 issue - branch - merge</li> <li>merge to main</li> <li>\ud83e\udd16 github actions</li> </ul>"},{"location":"readme_github/#issue-branch-merge","title":"\ud83d\ude80 issue - branch - merge","text":"<p>As much as possible I want to use this approach \ud83d\udc4d</p> <p>From https://github.com/castorfou/lmelp, \ud83d\udd17</p> <ul> <li>create an issue \ud83d\udcdd</li> <li>from issue create a branch (Development &gt; Create a branch) \ud83d\udd00</li> <li>work from this branch \ud83d\udcbb</li> <li>when satisfied merge to main (then github actions will trigger) \u2705</li> </ul>"},{"location":"readme_github/#merge-to-main","title":"merge to main","text":"<p>from <code>Pull requests</code> tab, should automatically suggest <code>Compare &amp; pull request</code> </p> <p>then <code>View pull request</code> &gt; <code>Merge pull request</code> &gt; <code>Confirm merge</code> &gt; <code>Delete branch</code></p>"},{"location":"readme_github/#github-actions","title":"\ud83e\udd16 github actions","text":"<p>configured in <code>.github/workflows/ci.yml</code> \u2699\ufe0f</p>"},{"location":"readme_github/#tests-automatiques","title":"Tests automatiques","text":"<p>Le projet dispose de tests automatiques configur\u00e9s via GitHub Actions dans <code>.github/workflows/tests.yml</code> \ud83e\uddea</p>"},{"location":"readme_github/#configuration-des-tests","title":"Configuration des tests","text":"<ul> <li>Framework : pytest avec couverture de code</li> <li>Environnement : Python 3.12 sur Ubuntu Latest</li> <li>D\u00e9clenchement : Push et Pull Request sur toutes les branches</li> <li>Couverture minimale : 90% (configurable dans le workflow)</li> </ul>"},{"location":"readme_github/#structure-des-tests","title":"Structure des tests","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/                    # Tests unitaires par module\n\u2502   \u251c\u2500\u2500 test_config.py      # Tests nbs/config.py (97% couverture)\n\u2502   \u251c\u2500\u2500 test_mongo.py       # Tests nbs/mongo.py (98% couverture) \n\u2502   \u251c\u2500\u2500 test_llm.py         # Tests nbs/llm.py (100% couverture)\n\u2502   \u251c\u2500\u2500 test_rss.py         # Tests nbs/rss.py (100% couverture)\n\u2502   \u2514\u2500\u2500 test_fixtures.py    # Tests infrastructure donn\u00e9es\n\u251c\u2500\u2500 integration/             # Tests d'int\u00e9gration\n\u2502   \u2514\u2500\u2500 test_workflows.py   # Tests workflows RSS\u2192MongoDB\u2192LLM\n\u251c\u2500\u2500 ui/                     # Tests interface utilisateur\n\u2502   \u2514\u2500\u2500 test_streamlit.py   # Tests basiques Streamlit\n\u2514\u2500\u2500 fixtures/               # Donn\u00e9es de test\n    \u251c\u2500\u2500 sample_config.json\n    \u251c\u2500\u2500 sample_episode.json\n    \u251c\u2500\u2500 sample_transcription.txt\n    \u2514\u2500\u2500 sample_rss_feed.xml\n</code></pre>"},{"location":"readme_github/#commandes-de-test-locales","title":"Commandes de test locales","text":"<pre><code># Tous les tests\npytest\n\n# Tests avec couverture\npytest --cov=nbs --cov-report=term-missing\n\n# Tests sp\u00e9cifiques\npytest tests/unit/test_config.py -v\n\n# Rapport HTML de couverture  \npytest --cov=nbs --cov-report=html\n# Voir htmlcov/index.html\n</code></pre>"},{"location":"readme_github/#metriques-actuelles","title":"M\u00e9triques actuelles","text":"<ul> <li>Total : 124 tests (104 unitaires + 11 int\u00e9gration + 9 UI)</li> <li>Couverture modules test\u00e9s : 98.75% moyenne</li> <li><code>config.py</code> : 97%</li> <li><code>llm.py</code> : 100% </li> <li><code>mongo.py</code> : 98%</li> <li><code>rss.py</code> : 100%</li> <li>Statut : \u2705 Tous les tests passent</li> </ul>"},{"location":"readme_github/#integration-cicd","title":"Int\u00e9gration CI/CD","text":"<p>Le workflow <code>.github/workflows/tests.yml</code> :</p> <ol> <li>Installation : Python + d\u00e9pendances depuis <code>tests/requirements.txt</code></li> <li>Ex\u00e9cution : <code>pytest</code> avec couverture de code</li> <li>Validation : \u00c9choue si couverture &lt; 90% (sur modules test\u00e9s)</li> <li>Robustesse : Tests depuis r\u00e9pertoire externe pour valider portabilit\u00e9</li> </ol> <p>Voir \ud83d\udcd6 Guide complet des tests unitaires pour plus de d\u00e9tails.</p>"},{"location":"readme_google/","title":"about Google services","text":"<ul> <li>Google services\ud83d\ude80</li> <li>Create a Google project\ud83c\udf1f</li> <li>Dashboard\ud83d\udcca</li> <li>API key\ud83d\udd11</li> <li>Quotas\ud83d\udcc8</li> </ul>"},{"location":"readme_google/#google-services","title":"Google services\ud83d\ude80","text":"<p>To use Gemini or Search, I followed these steps \ud83d\ude0e</p>"},{"location":"readme_google/#create-a-google-project","title":"Create a Google project\ud83c\udf1f","text":"<p>Set it up on Google Cloud Console \ud83d\udda5\ufe0f. My project is named <code>lmelp</code> \ud83d\udd12 (please verify if this info is sensitive).</p>"},{"location":"readme_google/#dashboard","title":"Dashboard\ud83d\udcca","text":"<p>Check out an overview of your project. \ud83d\udd0d I have pinned a few awesome products that might be really useful \ud83d\udcaa</p> <p></p>"},{"location":"readme_google/#api-key","title":"API key\ud83d\udd11","text":"<p>From the dashboard, navigate to generate your API key \ud83d\ude80: Dashboard &gt; APIs &amp; Services &gt; Credentials \ud83d\udc49</p> <p></p> <p>I configured one with: \u2705 - Restricted IP access (my two homes \ud83c\udfe0) - Restricted API access \ud83d\udd10     - Custom Search API \ud83d\udd0d     - Gemini for Google Cloud API \ud83c\udf0c     - Generative Language API \ud83c\udf10</p> <p>Then, I added this key in <code>.env</code> to be used by the project under two entries: <code>GEMINI_API_KEY</code> and <code>GOOGLE_CUSTOM_SEARCH_API_KEY</code> \ud83d\udd11</p>"},{"location":"readme_google/#quotas","title":"Quotas\ud83d\udcc8","text":"<p>APIs have quotas and they can be accessed at \u2139\ufe0f</p> <p>Dashboard &gt; IAMs &amp; Admin &gt; Quotas \u27a1\ufe0f</p> <p>Or dedicated page per API: \ud83d\udc47</p> <p>Custom Search API \ud83d\udd0d</p> <p></p> <p>Gemini for Google Cloud API \ud83c\udf0c</p> <p>Generative Language API \ud83c\udf0c</p> <p>When out of quotas (rateLimitExceeded), service will answer Error 429 \u26a0\ufe0f:</p> <pre><code>Erreur lors de la recherche Google: &lt;HttpError 429 when requesting https://customsearch.googleapis.com/customsearch/v1?q=B%C3%A9n%C3%A9dicte+Lacapria&amp;cx=c2af590ab41ca4fac&amp;key=AIzaSyCE59lk7YhoSSL7T4vDRAPMv7yhYfWZTHg&amp;alt=json returned \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:my_project_number'.\". Details: \"[{'message': \"Quota exceeded for quota metric 'Queries' and limit 'Queries per day' of service 'customsearch.googleapis.com' for consumer 'project_number:my_project_number'.\", 'domain': 'global', 'reason': 'rateLimitExceeded'}]\"&gt;\n</code></pre> <p>Will find a way to properly handle this case. \ud83d\udc4d</p>"},{"location":"readme_import_strategy/","title":"Strat\u00e9gie d'imports - Projet LMELP","text":""},{"location":"readme_import_strategy/#vue-densemble","title":"Vue d'ensemble","text":"<p>Le projet LMELP utilise diff\u00e9rentes strat\u00e9gies d'imports selon le contexte, optimis\u00e9es pour chaque usage.</p>"},{"location":"readme_import_strategy/#strategies-par-contexte","title":"Strat\u00e9gies par contexte","text":""},{"location":"readme_import_strategy/#nbs-modules-principaux","title":"\ud83d\udcc1 <code>nbs/</code> - Modules principaux","text":"<p>Pattern : Imports directs (m\u00eame dossier)</p> <pre><code># \u2705 Dans nbs/mongo.py\nfrom config import get_DB_VARS\n</code></pre> <p>Justification : Modules dans le m\u00eame dossier, imports simples et directs.</p>"},{"location":"readme_import_strategy/#scripts-scripts-utilitaires","title":"\ud83d\udcc1 <code>scripts/</code> - Scripts utilitaires","text":"<p>Pattern : Ajout explicite au sys.path</p> <pre><code># \u2705 Dans scripts/*.py\nimport sys\nimport os\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"../nbs\")))\nfrom config import get_RSS_URL\n</code></pre> <p>Justification : Scripts ponctuels ex\u00e9cut\u00e9s depuis diff\u00e9rents endroits, besoin de chemin absolu.</p>"},{"location":"readme_import_strategy/#ui-interface-streamlit","title":"\ud83d\udcc1 <code>ui/</code> - Interface Streamlit","text":"<p>Pattern : Fonction centralis\u00e9e add_to_sys_path()</p> <pre><code># \u2705 Dans ui/pages/*.py  \nfrom ui_tools import add_to_sys_path\nadd_to_sys_path()\nfrom mongo_episode import Episodes\n</code></pre> <p>Justification : Apps Streamlit avec logique r\u00e9utilisable, fonction centralis\u00e9e dans ui_tools.py.</p>"},{"location":"readme_import_strategy/#tests-tests-unitaires","title":"\ud83d\udcc1 <code>tests/</code> - Tests unitaires","text":"<p>Pattern : Imports explicites avec chemin complet</p> <pre><code># \u2705 Dans tests/unit/*.py\nfrom nbs.config import get_RSS_URL\nfrom nbs.mongo import get_collection\n</code></pre> <p>Justification : Isolation maximale, tra\u00e7abilit\u00e9 claire, pas de modification sys.path.</p>"},{"location":"readme_import_strategy/#avantages-de-cette-approche","title":"Avantages de cette approche","text":"Contexte Avantage <code>nbs/</code> Simple, pas de configuration <code>scripts/</code> Portable, fonctionne de partout <code>ui/</code> Centralis\u00e9, facile \u00e0 maintenir <code>tests/</code> Isol\u00e9, explicite, pas d'effets de bord"},{"location":"readme_import_strategy/#convention-de-nommage-des-tests","title":"Convention de nommage des tests","text":"<pre><code>tests/unit/test_config.py     \u2190 teste nbs/config.py\ntests/unit/test_mongo.py      \u2190 teste nbs/mongo.py  \ntests/unit/test_llm.py        \u2190 teste nbs/llm.py\n</code></pre> <p>Pattern : <code>test_&lt;module&gt;.py</code> teste <code>nbs/&lt;module&gt;.py</code></p>"},{"location":"readme_import_strategy/#exemples-concrets","title":"Exemples concrets","text":""},{"location":"readme_import_strategy/#import-dans-un-test","title":"Import dans un test","text":"<pre><code># tests/unit/test_config.py\nfrom nbs.config import get_RSS_URL  # \u2705 Explicite et clair\n\ndef test_get_RSS_URL_with_env_var():\n    # Test code...\n</code></pre>"},{"location":"readme_import_strategy/#import-dans-un-script","title":"Import dans un script","text":"<pre><code># scripts/get_transcription.py\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"../nbs\")))\nfrom config import get_RSS_URL  # \u2705 Apr\u00e8s modification sys.path\n</code></pre>"},{"location":"readme_import_strategy/#import-dans-streamlit","title":"Import dans Streamlit","text":"<pre><code># ui/pages/episodes.py\nfrom ui_tools import add_to_sys_path\nadd_to_sys_path()\nfrom mongo_episode import Episodes  # \u2705 Apr\u00e8s add_to_sys_path()\n</code></pre>"},{"location":"readme_import_strategy/#modules-nbdev-et-tests","title":"Modules nbdev et tests","text":"<p>Les modules g\u00e9n\u00e9r\u00e9s par nbdev (dans le dossier <code>nbs/</code>) utilisent des imports non relatifs (ex\u00a0: <code>from mongo import BaseEntity</code>). Pour garantir leur fonctionnement dans les tests et scripts, il faut que le dossier <code>nbs/</code> soit inclus dans le PYTHONPATH.</p>"},{"location":"readme_import_strategy/#configuration-automatique-pour-les-tests","title":"Configuration automatique pour les tests","text":"<p>Le fichier <code>tests/conftest.py</code> ajoute automatiquement le dossier <code>nbs/</code> au PYTHONPATH pour tous les tests\u00a0:</p> <pre><code>import sys\nimport os\nnbs_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'nbs'))\nif nbs_path not in sys.path:\n    sys.path.insert(0, nbs_path)\n</code></pre>"},{"location":"readme_import_strategy/#bonnes-pratiques","title":"Bonnes pratiques","text":"<ul> <li>Ne pas modifier les imports dans les fichiers g\u00e9n\u00e9r\u00e9s par nbdev.</li> <li>Centraliser la gestion du PYTHONPATH dans la config de test (conftest.py).</li> <li>Pour ex\u00e9cuter les tests manuellement\u00a0: <code>PYTHONPATH=nbs pytest ...</code></li> </ul>"},{"location":"readme_import_strategy/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>nbdev documentation</li> <li>pytest conftest.py</li> </ul>"},{"location":"readme_import_strategy/#evolutions-futures","title":"\u00c9volutions futures","text":"<p>Si le projet grandit, consid\u00e9rer : - Package Python installable : <code>pip install -e .</code> pour d\u00e9veloppement - Imports absolus partout : <code>from lmelp.config import get_RSS_URL</code> - Structure package standard : <code>src/lmelp/</code> layout</p> <p>Pour l'instant, le status quo fonctionne bien et respecte les contraintes de chaque contexte.</p>"},{"location":"readme_markdown/","title":"write markdown","text":"<ul> <li>\ud83d\udcd8 How to properly write usefull markdown files (.md) in this project</li> <li>\ud83d\udee0\ufe0f Standard vscode options</li> <li>\u2728 Markdown All in One vscode extension<ul> <li>\u2328\ufe0f shortcuts</li> <li>\ud83d\udcd1 table of contents</li> </ul> </li> <li>\ud83d\ude0a emojis</li> <li>\ud83d\uddbc\ufe0f images</li> </ul>"},{"location":"readme_markdown/#how-to-properly-write-usefull-markdown-files-md-in-this-project","title":"\ud83d\udcd8 How to properly write usefull markdown files (.md) in this project","text":""},{"location":"readme_markdown/#standard-vscode-options","title":"\ud83d\udee0\ufe0f Standard vscode options","text":"<p><code>Ctrl-k V</code> to open preview to the side \ud83d\udc40</p>"},{"location":"readme_markdown/#markdown-all-in-one-vscode-extension","title":"\u2728 Markdown All in One vscode extension","text":"<p>It helps with all you need for Markdown (keyboard shortcuts, table of contents, auto preview and more) \ud83e\udd16</p>"},{"location":"readme_markdown/#shortcuts","title":"\u2328\ufe0f shortcuts","text":"<p><code>Ctrl-B</code> to toggle bold \ud83d\udcaa</p>"},{"location":"readme_markdown/#table-of-contents","title":"\ud83d\udcd1 table of contents","text":"<p>Run command \"Create Table of Contents\" (in the VS Code Command Palette) to insert a new table of contents \ud83d\udd16</p>"},{"location":"readme_markdown/#emojis","title":"\ud83d\ude0a emojis","text":"<p>Use GitHub Copilot Rewrite: Modify using Copilot \ud83e\udd16</p> <p> \ud83d\uddbc\ufe0f</p> <p>Select everything, modify using Copilot with this prompt \u270d\ufe0f</p> <pre><code>Add nice emojis to this markdown text.\nIt has to be informative and helpful.\nNo more than 1 emoji per line.\nI would like emojis at beginning of text (after #s though) for titles or sections, \nand at end of line for regular lines.\n</code></pre>"},{"location":"readme_markdown/#images","title":"\ud83d\uddbc\ufe0f images","text":"<p>put them in <code>docs/img</code> \ud83d\udcc2</p>"},{"location":"readme_unit_test/","title":"Guide des Tests Unitaires \ud83e\uddea","text":""},{"location":"readme_unit_test/#vue-densemble","title":"Vue d'ensemble","text":"<p>Le projet LMELP utilise pytest comme framework de tests avec une approche de mocking complet pour isoler les tests de l'environnement ext\u00e9rieur (MongoDB, APIs, syst\u00e8me de fichiers).</p>"},{"location":"readme_unit_test/#architecture-des-tests","title":"Architecture des Tests","text":""},{"location":"readme_unit_test/#structure-des-dossiers","title":"Structure des Dossiers","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py                 # Package principal\n\u251c\u2500\u2500 conftest.py                # Configuration globale et fixtures\n\u251c\u2500\u2500 requirements.txt           # \ud83c\udd95 D\u00e9pendances minimales pour tests\n\u251c\u2500\u2500 fixtures/                  # \ud83c\udd95 Donn\u00e9es de test et utilitaires\n\u2502   \u251c\u2500\u2500 __init__.py           #     Fonctions load_sample_json/text\n\u2502   \u2514\u2500\u2500 data/                 #     Donn\u00e9es d'exemple\n\u2502       \u2514\u2500\u2500 sample_config.json\n\u2514\u2500\u2500 unit/                      # Tests unitaires\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_config.py         # Tests du module nbs/config.py\n    \u251c\u2500\u2500 test_fixtures.py       # \ud83c\udd95 Tests infrastructure fixtures\n    \u2514\u2500\u2500 test_mongo.py          # Tests du module nbs/mongo.py (\u00e0 venir)\n\n# Infrastructure CI/CD\n.env.test                      # \ud83c\udd95 Variables d'environnement de test\n.github/workflows/tests.yml    # \ud83c\udd95 GitHub Actions pour CI/CD\n</code></pre>"},{"location":"readme_unit_test/#configuration","title":"Configuration","text":"<ul> <li>pytest.ini : Configuration principale avec chemins et options + pytest-env</li> <li>.env.test : Variables d'environnement isol\u00e9es pour tests</li> <li>tests/requirements.txt : D\u00e9pendances optimis\u00e9es (sans PyTorch/ML)</li> <li>conftest.py : Fixtures globales et fonction <code>load_env_test()</code></li> </ul>"},{"location":"readme_unit_test/#infrastructure-cicd","title":"Infrastructure CI/CD \ud83d\ude80","text":""},{"location":"readme_unit_test/#github-actions","title":"GitHub Actions","text":"<p>Le projet utilise GitHub Actions pour l'int\u00e9gration continue avec un workflow optimis\u00e9 :</p> <pre><code># .github/workflows/tests.yml\nname: Tests Unitaires\non:\n  push:\n    branches: [ main, develop, \"**devops**\", \"**test**\" ]\n  pull_request:\n    branches: [ main, develop ]\n</code></pre> <p>Optimisations cl\u00e9s : - \u2705 D\u00e9pendances minimales : <code>pip install -r tests/requirements.txt</code> (30s vs 2m30s) - \u2705 Coverage cibl\u00e9e : <code>--cov=nbs.config</code> (97% sur module test\u00e9) - \u2705 Chemins portables : Fonction <code>get_project_root()</code> pour dev/CI - \u2705 Tests robustesse : Validation CI/CD depuis <code>/tmp</code></p>"},{"location":"readme_unit_test/#performance","title":"Performance","text":"Avant Apr\u00e8s Gain 2m30s installation 30s installation 5x plus rapide Tests sur tout <code>nbs/</code> Tests sur <code>nbs.config</code> Focus cibl\u00e9 Chemins absolus Chemins relatifs Portable"},{"location":"readme_unit_test/#frameworks-et-outils","title":"Frameworks et Outils","text":""},{"location":"readme_unit_test/#dependances","title":"D\u00e9pendances","text":"<pre><code># tests/requirements.txt - D\u00e9pendances minimales optimis\u00e9es\npytest&gt;=7.0           # Framework de tests\npytest-mock&gt;=3.10     # Mocking avanc\u00e9\npytest-env&gt;=0.8       # Variables d'environnement\npytest-cov&gt;=4.0       # Couverture de code\npython-dotenv&gt;=1.0.0  # Gestion .env\nPyYAML&gt;=6.0           # Parsing YAML (workflow tests)\nrequests&gt;=2.25.0      # HTTP (tests futurs)\n</code></pre>"},{"location":"readme_unit_test/#patterns-de-test","title":"Patterns de Test","text":""},{"location":"readme_unit_test/#1-structure-arrange-act-assert","title":"1. Structure ARRANGE-ACT-ASSERT","text":"<pre><code>def test_example_function(self, monkeypatch):\n    # ARRANGE : Pr\u00e9parer les donn\u00e9es et mocks\n    test_value = \"example\"\n    monkeypatch.setenv(\"TEST_VAR\", test_value)\n\n    # ACT : Ex\u00e9cuter la fonction \u00e0 tester\n    result = function_to_test()\n\n    # ASSERT : V\u00e9rifier les r\u00e9sultats\n    assert result == expected_value\n</code></pre>"},{"location":"readme_unit_test/#2-mocking-avec-monkeypatch","title":"2. Mocking avec Monkeypatch","text":"<pre><code># Variables d'environnement\nmonkeypatch.setenv(\"API_KEY\", \"fake_key\")\nmonkeypatch.delenv(\"OPTIONAL_VAR\", raising=False)\n\n# Fonctions et m\u00e9thodes\ndef mock_function():\n    return \"fake_result\"\n\nmonkeypatch.setattr(\"module.real_function\", mock_function)\n</code></pre>"},{"location":"readme_unit_test/#3-organisation-en-classes","title":"3. Organisation en Classes","text":"<pre><code>class TestConfigModule:\n    \"\"\"Tests pour le module de configuration\"\"\"\n\n    def test_specific_feature(self, monkeypatch):\n        # Test sp\u00e9cifique\n        pass\n</code></pre>"},{"location":"readme_unit_test/#strategies-de-mocking","title":"Strat\u00e9gies de Mocking","text":""},{"location":"readme_unit_test/#1-isolation-complete","title":"1. Isolation Compl\u00e8te","text":"<p>Principe : Aucun test ne doit d\u00e9pendre de ressources externes.</p> <pre><code># \u274c Mauvais : Test d\u00e9pend de MongoDB r\u00e9el\ndef test_save_entity():\n    entity = Entity(\"test\")\n    entity.save()  # Sauvegarde dans la vraie DB\n\n# \u2705 Bon : Test avec MongoDB mock\u00e9\n@patch('module.get_collection')\ndef test_save_entity(mock_get_collection):\n    mock_collection = Mock()\n    mock_get_collection.return_value = mock_collection\n\n    entity = Entity(\"test\")\n    entity.save()\n\n    mock_collection.insert_one.assert_called_once()\n</code></pre>"},{"location":"readme_unit_test/#11-mocking-des-dependances-lourdes-mlia","title":"1.1. Mocking des D\u00e9pendances Lourdes (ML/IA) \ud83e\udd16","text":"<p>Probl\u00e8me : Les d\u00e9pendances ML comme PyTorch, transformers, llama_index sont lourdes et causent des \u00e9checs en CI/CD.</p> <p>Solution : Mock pr\u00e9coce au niveau <code>sys.modules</code> avant tout import.</p> <pre><code>import sys\nfrom unittest.mock import Mock\n\n# \ud83d\udd25 CRITIQUE : Mocking AVANT les imports\n# Mock des modules ML lourds\nsys.modules['torch'] = Mock()\nsys.modules['transformers'] = Mock()\nsys.modules['datasets'] = Mock()\n\n# Mock des modules syst\u00e8me probl\u00e9matiques\nsys.modules['dbus'] = Mock()\nsys.modules['dbus.mainloop'] = Mock()\nsys.modules['dbus.mainloop.glib'] = Mock()\n\n# Mock des modules LlamaIndex et sous-modules\nsys.modules['llama_index'] = Mock()\nsys.modules['llama_index.core'] = Mock()\nsys.modules['llama_index.core.base'] = Mock()\nsys.modules['llama_index.core.base.embeddings'] = Mock()\nsys.modules['llama_index.embeddings'] = Mock()\nsys.modules['llama_index.embeddings.azure_openai'] = Mock()\n\n# Mock des modules Google AI\nsys.modules['google'] = Mock()\nsys.modules['google.generativeai'] = Mock()\nsys.modules['google.oauth2'] = Mock()\nsys.modules['google.oauth2.service_account'] = Mock()\n\n# PUIS seulement apr\u00e8s, importer le module \u00e0 tester\nfrom nbs.mongo_episode import MongoEpisode\n</code></pre> <p>Cas d'Usage Typiques :</p> <pre><code>class TestMongoEpisodeWithML:\n    \"\"\"Tests n\u00e9cessitant du mocking ML complet\"\"\"\n\n    def setup_method(self):\n        \"\"\"Mocking pr\u00e9coce pour chaque test\"\"\"\n        # D\u00e9j\u00e0 fait au niveau module, mais on peut renforcer\n        pass\n\n    def test_transcription_without_torch(self):\n        \"\"\"Test de transcription sans installer PyTorch\"\"\"\n        # Le module est d\u00e9j\u00e0 mock\u00e9, on peut tester la logique\n        episode = MongoEpisode()\n        # Test de la logique m\u00e9tier sans d\u00e9pendances ML\n        assert episode.collection_name == \"episodes\"\n</code></pre> <p>\u26a0\ufe0f Points Critiques : - Le mocking doit \u00eatre fait AVANT tout import du module test\u00e9 - Utiliser <code>sys.modules</code> plut\u00f4t que <code>@patch</code> pour les d\u00e9pendances transversales - Mocker les sous-modules \u00e9galement (ex: <code>llama_index.core.base</code>) - Tester en environnement propre (ex: nouveau terminal) pour valider</p>"},{"location":"readme_unit_test/#2-variables-denvironnement","title":"2. Variables d'Environnement","text":"<pre><code>def test_config_with_env(self, monkeypatch):\n    # Test avec variable d\u00e9finie\n    monkeypatch.setenv(\"API_KEY\", \"test_key\")\n    result = get_api_key()\n    assert result == \"test_key\"\n\ndef test_config_without_env(self, monkeypatch):\n    # Test sans variable (valeur par d\u00e9faut)\n    monkeypatch.delenv(\"API_KEY\", raising=False)\n    result = get_api_key()\n    assert result is None  # ou valeur par d\u00e9faut\n</code></pre>"},{"location":"readme_unit_test/#3-mocking-de-classes-et-methodes","title":"3. Mocking de Classes et M\u00e9thodes","text":"<pre><code>@patch('nbs.mongo.pymongo.MongoClient')\ndef test_database_connection(mock_client):\n    mock_db = Mock()\n    mock_client.return_value = {\"test_db\": mock_db}\n\n    collection = get_collection(\"localhost\", \"test_db\", \"test_coll\")\n\n    mock_client.assert_called_once_with(\"mongodb://localhost:27017/\")\n</code></pre>"},{"location":"readme_unit_test/#fixtures-globales","title":"Fixtures Globales","text":""},{"location":"readme_unit_test/#fixtures-disponibles-conftestpy","title":"Fixtures Disponibles (conftest.py)","text":"<pre><code>@pytest.fixture\ndef test_environment():\n    \"\"\"Environnement de test isol\u00e9\"\"\"\n\n@pytest.fixture  \ndef mock_mongodb():\n    \"\"\"Mock complet de MongoDB\"\"\"\n\n@pytest.fixture\ndef test_config():\n    \"\"\"Configuration de test standard\"\"\"\n</code></pre>"},{"location":"readme_unit_test/#utilisation-des-fixtures","title":"Utilisation des Fixtures","text":"<pre><code>def test_with_fixtures(self, test_environment, mock_mongodb):\n    # Les fixtures sont automatiquement inject\u00e9es\n    # test_environment et mock_mongodb sont disponibles\n    pass\n</code></pre>"},{"location":"readme_unit_test/#couverture-de-code","title":"Couverture de Code","text":""},{"location":"readme_unit_test/#mesurer-la-couverture","title":"Mesurer la Couverture","text":"<pre><code># Couverture pour un module\npytest tests/unit/test_config.py --cov=nbs.config --cov-report=term-missing\n\n# Couverture globale\npytest --cov=nbs --cov-report=html\n\n# Couverture avec seuil minimum\npytest --cov=nbs --cov-fail-under=90\n</code></pre>"},{"location":"readme_unit_test/#interpreter-les-resultats","title":"Interpr\u00e9ter les R\u00e9sultats","text":"<pre><code>Name            Stmts   Miss  Cover   Missing\n---------------------------------------------\nnbs/config.py      60      2    97%   43, 154\n---------------------------------------------\nTOTAL              60      2    97%\n</code></pre> <ul> <li>Stmts : Nombre total de lignes de code</li> <li>Miss : Lignes non test\u00e9es</li> <li>Cover : Pourcentage de couverture</li> <li>Missing : Num\u00e9ros de lignes manquantes</li> </ul>"},{"location":"readme_unit_test/#objectifs-de-couverture","title":"Objectifs de Couverture","text":"<ul> <li>Minimum acceptable : 80%</li> <li>Objectif : 90%+</li> <li>Excellence : 95%+</li> </ul>"},{"location":"readme_unit_test/#commandes-principales","title":"Commandes Principales","text":""},{"location":"readme_unit_test/#execution-des-tests","title":"Ex\u00e9cution des Tests","text":"<pre><code># Tous les tests\npytest\n\n# Tests avec verbosit\u00e9\npytest -v\n\n# Tests sp\u00e9cifiques\npytest tests/unit/test_config.py\npytest tests/unit/test_config.py::TestConfig::test_specific\n\n# Tests avec pattern\npytest -k \"test_config\"\n</code></pre>"},{"location":"readme_unit_test/#debug-et-developpement","title":"Debug et D\u00e9veloppement","text":"<pre><code># Arr\u00eater au premier \u00e9chec\npytest -x\n\n# Mode debug avec pdb\npytest --pdb\n\n# Afficher les print()\npytest -s\n\n# Tests en parall\u00e8le (avec pytest-xdist)\npytest -n auto\n</code></pre>"},{"location":"readme_unit_test/#rapports","title":"Rapports","text":"<pre><code># Rapport HTML de couverture\npytest --cov=nbs --cov-report=html\n# Voir tests/htmlcov/index.html\n\n# Rapport XML (pour CI/CD)\npytest --cov=nbs --cov-report=xml\n\n# Rapport JUnit\npytest --junit-xml=tests/results.xml\n</code></pre>"},{"location":"readme_unit_test/#bonnes-pratiques","title":"Bonnes Pratiques","text":""},{"location":"readme_unit_test/#1-nommage","title":"1. Nommage","text":"<ul> <li>Fichiers : <code>test_module_name.py</code></li> <li>Classes : <code>TestModuleName</code></li> <li>Fonctions : <code>test_specific_behavior</code></li> </ul>"},{"location":"readme_unit_test/#2-documentation","title":"2. Documentation","text":"<pre><code>def test_function_behavior(self, monkeypatch):\n    \"\"\"Test que la fonction retourne la valeur attendue quand X\"\"\"\n    # Commentaires expliquant les \u00e9tapes complexes\n</code></pre>"},{"location":"readme_unit_test/#3-isolation","title":"3. Isolation","text":"<ul> <li>Chaque test doit \u00eatre ind\u00e9pendant</li> <li>Utiliser des mocks pour les d\u00e9pendances externes</li> <li>Nettoyer apr\u00e8s chaque test (automatique avec fixtures)</li> </ul>"},{"location":"readme_unit_test/#4-lisibilite","title":"4. Lisibilit\u00e9","text":"<ul> <li>Un test = Un comportement</li> <li>Arrange-Act-Assert clairement s\u00e9par\u00e9s</li> <li>Noms explicites pour les variables de test</li> </ul>"},{"location":"readme_unit_test/#5-mocking-des-dependances-lourdes-lecons-github-actions","title":"5. Mocking des D\u00e9pendances Lourdes (Le\u00e7ons GitHub Actions) \ud83d\ude80","text":"<p>Probl\u00e8me R\u00e9solu : Import failures en CI/CD avec d\u00e9pendances ML/IA</p> <p>Strat\u00e9gie Gagnante : 1. Mock pr\u00e9coce : <code>sys.modules</code> avant imports 2. Mock exhaustif : Inclure tous les sous-modules 3. Test isolated : Valider en environnement propre 4. Requirements split : <code>tests/requirements.txt</code> minimal</p> <pre><code># Pattern \u00e9prouv\u00e9 pour nouveaux tests ML\nimport sys\nfrom unittest.mock import Mock\n\n# Mock AVANT imports (dans l'ordre de d\u00e9couverte des erreurs)\nsys.modules['torch'] = Mock()\nsys.modules['transformers'] = Mock() \nsys.modules['dbus'] = Mock()\nsys.modules['llama_index'] = Mock()\nsys.modules['google.generativeai'] = Mock()\n\n# Puis import du module\nfrom nbs.module_with_ml import ModuleToTest\n</code></pre> <p>M\u00e9triques de Succ\u00e8s : - \u2705 214 tests passent en GitHub Actions - \u2705 Installation CI : 30s (vs 2m30s avant) - \u2705 Couverture maintenue : 72.72% - \u2705 Z\u00e9ro d\u00e9pendance ML en tests</p>"},{"location":"readme_unit_test/#patterns-avances","title":"Patterns Avanc\u00e9s","text":""},{"location":"readme_unit_test/#1-mocking-de-hierarchies-complexes","title":"1. Mocking de Hi\u00e9rarchies Complexes","text":"<pre><code>class MockRepo:\n    def __init__(self, path, search_parent_directories=True):\n        self.git = MockGit()\n\nclass MockGit:\n    def rev_parse(self, option):\n        return \"/fake/git/root\"\n\nmonkeypatch.setattr(\"nbs.config.Repo\", MockRepo)\n</code></pre>"},{"location":"readme_unit_test/#2-tests-parametres","title":"2. Tests Param\u00e9tr\u00e9s","text":"<pre><code>@pytest.mark.parametrize(\"input,expected\", [\n    (\"test1\", \"result1\"),\n    (\"test2\", \"result2\"),\n    (\"test3\", \"result3\"),\n])\ndef test_multiple_cases(input, expected):\n    assert function(input) == expected\n</code></pre>"},{"location":"readme_unit_test/#3-tests-dexception","title":"3. Tests d'Exception","text":"<pre><code>def test_function_raises_error():\n    with pytest.raises(ValueError, match=\"Expected error message\"):\n        function_that_should_fail()\n</code></pre>"},{"location":"readme_unit_test/#depannage","title":"D\u00e9pannage","text":""},{"location":"readme_unit_test/#problemes-courants","title":"Probl\u00e8mes Courants","text":""},{"location":"readme_unit_test/#variables-denvironnement-persistantes","title":"Variables d'Environnement Persistantes","text":"<pre><code># \u274c Les vraies variables interf\u00e8rent\ndef test_without_env():\n    result = get_env_var()  # Utilise la vraie variable !\n\n# \u2705 Mock complet\ndef test_without_env(self, monkeypatch):\n    def mock_getenv(key, default=None):\n        return None\n    monkeypatch.setattr(os, \"getenv\", mock_getenv)\n</code></pre>"},{"location":"readme_unit_test/#imports-et-paths","title":"Imports et Paths","text":"<pre><code># \u2705 Imports explicites pour les tests\nfrom nbs.config import function_to_test\n\n# \u2705 Mocking avec le path complet\nmonkeypatch.setattr(\"nbs.config.function\", mock_function)\n</code></pre>"},{"location":"readme_unit_test/#debug-des-tests","title":"Debug des Tests","text":"<pre><code># Afficher les valeurs pour debug\ndef test_debug(self, monkeypatch):\n    result = function()\n    print(f\"Debug: result = {result}\")  # Visible avec pytest -s\n    assert result == expected\n</code></pre>"},{"location":"readme_unit_test/#evolution-et-maintenance","title":"\u00c9volution et Maintenance","text":""},{"location":"readme_unit_test/#ajout-de-nouveaux-tests","title":"Ajout de Nouveaux Tests","text":"<ol> <li>Identifier le module \u00e0 tester</li> <li>Cr\u00e9er le fichier <code>test_module.py</code></li> <li>D\u00e9finir les classes et m\u00e9thodes de test</li> <li>Impl\u00e9menter les mocks n\u00e9cessaires</li> <li>V\u00e9rifier la couverture</li> </ol>"},{"location":"readme_unit_test/#refactoring","title":"Refactoring","text":"<ul> <li>Maintenir la couverture lors des changements</li> <li>Adapter les mocks aux nouvelles signatures</li> <li>Regrouper les fixtures communes</li> </ul> <p>Ce guide \u00e9volue avec le projet. N'h\u00e9sitez pas \u00e0 l'enrichir ! \ud83d\ude80</p>"},{"location":"readme_uv_devcontainer/","title":"devcontainer and uv","text":"<p>As explained in README, this project uses devcontainer and uv.</p>"},{"location":"readme_uv_devcontainer/#devcontainer","title":"devcontainer","text":"<p>Everything is in <code>.devcontainer</code></p>"},{"location":"readme_uv_devcontainer/#update-requirements","title":"update requirements","text":"<p>make modifications in <code>.devcontainer/requirements.txt</code></p> <p>to apply modifications </p> <pre><code>source .venv/bin/activate\nexport UV_LINK_MODE=copy\nuv pip install -r .devcontainer/requirements.txt\n</code></pre> <p>(or you can decide to rebuild devcontainer but it is longer)</p>"},{"location":"readme_uv_devcontainer/#venv","title":"venv","text":"<p>on this project, virtualenv is in <code>.venv</code></p>"},{"location":"readme_uv_devcontainer/#uv","title":"uv","text":"<p>to execute python code from our venv,</p> <pre><code>source .venv/bin/activate\nuv run python --version\n</code></pre>"},{"location":"readme_vscode_hints/","title":"some vs_code hints","text":"<ul> <li>\ud83d\udee0\ufe0f Vscode hints</li> <li>\ud83d\udd04 multicurseur pour remplacer des variables par ex</li> <li>\ud83d\udccb multicurseur sur chaque ligne d'un texte</li> <li>\ud83d\ude48 cacher un repertoire du workspace (par exemple pycache)</li> <li>\u2328\ufe0f ctrl-c ctrl-v dans le terminal</li> <li>\ud83d\udd0c ajouter des sources pour pylance</li> <li>\ud83d\udc0d tester un petit code python en REPL</li> <li>\ud83d\udcdd editer des fichiers markdown</li> <li>\ud83d\udce6 utiliser dev container</li> </ul>"},{"location":"readme_vscode_hints/#vscode-hints","title":"\ud83d\udee0\ufe0f Vscode hints","text":""},{"location":"readme_vscode_hints/#multicurseur-pour-remplacer-des-variables-par-ex","title":"\ud83d\udd04 multicurseur pour remplacer des variables par ex","text":"<p>sur le mot <code>Ctrl-d</code> autant de fois que le nombre de variable \u00e0 remplacer \ud83d\udca1</p>"},{"location":"readme_vscode_hints/#multicurseur-sur-chaque-ligne-dun-texte","title":"\ud83d\udccb multicurseur sur chaque ligne d'un texte","text":"<p>(pour inserer un &gt; par ex en debut de ligne) \u27a1\ufe0f selection du texte puis <code>Shift-Alt-i</code> \ud83d\udc49</p>"},{"location":"readme_vscode_hints/#cacher-un-repertoire-du-workspace-par-exemple-pycache","title":"\ud83d\ude48 cacher un repertoire du workspace (par exemple pycache)","text":"<p>ouvrir settings.json : <code>Ctrl-Shift-p</code> et taper Preferences: Open Settings (JSON) \u2699\ufe0f ajouter une entree dans <code>files.exclude</code> \u2795</p> <pre><code>    \"files.exclude\": {\n        \"**/.git\": true,\n        \"**/__pycache__\": true,\n        \"**/.ipynb_checkpoints\": true,\n        \"**/.venv\": true,\n    },\n</code></pre>"},{"location":"readme_vscode_hints/#ctrl-c-ctrl-v-dans-le-terminal","title":"\u2328\ufe0f ctrl-c ctrl-v dans le terminal","text":"<pre><code>Go to \u2018Preferences &gt; Keyboard Shortcuts\u2019\nSet the \u2018Terminal: Copy Selection\u2019 keybindings to Ctrl-C\nSet the \u2018Terminal: Paste into Active Terminal\u2019 keybinding to Ctrl-V\n</code></pre> <p>And that seemed to be that. When there is a selection Ctrl-C will copy without sending SIGINT and if there is no selection VS Code sends a SIGINT \ud83d\udca1</p>"},{"location":"readme_vscode_hints/#ajouter-des-sources-pour-pylance","title":"\ud83d\udd0c ajouter des sources pour pylance","text":"<p>ouvrir settings.json : <code>Ctrl-Shift-p</code> et taper Preferences: Open Settings (JSON) \u2699\ufe0f ajouter une entree dans <code>python.analysis.extraPaths</code> \u2795</p> <pre><code>    \"python.analysis.extraPaths\": [\n        \"./nbs\"\n    ],\n</code></pre>"},{"location":"readme_vscode_hints/#tester-un-petit-code-python-en-repl","title":"\ud83d\udc0d tester un petit code python en REPL","text":"<p>doc vscode native REPL \ud83d\udd17  </p> <p>You can open the Native REPL via the Command Palette (Ctrl+Shift+P) by searching for Python: Start Native REPL. Furthermore, you can send code to the Native REPL via Smart Send (Shift+Enter) and Run Selection/Line in Python REPL by setting <code>\"python.REPL.sendToNativeREPL\": true</code> in your settings.json file. \ud83d\ude80  </p> <p>ca fait tourner un notebook Untitled-1.ipnb juste a cote. \ud83d\udd0d</p>"},{"location":"readme_vscode_hints/#editer-des-fichiers-markdown","title":"\ud83d\udcdd editer des fichiers markdown","text":"<p>readme_markdown \ud83d\udcc4</p>"},{"location":"readme_vscode_hints/#utiliser-dev-container","title":"\ud83d\udce6 utiliser dev container","text":"<p>Ressources: \ud83d\udcda</p> <ul> <li>vscode doc website Create a dev container \ud83d\udcd6</li> <li>youtube Get Started with Dev Containers in VS Code \ud83c\udfa5</li> <li>youtube Beginner's Series to: Dev Containers \ud83c\udfac</li> </ul> <p>Etapes: \ud83d\udcdd</p> <ol> <li>installer <code>dev containers</code> extension \u2b07\ufe0f</li> <li>palette: <code>Dev Containers: Add Dev Container Configuration Files...</code> using ms-python3, <code>Reopen in Container</code> \ud83c\udfa8</li> <li>extensions: les extensions installees localement qui m'interessent pour ce projet, <code>Manage &gt; Add to devcontainer.json</code>, et en sauvant je rebuilde le container \ud83d\udd27</li> <li>requirements: les lib python necessaires pour ce projet \ud83d\udccc</li> <li>postCommand.sh: j'installe cmake et dbus (pour supprimer la mise en veille), la locale fr_FR.UTF-8 pour la conversion de dates, les libs python, pre-commit et le safe.directory git (car les utilisateurs host et docker sont differents) \u26a1</li> <li>runArgs: \ud83d\ude80  </li> <li><code>--network=host</code> pour acceder au container depuis le host (pour streamlit) \ud83c\udf10  </li> <li><code>--label com.centurylinklabs.watchtower.enable=false</code> pour exclure le container de la mise a jour watchtower \ud83d\udeab  </li> <li><code>--env CONTAINER_NAME=vscode-dev-container-lmelp</code> pour retrouver le nom du container depuis un script execute depuis host \ud83c\udd94</li> <li>forwardPorts pour acceder a streamlit \ud83d\udd00</li> <li>shutdownAction a \"none\" pour empecher que le container ne s'arrete a la sortie de vscode (utile pour lancer les scripts ou streamlit) \ud83d\uded1</li> </ol> <p>A chaque modification, faire un <code>Dev Containers: Rebuild Container</code>. </p> <p>Depuis Windows+WSL, il faut activer <code>Dev&gt;Containers: Execute in WSL</code>, cela utilisera le docker de WSL et pas le docker Windows (que je n'ai pas) \ud83d\udc33</p> <p></p> <p>Voir dans <code>.devcontainer</code> pour le detail. \ud83d\udcc2</p>"},{"location":"rss/","title":"Module rss","text":""},{"location":"rss/#rss.Podcast","title":"<code>Podcast</code>","text":"Source code in <code>nbs/rss.py</code> <pre><code>class Podcast:\n    def __init__(self):\n        \"\"\"\n        Initialise la classe Podcast en analysant le flux RSS et en obtenant la collection MongoDB.\n        \"\"\"\n        self.parsed_flow = feedparser.parse(get_RSS_URL())\n        DB_HOST, DB_NAME, _ = get_DB_VARS()\n        self.collection = get_collection(\n            target_db=DB_HOST, client_name=DB_NAME, collection_name=\"episodes\"\n        )\n\n    def get_most_recent_episode_from_DB(self) -&gt; Optional[datetime]:\n        \"\"\"\n        R\u00e9cup\u00e8re la date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s dans la base de donn\u00e9es.\n\n        Returns:\n            Optional[datetime]: La date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s, ou None si aucun \u00e9pisode n'est trouv\u00e9.\n        \"\"\"\n        most_recent_document = self.collection.find().sort({\"date\": -1}).limit(1)\n        most_recent_date = None\n        for doc in most_recent_document:\n            most_recent_date = doc[\"date\"].replace(tzinfo=pytz.timezone(\"Europe/Paris\"))\n        return most_recent_date\n\n    def list_last_large_episodes(\n        self, duree_mini_minutes: int = 15\n    ) -&gt; List[FeedParserDict]:\n        \"\"\"\n        Liste les \u00e9pisodes RSS qui sont plus r\u00e9cents que le plus r\u00e9cent \u00e9pisode stock\u00e9 dans la base de donn\u00e9es\n        et qui durent plus de `duree_mini_minutes` minutes.\n\n        Args:\n            duree_mini_minutes (int): La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 lister. Par d\u00e9faut \u00e0 15 minutes.\n\n        Returns:\n            List[FeedParserDict]: Une liste d'entr\u00e9es RSS correspondant aux crit\u00e8res.\n        \"\"\"\n        last_large_episodes = []\n        for entry in self.parsed_flow.entries:\n            date_rss = datetime.strptime(entry.published, RSS_DATE_FORMAT)\n            date_db = self.get_most_recent_episode_from_DB()\n            if date_db and date_rss &gt; date_db:\n                if (\n                    RSS_episode.get_duree_in_seconds(entry.itunes_duration)\n                    &gt; duree_mini_minutes * 60\n                ):\n                    last_large_episodes.append(entry)\n        return last_large_episodes\n\n    def store_last_large_episodes(self, duree_mini_minutes: int = 15) -&gt; None:\n        \"\"\"\n        Parcourt la liste des \u00e9pisodes longs r\u00e9cents, instancie RSS_episode et les conserve dans la base de donn\u00e9es.\n        Affiche le nombre de mises \u00e0 jour r\u00e9ussies dans la base de donn\u00e9es.\n\n        Args:\n            duree_mini_minutes (int): La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 stocker. Par d\u00e9faut \u00e0 15 minutes.\n        \"\"\"\n        updates = 0\n        last_large_episodes = self.list_last_large_episodes(duree_mini_minutes)\n        for entry in last_large_episodes:\n            rss_entry = RSS_episode.from_feed_entry(entry)\n            updates += rss_entry.keep()\n        print(f\"Updated episodes: {updates}\")\n</code></pre>"},{"location":"rss/#rss.Podcast.__init__","title":"<code>__init__()</code>","text":"<p>Initialise la classe Podcast en analysant le flux RSS et en obtenant la collection MongoDB.</p> Source code in <code>nbs/rss.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialise la classe Podcast en analysant le flux RSS et en obtenant la collection MongoDB.\n    \"\"\"\n    self.parsed_flow = feedparser.parse(get_RSS_URL())\n    DB_HOST, DB_NAME, _ = get_DB_VARS()\n    self.collection = get_collection(\n        target_db=DB_HOST, client_name=DB_NAME, collection_name=\"episodes\"\n    )\n</code></pre>"},{"location":"rss/#rss.Podcast.get_most_recent_episode_from_DB","title":"<code>get_most_recent_episode_from_DB()</code>","text":"<p>R\u00e9cup\u00e8re la date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s dans la base de donn\u00e9es.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: La date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s, ou None si aucun \u00e9pisode n'est trouv\u00e9.</p> Source code in <code>nbs/rss.py</code> <pre><code>def get_most_recent_episode_from_DB(self) -&gt; Optional[datetime]:\n    \"\"\"\n    R\u00e9cup\u00e8re la date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s dans la base de donn\u00e9es.\n\n    Returns:\n        Optional[datetime]: La date la plus r\u00e9cente des \u00e9pisodes stock\u00e9s, ou None si aucun \u00e9pisode n'est trouv\u00e9.\n    \"\"\"\n    most_recent_document = self.collection.find().sort({\"date\": -1}).limit(1)\n    most_recent_date = None\n    for doc in most_recent_document:\n        most_recent_date = doc[\"date\"].replace(tzinfo=pytz.timezone(\"Europe/Paris\"))\n    return most_recent_date\n</code></pre>"},{"location":"rss/#rss.Podcast.list_last_large_episodes","title":"<code>list_last_large_episodes(duree_mini_minutes=15)</code>","text":"<p>Liste les \u00e9pisodes RSS qui sont plus r\u00e9cents que le plus r\u00e9cent \u00e9pisode stock\u00e9 dans la base de donn\u00e9es et qui durent plus de <code>duree_mini_minutes</code> minutes.</p> <p>Parameters:</p> Name Type Description Default <code>duree_mini_minutes</code> <code>int</code> <p>La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 lister. Par d\u00e9faut \u00e0 15 minutes.</p> <code>15</code> <p>Returns:</p> Type Description <code>List[FeedParserDict]</code> <p>List[FeedParserDict]: Une liste d'entr\u00e9es RSS correspondant aux crit\u00e8res.</p> Source code in <code>nbs/rss.py</code> <pre><code>def list_last_large_episodes(\n    self, duree_mini_minutes: int = 15\n) -&gt; List[FeedParserDict]:\n    \"\"\"\n    Liste les \u00e9pisodes RSS qui sont plus r\u00e9cents que le plus r\u00e9cent \u00e9pisode stock\u00e9 dans la base de donn\u00e9es\n    et qui durent plus de `duree_mini_minutes` minutes.\n\n    Args:\n        duree_mini_minutes (int): La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 lister. Par d\u00e9faut \u00e0 15 minutes.\n\n    Returns:\n        List[FeedParserDict]: Une liste d'entr\u00e9es RSS correspondant aux crit\u00e8res.\n    \"\"\"\n    last_large_episodes = []\n    for entry in self.parsed_flow.entries:\n        date_rss = datetime.strptime(entry.published, RSS_DATE_FORMAT)\n        date_db = self.get_most_recent_episode_from_DB()\n        if date_db and date_rss &gt; date_db:\n            if (\n                RSS_episode.get_duree_in_seconds(entry.itunes_duration)\n                &gt; duree_mini_minutes * 60\n            ):\n                last_large_episodes.append(entry)\n    return last_large_episodes\n</code></pre>"},{"location":"rss/#rss.Podcast.store_last_large_episodes","title":"<code>store_last_large_episodes(duree_mini_minutes=15)</code>","text":"<p>Parcourt la liste des \u00e9pisodes longs r\u00e9cents, instancie RSS_episode et les conserve dans la base de donn\u00e9es. Affiche le nombre de mises \u00e0 jour r\u00e9ussies dans la base de donn\u00e9es.</p> <p>Parameters:</p> Name Type Description Default <code>duree_mini_minutes</code> <code>int</code> <p>La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 stocker. Par d\u00e9faut \u00e0 15 minutes.</p> <code>15</code> Source code in <code>nbs/rss.py</code> <pre><code>def store_last_large_episodes(self, duree_mini_minutes: int = 15) -&gt; None:\n    \"\"\"\n    Parcourt la liste des \u00e9pisodes longs r\u00e9cents, instancie RSS_episode et les conserve dans la base de donn\u00e9es.\n    Affiche le nombre de mises \u00e0 jour r\u00e9ussies dans la base de donn\u00e9es.\n\n    Args:\n        duree_mini_minutes (int): La dur\u00e9e minimale en minutes des \u00e9pisodes \u00e0 stocker. Par d\u00e9faut \u00e0 15 minutes.\n    \"\"\"\n    updates = 0\n    last_large_episodes = self.list_last_large_episodes(duree_mini_minutes)\n    for entry in last_large_episodes:\n        rss_entry = RSS_episode.from_feed_entry(entry)\n        updates += rss_entry.keep()\n    print(f\"Updated episodes: {updates}\")\n</code></pre>"},{"location":"rss/#rss.extraire_dureesummary","title":"<code>extraire_dureesummary(summary)</code>","text":"<p>Extrait la dur\u00e9e d'un \u00e9pisode du masque.</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>str</code> <p>Le r\u00e9sum\u00e9 de l'\u00e9pisode contenant la dur\u00e9e.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Le nombre de secondes correspondant \u00e0 la dur\u00e9e d'un \u00e9pisode.</p> <code>int</code> <p>Retourne -1 si la dur\u00e9e n'est pas trouv\u00e9e.</p> Source code in <code>nbs/rss.py</code> <pre><code>def extraire_dureesummary(summary: str) -&gt; int:\n    \"\"\"\n    Extrait la dur\u00e9e d'un \u00e9pisode du masque.\n\n    Args:\n        summary (str): Le r\u00e9sum\u00e9 de l'\u00e9pisode contenant la dur\u00e9e.\n\n    Returns:\n        int: Le nombre de secondes correspondant \u00e0 la dur\u00e9e d'un \u00e9pisode.\n        Retourne -1 si la dur\u00e9e n'est pas trouv\u00e9e.\n    \"\"\"\n    # Expression r\u00e9guli\u00e8re pour extraire la dur\u00e9e\n    pattern_duree = r\"dur\u00e9e\\s*:\\s*(\\d{2}:\\d{2}:\\d{2})\"\n\n    # Recherche de la dur\u00e9e dans le texte\n    match = re.search(pattern_duree, summary)\n\n    if match:\n        duree_str = match.group(1)\n        heures, minutes, secondes = map(int, duree_str.split(\":\"))\n        return heures * 3600 + minutes * 60 + secondes\n    else:\n        return -1\n</code></pre>"},{"location":"rss/#rss.extraire_urls_rss","title":"<code>extraire_urls_rss(duree_mini_minutes=15)</code>","text":"<p>Extrait les URLs des balises <code>enclosure</code> d'un flux RSS des \u00e9pisodes durant plus de <code>duree_mini_minutes</code> minutes.</p> <p>Parameters:</p> Name Type Description Default <code>duree_mini_minutes</code> <code>int</code> <p>La dur\u00e9e minimale en minutes des \u00e9pisodes du flux.</p> <code>15</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: Une liste d'URLs.</p> Source code in <code>nbs/rss.py</code> <pre><code>def extraire_urls_rss(duree_mini_minutes: int = 15) -&gt; List[str]:\n    \"\"\"\n    Extrait les URLs des balises `enclosure` d'un flux RSS des \u00e9pisodes durant plus de `duree_mini_minutes` minutes.\n\n    Args:\n        duree_mini_minutes (int): La dur\u00e9e minimale en minutes des \u00e9pisodes du flux.\n\n    Returns:\n        List[str]: Une liste d'URLs.\n    \"\"\"\n    url_flux = get_RSS_URL()\n\n    flux = feedparser.parse(url_flux)\n    urls = []\n    for entree in flux.entries:\n        for link in entree.links:\n            if link.type == \"audio/mpeg\":\n                if extraire_dureesummary(entree.summary) &gt; duree_mini_minutes * 60:\n                    urls.append(link.href)\n    return urls\n</code></pre>"},{"location":"web/","title":"Module web","text":""},{"location":"web/#web.WebPage","title":"<code>WebPage</code>","text":"Source code in <code>nbs/web.py</code> <pre><code>class WebPage:\n    def __init__(self):\n        \"\"\"\n        Initialize the WebPage object.\n\n        This method reads the HTML content from the file specified by the\n        `WEB_LMELP_FILENAME` environment variable, parses it using BeautifulSoup,\n        and extracts information about the episodes.\n        \"\"\"\n        file_path = get_WEB_filename()\n\n        # Lire le contenu du fichier HTML\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            html_content = file.read()\n\n        # Analyser le contenu HTML avec BeautifulSoup\n        soup = BeautifulSoup(html_content, \"html.parser\")\n\n        # Extraire les informations des \u00e9pisodes\n        self.episodes: List[Dict[str, Any]] = []\n\n        # Rechercher les \u00e9l\u00e9ments contenant les informations des \u00e9pisodes\n        for item in soup.find_all(\"li\", class_=\"Collection-section-items-item\"):\n            title_element = item.find(\"span\", class_=\"CardTitle\")\n            link_element = item.find(\"a\", class_=\"underline-hover\")\n            description_element = item.find(\"div\", class_=\"CardDescription\")\n            date_elements = item.find(\n                \"div\", class_=\"DefaultDetails-secondLine\"\n            ).find_all(\"p\")\n\n            if (\n                title_element\n                and link_element\n                and description_element\n                and len(date_elements) &gt;= 3\n            ):\n                title = title_element.get_text(strip=True)\n                url = link_element[\"href\"]\n                description = description_element.get_text(strip=True)\n                date = date_elements[0].get_text(strip=True)\n                duration = date_elements[2].get_text(strip=True)\n\n                self.episodes.append(\n                    {\n                        \"title\": title,\n                        \"url\": url,\n                        \"description\": description,\n                        \"date\": date,\n                        \"duration\": duration,\n                    }\n                )\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the WebPage object.\n\n        Returns:\n            str: A string containing the details of all episodes.\n        \"\"\"\n        output = \"\"\n        for episode in self.episodes:\n            output += f\"\"\"\nTitle: {episode['title']}\nURL: {episode['url']}\nDescription: {episode['description']}\nDate: {episode['date']}\nDuration: {episode['duration']}\n\n            \"\"\"\n        return output\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the WebPage object for debugging.\n\n        Returns:\n            str: A string containing the details of all episodes.\n        \"\"\"\n        return self.__str__()\n\n    def __getitem__(self, index: int) -&gt; Dict[str, Any]:\n        \"\"\"\n        Get an episode by its index.\n\n        Args:\n            index (int): The index of the episode to retrieve.\n\n        Returns:\n            dict: A dictionary containing the details of the episode.\n        \"\"\"\n        return self.episodes[index]\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Get the number of episodes.\n\n        Returns:\n            int: The number of episodes.\n        \"\"\"\n        return len(self.episodes)\n</code></pre>"},{"location":"web/#web.WebPage.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Get an episode by its index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The index of the episode to retrieve.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>A dictionary containing the details of the episode.</p> Source code in <code>nbs/web.py</code> <pre><code>def __getitem__(self, index: int) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get an episode by its index.\n\n    Args:\n        index (int): The index of the episode to retrieve.\n\n    Returns:\n        dict: A dictionary containing the details of the episode.\n    \"\"\"\n    return self.episodes[index]\n</code></pre>"},{"location":"web/#web.WebPage.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the WebPage object.</p> <p>This method reads the HTML content from the file specified by the <code>WEB_LMELP_FILENAME</code> environment variable, parses it using BeautifulSoup, and extracts information about the episodes.</p> Source code in <code>nbs/web.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the WebPage object.\n\n    This method reads the HTML content from the file specified by the\n    `WEB_LMELP_FILENAME` environment variable, parses it using BeautifulSoup,\n    and extracts information about the episodes.\n    \"\"\"\n    file_path = get_WEB_filename()\n\n    # Lire le contenu du fichier HTML\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        html_content = file.read()\n\n    # Analyser le contenu HTML avec BeautifulSoup\n    soup = BeautifulSoup(html_content, \"html.parser\")\n\n    # Extraire les informations des \u00e9pisodes\n    self.episodes: List[Dict[str, Any]] = []\n\n    # Rechercher les \u00e9l\u00e9ments contenant les informations des \u00e9pisodes\n    for item in soup.find_all(\"li\", class_=\"Collection-section-items-item\"):\n        title_element = item.find(\"span\", class_=\"CardTitle\")\n        link_element = item.find(\"a\", class_=\"underline-hover\")\n        description_element = item.find(\"div\", class_=\"CardDescription\")\n        date_elements = item.find(\n            \"div\", class_=\"DefaultDetails-secondLine\"\n        ).find_all(\"p\")\n\n        if (\n            title_element\n            and link_element\n            and description_element\n            and len(date_elements) &gt;= 3\n        ):\n            title = title_element.get_text(strip=True)\n            url = link_element[\"href\"]\n            description = description_element.get_text(strip=True)\n            date = date_elements[0].get_text(strip=True)\n            duration = date_elements[2].get_text(strip=True)\n\n            self.episodes.append(\n                {\n                    \"title\": title,\n                    \"url\": url,\n                    \"description\": description,\n                    \"date\": date,\n                    \"duration\": duration,\n                }\n            )\n</code></pre>"},{"location":"web/#web.WebPage.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of episodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of episodes.</p> Source code in <code>nbs/web.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Get the number of episodes.\n\n    Returns:\n        int: The number of episodes.\n    \"\"\"\n    return len(self.episodes)\n</code></pre>"},{"location":"web/#web.WebPage.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the WebPage object for debugging.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string containing the details of all episodes.</p> Source code in <code>nbs/web.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the WebPage object for debugging.\n\n    Returns:\n        str: A string containing the details of all episodes.\n    \"\"\"\n    return self.__str__()\n</code></pre>"},{"location":"web/#web.WebPage.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of the WebPage object.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string containing the details of all episodes.</p> Source code in <code>nbs/web.py</code> <pre><code>    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the WebPage object.\n\n        Returns:\n            str: A string containing the details of all episodes.\n        \"\"\"\n        output = \"\"\n        for episode in self.episodes:\n            output += f\"\"\"\nTitle: {episode['title']}\nURL: {episode['url']}\nDescription: {episode['description']}\nDate: {episode['date']}\nDuration: {episode['duration']}\n\n            \"\"\"\n        return output\n</code></pre>"},{"location":"whisper/","title":"Module whisper","text":""},{"location":"whisper/#whisper.extract_whisper","title":"<code>extract_whisper(audio_filename)</code>","text":"<p>Extrait la transcription d'un fichier audio en utilisant le mod\u00e8le Whisper.</p> <p>Parameters:</p> Name Type Description Default <code>audio_filename</code> <code>str</code> <p>Le chemin du fichier audio \u00e0 transcrire.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>La transcription du fichier audio.</p> Source code in <code>nbs/whisper.py</code> <pre><code>def extract_whisper(audio_filename: str) -&gt; str:\n    \"\"\"\n    Extrait la transcription d'un fichier audio en utilisant le mod\u00e8le Whisper.\n\n    Args:\n        audio_filename (str): Le chemin du fichier audio \u00e0 transcrire.\n\n    Returns:\n        str: La transcription du fichier audio.\n    \"\"\"\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n\n    model_id = \"openai/whisper-large-v3-turbo\"\n\n    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n    )\n    model.to(device)\n\n    processor = AutoProcessor.from_pretrained(model_id)\n\n    generate_kwargs = {\n        \"language\": \"french\",\n    }\n\n    pipe = pipeline(\n        \"automatic-speech-recognition\",\n        model=model,\n        tokenizer=processor.tokenizer,\n        feature_extractor=processor.feature_extractor,\n        torch_dtype=torch_dtype,\n        device=device,\n        chunk_length_s=30,\n        batch_size=16,  # batch size for inference - set based on your device\n        generate_kwargs=generate_kwargs,\n    )\n\n    dataset = load_dataset(\n        \"distil-whisper/librispeech_long\", \"clean\", split=\"validation\"\n    )\n    sample = dataset[0][\"audio\"]\n\n    result = pipe(\n        audio_filename,\n        return_timestamps=True,\n    )\n\n    return result[\"text\"]\n</code></pre>"},{"location":"whisper/#whisper.list_audio_files","title":"<code>list_audio_files(audio_path=AUDIO_PATH)</code>","text":"<p>Liste tous les fichiers audio (MP3 et M4A) dans le r\u00e9pertoire sp\u00e9cifi\u00e9.</p> <p>Parameters:</p> Name Type Description Default <code>audio_path</code> <code>str</code> <p>Le chemin du r\u00e9pertoire contenant les fichiers audio. Par d\u00e9faut, utilise la constante AUDIO_PATH.</p> <code>AUDIO_PATH</code> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>Une liste des chemins de fichiers audio (MP3 et M4A) trouv\u00e9s.</p> Source code in <code>nbs/whisper.py</code> <pre><code>def list_audio_files(audio_path=AUDIO_PATH) -&gt; List[str]:\n    \"\"\"\n    Liste tous les fichiers audio (MP3 et M4A) dans le r\u00e9pertoire sp\u00e9cifi\u00e9.\n\n    Args:\n        audio_path (str): Le chemin du r\u00e9pertoire contenant les fichiers audio. Par d\u00e9faut, utilise la constante AUDIO_PATH.\n\n    Returns:\n        list: Une liste des chemins de fichiers audio (MP3 et M4A) trouv\u00e9s.\n    \"\"\"\n    fullpath = get_audio_path(audio_path, year=\"\")\n\n    mp3_files = glob.glob(os.path.join(fullpath, \"**/*.mp3\"), recursive=True)\n    m4a_files = glob.glob(os.path.join(fullpath, \"**/*.m4a\"), recursive=True)\n\n    return mp3_files + m4a_files\n</code></pre>"},{"location":"whisper/#whisper.list_mp3_files","title":"<code>list_mp3_files(audio_path=AUDIO_PATH)</code>","text":"<p>Liste tous les fichiers MP3 dans le r\u00e9pertoire sp\u00e9cifi\u00e9.</p> <p>Parameters:</p> Name Type Description Default <code>audio_path</code> <code>str</code> <p>Le chemin du r\u00e9pertoire contenant les fichiers audio. Par d\u00e9faut, utilise la constante AUDIO_PATH.</p> <code>AUDIO_PATH</code> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>Une liste des chemins de fichiers MP3 trouv\u00e9s.</p> Source code in <code>nbs/whisper.py</code> <pre><code>def list_mp3_files(audio_path=AUDIO_PATH) -&gt; List[str]:\n    \"\"\"\n    Liste tous les fichiers MP3 dans le r\u00e9pertoire sp\u00e9cifi\u00e9.\n\n    Args:\n        audio_path (str): Le chemin du r\u00e9pertoire contenant les fichiers audio. Par d\u00e9faut, utilise la constante AUDIO_PATH.\n\n    Returns:\n        list: Une liste des chemins de fichiers MP3 trouv\u00e9s.\n    \"\"\"\n    fullpath = get_audio_path(audio_path, year=\"\")\n    return glob.glob(os.path.join(fullpath, \"**/*.mp3\"), recursive=True)\n</code></pre>"},{"location":"whisper/#whisper.store_whisper_in_db","title":"<code>store_whisper_in_db(whisper, collection, oid, force=False, verbose=False)</code>","text":"<p>Stocke la transcription Whisper dans la base de donn\u00e9es.</p> <p>Parameters:</p> Name Type Description Default <code>whisper</code> <code>str</code> <p>La transcription du fichier audio.</p> required <code>collection</code> <code>Collection</code> <p>La collection pymongo.</p> required <code>oid</code> <code>str</code> <p>L'identifiant de l'\u00e9pisode.</p> required <code>force</code> <code>bool</code> <p>Si True, \u00e9crase le Whisper existant. Par d\u00e9faut, False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Si True, affiche des messages d\u00e9taill\u00e9s. Par d\u00e9faut, False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True si le Whisper a \u00e9t\u00e9 stock\u00e9, False sinon.</p> Source code in <code>nbs/whisper.py</code> <pre><code>def store_whisper_in_db(\n    whisper: str,\n    collection: pymongo.collection.Collection,\n    oid: str,\n    force: bool = False,\n    verbose: bool = False,\n) -&gt; bool:\n    \"\"\"\n    Stocke la transcription Whisper dans la base de donn\u00e9es.\n\n    Args:\n        whisper (str): La transcription du fichier audio.\n        collection: La collection pymongo.\n        oid (str): L'identifiant de l'\u00e9pisode.\n        force (bool, optional): Si True, \u00e9crase le Whisper existant. Par d\u00e9faut, False.\n        verbose (bool, optional): Si True, affiche des messages d\u00e9taill\u00e9s. Par d\u00e9faut, False.\n\n    Returns:\n        bool: True si le Whisper a \u00e9t\u00e9 stock\u00e9, False sinon.\n    \"\"\"\n    # R\u00e9cup\u00e9ration du document\n    document_entry = collection.find_one({\"_id\": ObjectId(oid)})\n\n    if document_entry is None:\n        if verbose:\n            print(f\"Document avec l'oid {oid} non trouv\u00e9\")\n        return False\n\n    if \"whisper\" in document_entry and not force:\n        if verbose:\n            print(\n                f\"Whisper d\u00e9j\u00e0 stock\u00e9 pour l'oid {oid}, et on ne force pas le stockage\"\n            )\n        return False\n    else:\n        document_entry[\"whisper\"] = whisper\n        collection.update_one({\"_id\": ObjectId(oid)}, {\"$set\": document_entry})\n        if verbose:\n            print(f\"Whisper stock\u00e9 pour l'oid {oid}\")\n        return True\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/","title":"Fix Streamlit int64 Type Error - Issue #69","text":"<p>Date: 2025-11-16 23:19 Issue: #69 Branch: <code>69-bug-impossible-de-generer-la-transcription-dun-nouvel-episode</code></p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#probleme-rencontre","title":"Probl\u00e8me Rencontr\u00e9","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#symptome","title":"Sympt\u00f4me","text":"<p>Erreur <code>Selectbox Value has invalid type: int64</code> lors du clic sur \"G\u00e9n\u00e9rer le r\u00e9sum\u00e9 des avis critiques\" dans l'interface Streamlit.</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#cause-racine","title":"Cause Racine","text":"<p>Dans ui/pages/4_avis_critiques.py, le param\u00e8tre <code>index</code> de <code>st.selectbox()</code> recevait des valeurs de type <code>numpy.int64</code> ou <code>pandas.Int64</code> au lieu de <code>int</code> natif Python. Streamlit n'accepte pas ces types numpy/pandas pour ses param\u00e8tres.</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#contexte","title":"Contexte","text":"<ul> <li>L'utilisateur mentionnait avoir d\u00e9j\u00e0 eu ce probl\u00e8me et pensait que la correction \u00e9tait partielle</li> <li>Le probl\u00e8me se produisait sp\u00e9cifiquement sur la page des avis critiques (page 4)</li> <li>Les DataFrames pandas retournent naturellement des <code>int64</code> lors d'op\u00e9rations comme <code>reset_index()</code> ou <code>.index[0]</code></li> </ul>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#solution-implementee","title":"Solution Impl\u00e9ment\u00e9e","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#approche-tdd","title":"Approche TDD","text":"<ol> <li>Tests RED: Cr\u00e9ation de tests de compatibilit\u00e9 des types dans tests/ui/test_streamlit.py</li> <li>Impl\u00e9mentation: Ajout de conversions <code>int()</code> syst\u00e9matiques</li> <li>Tests GREEN: Validation avec 268 tests passants</li> </ol>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#modifications-de-code","title":"Modifications de Code","text":"<p>Fichier: ui/pages/4_avis_critiques.py</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#1-ligne-338-parametre-index-de-stselectbox","title":"1. Ligne 338 - Param\u00e8tre index de st.selectbox()","text":"<pre><code># AVANT (implicite, causait l'erreur)\nselected_value = st.selectbox(\n    \"S\u00e9lectionnez un \u00e9pisode\",\n    episodes_df[\"selecteur\"],\n    index=st.session_state.selected_episode_index,  # \u274c Pouvait \u00eatre int64\n)\n\n# APR\u00c8S (correction)\nselected_value = st.selectbox(\n    \"S\u00e9lectionnez un \u00e9pisode\",\n    episodes_df[\"selecteur\"],\n    index=int(st.session_state.selected_episode_index),  # \u2705 Toujours int natif\n)\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#2-ligne-348-stockage-du-nouvel-index","title":"2. Ligne 348 - Stockage du nouvel index","text":"<pre><code># AVANT\nnew_index = episodes_df[episodes_df[\"selecteur\"] == selected_value].index[0]\nst.session_state.selected_episode_index = new_index  # \u274c int64\n\n# APR\u00c8S\nnew_index = episodes_df[episodes_df[\"selecteur\"] == selected_value].index[0]\nst.session_state.selected_episode_index = int(new_index)  # \u2705 int natif\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#3-lignes-361-363-bouton-precedent","title":"3. Lignes 361-363 - Bouton \"Pr\u00e9c\u00e9dent\"","text":"<pre><code># AVANT\nst.session_state.selected_episode_index = int(min(\n    len(episodes_df) - 1, st.session_state.selected_episode_index + 1\n))\n\n# APR\u00c8S\nst.session_state.selected_episode_index = int(min(\n    len(episodes_df) - 1, int(st.session_state.selected_episode_index) + 1\n))  # \u2705 Double conversion pour s\u00e9curit\u00e9\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#4-lignes-376-378-bouton-suivant","title":"4. Lignes 376-378 - Bouton \"Suivant\"","text":"<pre><code># AVANT\nst.session_state.selected_episode_index = int(max(\n    0, st.session_state.selected_episode_index - 1\n))\n\n# APR\u00c8S\nst.session_state.selected_episode_index = int(max(\n    0, int(st.session_state.selected_episode_index) - 1\n))  # \u2705 Double conversion pour s\u00e9curit\u00e9\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#5-ligne-484-acces-avec-iloc","title":"5. Ligne 484 - Acc\u00e8s avec iloc","text":"<pre><code># AVANT\nepisode = episodes_df.iloc[[st.session_state.selected_episode_index]]\n\n# APR\u00c8S\nepisode = episodes_df.iloc[[int(st.session_state.selected_episode_index)]]  # \u2705 int natif\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#tests-ajoutes","title":"Tests Ajout\u00e9s","text":"<p>Fichier: tests/ui/test_streamlit.py</p> <p>Nouvelle classe de tests <code>TestStreamlitTypeCompatibility</code> avec 3 tests:</p> <ol> <li>test_index_types_are_native_python_int: V\u00e9rifie la conversion numpy.int64 \u2192 int natif</li> <li>test_min_max_operations_return_native_int: Valide que min()/max() retournent des int natifs</li> <li>test_dataframe_index_access_type: Teste l'acc\u00e8s aux index de DataFrame et leur conversion</li> </ol> <pre><code>def test_index_types_are_native_python_int(self):\n    \"\"\"Test que les index utilis\u00e9s dans st.selectbox sont des int natifs Python\"\"\"\n    import numpy as np\n\n    numpy_int64 = np.int64(5)\n    native_int = 5\n\n    # V\u00e9rifier la diff\u00e9rence de types\n    assert type(numpy_int64).__name__ in ['int64', 'int_']\n    assert type(native_int) == int\n\n    # Test de conversion\n    converted_numpy = int(numpy_int64)\n    assert type(converted_numpy) == int\n    assert converted_numpy == 5\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#apprentissages-cles","title":"Apprentissages Cl\u00e9s","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#1-compatibilite-des-types-streamlit","title":"1. Compatibilit\u00e9 des Types Streamlit","text":"<ul> <li>Streamlit est strict sur les types: N'accepte que des <code>int</code> natifs Python, pas <code>numpy.int64</code> ou <code>pandas.Int64</code></li> <li>Les DataFrames pandas retournent des int64: Op\u00e9rations comme <code>.index[0]</code>, <code>reset_index()</code> produisent naturellement des int64</li> <li>Solution: Conversion syst\u00e9matique avec <code>int()</code> avant passage \u00e0 Streamlit</li> </ul>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#2-pattern-de-correction","title":"2. Pattern de Correction","text":"<p>Toujours appliquer cette conversion lors de: - Utilisation d'index dans <code>st.selectbox(index=...)</code> - Stockage dans <code>st.session_state</code> - Op\u00e9rations arithm\u00e9tiques avec des index pandas</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#3-tests-de-compatibilite","title":"3. Tests de Compatibilit\u00e9","text":"<p>Les tests de type sont essentiels pour d\u00e9tecter ces probl\u00e8mes:</p> <pre><code>assert type(value) == int  # V\u00e9rification stricte du type natif\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#4-cas-similaires-a-surveiller","title":"4. Cas Similaires \u00e0 Surveiller","text":"<p>D'autres widgets Streamlit peuvent avoir des probl\u00e8mes similaires: - <code>st.slider(value=...)</code> - <code>st.number_input(value=...)</code> - <code>st.radio(index=...)</code></p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#resultats","title":"R\u00e9sultats","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#tests","title":"Tests","text":"<ul> <li>\u2705 268 tests passants (100% de succ\u00e8s)</li> <li>\u2705 3 nouveaux tests de compatibilit\u00e9 des types</li> <li>\u2705 Pas de r\u00e9gression sur les tests existants</li> </ul>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#validation-utilisateur","title":"Validation Utilisateur","text":"<ul> <li>\u2705 Bug confirm\u00e9 r\u00e9solu par l'utilisateur</li> <li>\u2705 Interface fonctionnelle sans erreur</li> <li>\u2705 G\u00e9n\u00e9ration de r\u00e9sum\u00e9s d'avis critiques op\u00e9rationnelle</li> </ul>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#documentation","title":"Documentation","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#commentaires-ajoutes-au-code","title":"Commentaires Ajout\u00e9s au Code","text":"<p>Tous les points de conversion incluent maintenant un commentaire explicatif:</p> <pre><code># IMPORTANT: Convertir l'index en int natif Python pour \u00e9viter les erreurs de type avec Streamlit\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#issue-github","title":"Issue GitHub","text":"<p>Commentaire d\u00e9taill\u00e9 ajout\u00e9 \u00e0 l'issue #69 documentant: - Cause racine - Fichiers concern\u00e9s - Solution propos\u00e9e - Approche TDD - Notes sur les corrections pr\u00e9c\u00e9dentes</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#recommandations-futures","title":"Recommandations Futures","text":""},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#1-lintertype-checker-custom","title":"1. Linter/Type Checker Custom","text":"<p>Cr\u00e9er une r\u00e8gle de linting pour d\u00e9tecter automatiquement: - Acc\u00e8s \u00e0 <code>.index[0]</code> sans conversion <code>int()</code> - Param\u00e8tres Streamlit recevant potentiellement des int64</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#2-helper-function","title":"2. Helper Function","text":"<p>Envisager une fonction utilitaire:</p> <pre><code>def safe_int_for_streamlit(value):\n    \"\"\"Convertit toute valeur en int natif Python pour Streamlit\"\"\"\n    return int(value) if value is not None else 0\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#3-documentation-projet","title":"3. Documentation Projet","text":"<p>Ajouter une section dans CLAUDE.md sur les bonnes pratiques Streamlit: - Toujours convertir les index pandas en int natif - Liste des widgets sensibles aux types - Exemples de conversions</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#4-review-systematique","title":"4. Review Syst\u00e9matique","text":"<p>Lors de code review, v\u00e9rifier syst\u00e9matiquement: - Tous les <code>st.selectbox()</code> avec param\u00e8tre <code>index</code> - Tous les <code>st.session_state</code> stockant des index - Toute op\u00e9ration arithm\u00e9tique sur des index pandas</p>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#commandes-utilisees","title":"Commandes Utilis\u00e9es","text":"<pre><code># Cr\u00e9ation de la branche\ngh issue develop 69 --checkout\n\n# Ex\u00e9cution des tests\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/ -v\n\n# Tests sp\u00e9cifiques de compatibilit\u00e9\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/ui/test_streamlit.py::TestStreamlitTypeCompatibility -v\n\n# Commentaire sur l'issue\ngh issue comment 69 --body \"...\"\n</code></pre>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#liens-et-references","title":"Liens et R\u00e9f\u00e9rences","text":"<ul> <li>Issue GitHub: #69</li> <li>Branch: <code>69-bug-impossible-de-generer-la-transcription-dun-nouvel-episode</code></li> <li>Fichiers modifi\u00e9s:</li> <li>ui/pages/4_avis_critiques.py (5 emplacements)</li> <li>tests/ui/test_streamlit.py (nouvelle classe de tests)</li> <li>Documentation Streamlit: Les widgets Streamlit n\u00e9cessitent des types Python natifs</li> <li>Pandas Index Documentation: Les index pandas peuvent \u00eatre de type int64</li> </ul>"},{"location":"claude/memory/251116-2319-fix-streamlit-int64-type-error/#conclusion","title":"Conclusion","text":"<p>Cette correction r\u00e9sout d\u00e9finitivement le probl\u00e8me de compatibilit\u00e9 des types entre pandas/numpy et Streamlit. L'approche syst\u00e9matique avec conversions <code>int()</code> garantit qu'aucun type int64 ne sera pass\u00e9 aux widgets Streamlit, \u00e9liminant cette classe d'erreurs.</p> <p>Le pattern \u00e9tabli peut \u00eatre r\u00e9utilis\u00e9 pour d'autres pages Streamlit du projet et sert de r\u00e9f\u00e9rence pour les bonnes pratiques de d\u00e9veloppement avec Streamlit et pandas.</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/","title":"Impl\u00e9mentation du Favicon Streamlit - Issue #74","text":"<p>Date: 2025-11-20 07:33 Issue: #74 - Changer le favicon du site Branche: <code>74-changer-le-favicon-du-site</code></p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#contexte","title":"Contexte","text":"<p>Remplacement du favicon par d\u00e9faut de l'interface Streamlit par un favicon personnalis\u00e9 provenant du projet back-office-lmelp.</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#apprentissages-cles","title":"Apprentissages Cl\u00e9s","text":""},{"location":"claude/memory/251120-0733-favicon-implementation/#1-configuration-streamlit-multi-pages","title":"1. Configuration Streamlit Multi-Pages","text":"<p>D\u00e9couverte importante : Dans une application Streamlit multi-pages, le <code>st.set_page_config()</code> de la page principale s'applique automatiquement \u00e0 toutes les sous-pages.</p> <p>Architecture finale : - \u2705 Page principale (<code>ui/lmelp.py</code>) : Configure le favicon une seule fois - \u2705 Sous-pages (<code>ui/pages/*.py</code>) : H\u00e9ritent automatiquement, pas de duplication - \u274c Anti-pattern : R\u00e9p\u00e9ter <code>st.set_page_config()</code> dans chaque sous-page</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#2-chargement-du-favicon-avec-pil","title":"2. Chargement du Favicon avec PIL","text":"<p>Probl\u00e8me initial : Les chemins relatifs string ne fonctionnent pas toujours avec Streamlit.</p> <p>Solution : Utiliser PIL.Image pour charger le favicon :</p> <pre><code>from pathlib import Path\nfrom PIL import Image\n\n# Load favicon\nfavicon_path = Path(__file__).parent / \"assets\" / \"favicons\" / \"favicon-32x32.png\"\nfavicon = Image.open(favicon_path)\n\nst.set_page_config(\n    page_title=\"le masque et la plume\",\n    page_icon=favicon,  # Objet PIL.Image, pas un string\n    layout=\"wide\",\n    initial_sidebar_state=\"auto\",\n)\n</code></pre> <p>Pourquoi PIL ? - \u2705 Chemins absolus r\u00e9solus correctement - \u2705 Objet Image accept\u00e9 nativement par Streamlit - \u2705 Pas de probl\u00e8mes de cache navigateur - \u274c Les chemins string relatifs peuvent \u00e9chouer silencieusement</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#3-generation-multi-format-des-favicons","title":"3. G\u00e9n\u00e9ration Multi-Format des Favicons","text":"<p>Script : <code>ui/assets/favicons/scripts/generate_favicons.py</code></p> <p>Formats g\u00e9n\u00e9r\u00e9s (7 fichiers) : - <code>favicon.ico</code> - Multi-taille (16, 32, 48) - <code>favicon-16x16.png</code>, <code>favicon-32x32.png</code>, <code>favicon-48x48.png</code> - Formats standard - <code>apple-touch-icon.png</code> (180x180) - iOS - <code>android-chrome-192x192.png</code>, <code>android-chrome-512x512.png</code> - Android/PWA</p> <p>Technique : Redimensionnement avec <code>Image.Resampling.LANCZOS</code> pour qualit\u00e9 optimale</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#4-structure-de-fichiers","title":"4. Structure de Fichiers","text":"<pre><code>ui/\n\u251c\u2500\u2500 lmelp.py                           # Configure favicon (PIL)\n\u251c\u2500\u2500 assets/\n\u2502   \u2514\u2500\u2500 favicons/\n\u2502       \u251c\u2500\u2500 favicon.png                # Source (1327x1328)\n\u2502       \u251c\u2500\u2500 favicon-32x32.png          # Utilis\u00e9 par Streamlit\n\u2502       \u251c\u2500\u2500 [6 autres formats]\n\u2502       \u251c\u2500\u2500 scripts/\n\u2502       \u2502   \u2514\u2500\u2500 generate_favicons.py   # Script de g\u00e9n\u00e9ration\n\u2502       \u2514\u2500\u2500 README.md                  # Documentation\n\u2514\u2500\u2500 pages/\n    \u251c\u2500\u2500 1_episodes.py                  # Pas de page_icon\n    \u251c\u2500\u2500 2_auteurs.py                   # H\u00e9rite du favicon\n    \u251c\u2500\u2500 3_livres.py                    # H\u00e9rite du favicon\n    \u2514\u2500\u2500 4_avis_critiques.py            # H\u00e9rite du favicon\n</code></pre> <p>Rationale : Script dans <code>ui/assets/favicons/scripts/</code> car utilis\u00e9 rarement (pas dans <code>scripts/</code> principal)</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#5-tests-tdd","title":"5. Tests TDD","text":"<p>Approche : RED \u2192 GREEN \u2192 REFACTOR</p> <p>Tests cr\u00e9\u00e9s : 1. <code>tests/integration/test_favicons.py</code> - Existence et validit\u00e9 des fichiers 2. <code>tests/integration/test_favicon_usage.py</code> - Architecture et coh\u00e9rence</p> <p>Tests cl\u00e9s :</p> <pre><code># V\u00e9rifie que seule la page principale configure le favicon\ndef test_main_page_uses_favicon_with_pil(ui_files)\n\n# V\u00e9rifie que les sous-pages n'ont PAS de configuration\ndef test_subpages_dont_configure_favicon(ui_files)\n\n# V\u00e9rifie l'utilisation de PIL.Image\ndef test_favicon_path_uses_pil_image(ui_files)\n</code></pre> <p>Valeur : Les tests guident le refactoring et d\u00e9tectent les duplications</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#decisions-techniques","title":"D\u00e9cisions Techniques","text":""},{"location":"claude/memory/251120-0733-favicon-implementation/#pourquoi-favicon-32x32png-et-pas-faviconico","title":"Pourquoi favicon-32x32.png et pas favicon.ico ?","text":"<ul> <li>Streamlit g\u00e8re mieux les PNG que les ICO</li> <li>Format standard pour navigateurs modernes</li> <li>Meilleure compatibilit\u00e9 cross-platform</li> </ul>"},{"location":"claude/memory/251120-0733-favicon-implementation/#pourquoi-un-seul-point-de-configuration","title":"Pourquoi un seul point de configuration ?","text":"<ul> <li>DRY : Don't Repeat Yourself</li> <li>Maintenabilit\u00e9 : Un seul endroit \u00e0 modifier</li> <li>Coh\u00e9rence : Impossible d'avoir des favicons diff\u00e9rents par page</li> <li>Performance : Moins de code \u00e0 charger</li> </ul>"},{"location":"claude/memory/251120-0733-favicon-implementation/#organisation-des-fichiers","title":"Organisation des fichiers","text":"<p>D\u00e9cision : Script dans <code>ui/assets/favicons/scripts/</code> plut\u00f4t que <code>scripts/</code></p> <p>Raison : - Utilis\u00e9 uniquement lors de changements d'image (rare) - Proximit\u00e9 avec les ressources qu'il manipule - Ne pollue pas le r\u00e9pertoire <code>scripts/</code> principal</p>"},{"location":"claude/memory/251120-0733-favicon-implementation/#pieges-evites","title":"Pi\u00e8ges \u00c9vit\u00e9s","text":""},{"location":"claude/memory/251120-0733-favicon-implementation/#piege-1-chemins-relatifs-string","title":"\u274c Pi\u00e8ge 1 : Chemins relatifs string","text":"<pre><code># NE FONCTIONNE PAS TOUJOURS\npage_icon=\"assets/favicons/favicon.ico\"\n</code></pre>"},{"location":"claude/memory/251120-0733-favicon-implementation/#piege-2-duplication-dans-chaque-page","title":"\u274c Pi\u00e8ge 2 : Duplication dans chaque page","text":"<pre><code># ANTI-PATTERN\n# Dans chaque fichier ui/pages/*.py\nst.set_page_config(page_icon=\"...\")  # Inutile !\n</code></pre>"},{"location":"claude/memory/251120-0733-favicon-implementation/#piege-3-format-ico-au-lieu-de-png","title":"\u274c Pi\u00e8ge 3 : Format ICO au lieu de PNG","text":"<pre><code># MOINS COMPATIBLE\npage_icon=favicon_ico  # Pr\u00e9f\u00e9rer PNG 32x32\n</code></pre>"},{"location":"claude/memory/251120-0733-favicon-implementation/#commandes-utiles","title":"Commandes Utiles","text":"<pre><code># R\u00e9g\u00e9n\u00e9rer les favicons\npython ui/assets/favicons/scripts/generate_favicons.py\n\n# Tester l'impl\u00e9mentation\npytest tests/integration/test_favicons.py -v\npytest tests/integration/test_favicon_usage.py -v\n\n# Lancer l'UI\n./ui/lmelp_ui.sh\n</code></pre>"},{"location":"claude/memory/251120-0733-favicon-implementation/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Source originale : https://github.com/castorfou/back-office-lmelp/blob/main/frontend/public/gimp_favicon/favicon.png</li> <li>Documentation Streamlit : <code>st.set_page_config()</code> page_icon parameter</li> <li>Pillow docs : Image.Resampling.LANCZOS</li> </ul>"},{"location":"claude/memory/251120-0733-favicon-implementation/#impact","title":"Impact","text":"<ul> <li>\u2705 Favicon personnalis\u00e9 visible sur toutes les pages</li> <li>\u2705 Code maintenable et testable</li> <li>\u2705 Architecture propre (config centralis\u00e9e)</li> <li>\u2705 Documentation compl\u00e8te</li> <li>\u2705 9 tests passants (4 favicons + 5 usage)</li> </ul>"},{"location":"claude/memory/251120-0733-favicon-implementation/#a-retenir-pour-le-futur","title":"\u00c0 Retenir pour le Futur","text":"<ol> <li>Streamlit multi-pages : Configuration globale dans la page principale</li> <li>Favicons : Toujours utiliser PIL.Image pour le chargement</li> <li>TDD : Les tests guident vers une architecture propre</li> <li>Simplicit\u00e9 : Ne pas dupliquer ce qui peut \u00eatre h\u00e9rit\u00e9</li> </ol>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/","title":"Fix du Flash du Favicon Streamlit - Issue #76","text":"<p>Date: 2025-11-20 23:42 Issue: #76 - Bug favicon (flash de la couronne blanche) Branche: <code>76-bug-favicon</code> Commit: <code>6530621</code></p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#probleme","title":"Probl\u00e8me","text":"<p>Apr\u00e8s l'impl\u00e9mentation du favicon personnalis\u00e9 (issue #74), un bug persistait : - Le favicon par d\u00e9faut de Streamlit (couronne blanche/fond noir) s'affiche bri\u00e8vement avant le favicon personnalis\u00e9 (masque de th\u00e9\u00e2tre/fond vert) - Les bookmarks capturent l'ancien favicon au lieu du nouveau - L'exp\u00e9rience utilisateur est d\u00e9grad\u00e9e par ce \"flash\"</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#cause-racine","title":"Cause Racine","text":"<p>Limitation connue de Streamlit (GitHub issue #9058) : - Le favicon par d\u00e9faut est hardcod\u00e9 dans <code>streamlit/static/favicon.png</code> - Il est charg\u00e9 dans le HTML initial avant que JavaScript n'ex\u00e9cute <code>st.set_page_config()</code> - Aucune option de configuration officielle (<code>server.favIconPath</code> n'existe pas dans Streamlit 1.51.0)</p> <p>Consensus communautaire : La seule solution fiable est de patcher directement l'installation Streamlit.</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#solution-implementee","title":"Solution Impl\u00e9ment\u00e9e","text":""},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#script-de-patch-automatise","title":"Script de Patch Automatis\u00e9","text":"<p>Fichier : <code>ui/assets/favicons/scripts/patch_streamlit_favicon.py</code> (144 lignes)</p> <p>Fonctionnement : 1. D\u00e9tecte automatiquement le chemin d'installation de Streamlit 2. Sauvegarde l'original (<code>favicon.png.original</code>) 3. Remplace par notre favicon personnalis\u00e9 (<code>favicon-32x32.png</code>) 4. Support multi-environnement (dev + Docker)</p> <pre><code># Appliquer le patch\npython ui/assets/favicons/scripts/patch_streamlit_favicon.py\n\n# Restaurer l'original\npython ui/assets/favicons/scripts/patch_streamlit_favicon.py --restore\n</code></pre>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#automatisation-deux-contextes","title":"Automatisation : Deux Contextes","text":""},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#1-devcontainer-devcontainerpostcreatecommandsh","title":"1. Devcontainer (<code>.devcontainer/postCreateCommand.sh</code>)","text":"<p>Ajout d'une fonction <code>patch_streamlit_favicon()</code> ex\u00e9cut\u00e9e apr\u00e8s l'installation des d\u00e9pendances :</p> <pre><code>patch_streamlit_favicon() {\n    if [ -f \".venv/bin/activate\" ]; then\n        source .venv/bin/activate\n        python ui/assets/favicons/scripts/patch_streamlit_favicon.py\n    fi\n}\n</code></pre> <p>Trigger : \u00c0 chaque reconstruction du devcontainer</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#2-docker-dockerbuilddockerfile","title":"2. Docker (<code>docker/build/Dockerfile</code>)","text":"<p>Int\u00e9gration dans le stage <code>builder</code> apr\u00e8s l'installation de Streamlit :</p> <pre><code># Patch Streamlit favicon to prevent default crown icon flash\nCOPY ui/assets/favicons/favicon-32x32.png /tmp/custom-favicon.png\nCOPY ui/assets/favicons/scripts/patch_streamlit_favicon.py /tmp/patch_streamlit_favicon.py\nRUN python /tmp/patch_streamlit_favicon.py &amp;&amp; \\\n    rm /tmp/custom-favicon.png /tmp/patch_streamlit_favicon.py\n</code></pre> <p>Avantage : Le favicon patch\u00e9 est copi\u00e9 dans l'image runtime avec <code>/usr/local</code></p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#tests-tdd","title":"Tests (TDD)","text":"<p>Fichier : <code>tests/integration/test_streamlit_patch.py</code> (98 lignes, 5 tests)</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#strategie-de-test","title":"Strat\u00e9gie de Test","text":"<p>Utilisation de hash MD5 pour comparer les fichiers binaires (images PNG) :</p> <pre><code>1. test_streamlit_favicon_exists\n   \u2192 V\u00e9rifie existence du favicon Streamlit\n\n2. test_custom_favicon_exists\n   \u2192 V\u00e9rifie existence de notre favicon\n\n3. test_backup_exists_after_patch\n   \u2192 V\u00e9rifie que le backup a \u00e9t\u00e9 cr\u00e9\u00e9\n\n4. test_streamlit_favicon_matches_custom\n   \u2192 Compare MD5 : Streamlit = notre favicon\n\n5. test_backup_different_from_custom\n   \u2192 Compare MD5 : backup \u2260 notre favicon (preuve du patch)\n</code></pre> <p>R\u00e9sultat : \u2705 5/5 tests passent</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#documentation","title":"Documentation","text":""},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#fichiers-crees","title":"Fichiers Cr\u00e9\u00e9s","text":"<ol> <li><code>ui/assets/favicons/scripts/patch_streamlit_favicon.py</code> (144 lignes)</li> <li>Script de patch avec backup automatique</li> <li>Support dev + Docker</li> <li>Messages clairs avec emojis</li> <li> <p>R\u00e9versible</p> </li> <li> <p><code>ui/assets/favicons/scripts/README_patch_favicon.md</code> (88 lignes)</p> </li> <li>Explication du probl\u00e8me</li> <li>Instructions d'utilisation</li> <li>Quand ex\u00e9cuter le patch</li> <li> <p>R\u00e9f\u00e9rences aux issues Streamlit</p> </li> <li> <p><code>tests/integration/test_streamlit_patch.py</code> (98 lignes)</p> </li> <li>5 tests de validation</li> <li>V\u00e9rification par hash MD5</li> </ol>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#fichiers-modifies","title":"Fichiers Modifi\u00e9s","text":"<ol> <li><code>.devcontainer/postCreateCommand.sh</code> (+19 lignes)</li> <li>Fonction <code>patch_streamlit_favicon()</code></li> <li> <p>Appel\u00e9e apr\u00e8s <code>setup_git</code></p> </li> <li> <p><code>docker/build/Dockerfile</code> (+7 lignes)</p> </li> <li>Patch dans stage <code>builder</code></li> <li> <p>Cleanup des fichiers temporaires</p> </li> <li> <p><code>ui/assets/favicons/README.md</code> (+34 lignes, -5 lignes)</p> </li> <li>Nouvelle section \"Patch Streamlit\"</li> <li>Documentation de l'automatisation</li> <li>Lien vers README_patch_favicon.md</li> </ol>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#statistiques","title":"Statistiques","text":"<ul> <li>Total lignes ajout\u00e9es : 390</li> <li>Total lignes supprim\u00e9es : 5</li> <li>Fichiers cr\u00e9\u00e9s : 3</li> <li>Fichiers modifi\u00e9s : 3</li> <li>Tests : 5 (100% pass)</li> <li>Temps de patch : &lt; 1 seconde</li> </ul>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#apprentissages-cles","title":"Apprentissages Cl\u00e9s","text":""},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#1-probleme-non-resolu-dans-streamlit","title":"1. Probl\u00e8me Non R\u00e9solu dans Streamlit","text":"<p>Ce n'est pas un bug mais une limitation d'architecture : - Le HTML initial contient le favicon par d\u00e9faut - JavaScript (st.set_page_config) s'ex\u00e9cute apr\u00e8s - Streamlit n'a pas d'option pour changer le favicon dans l'HTML initial</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#2-solution-hacky-mais-officiellement-recommandee","title":"2. Solution \"Hacky\" Mais Officiellement Recommand\u00e9e","text":"<p>La communaut\u00e9 Streamlit recommande explicitement cette approche :</p> <p>\"I do not believe there is an easy fix for this unless you go directly into root folder of streamlit and edit the title/favicon there\"</p> <p>R\u00e9f\u00e9rences : - GitHub issue #9058 (ouvert depuis 2023, toujours ouvert) - Discussion #74003 (juillet 2024) - Discussion #30884 (septembre 2022)</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#3-automatisation-critique","title":"3. Automatisation Critique","text":"<p>Le patch doit \u00eatre appliqu\u00e9 automatiquement car il est perdu \u00e0 chaque : - Mise \u00e0 jour de Streamlit (<code>pip install --upgrade streamlit</code>) - Reconstruction du devcontainer - Build de l'image Docker - Cr\u00e9ation d'un nouvel environnement virtuel</p> <p>Notre solution : Int\u00e9grer dans les scripts d'installation (devcontainer + Docker)</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#4-tests-de-modifications-systeme","title":"4. Tests de Modifications Syst\u00e8me","text":"<p>Les tests v\u00e9rifient une modification dans <code>site-packages</code> (hors du code du projet).</p> <p>Technique : Utilisation de hash MD5 pour comparer des images binaires :</p> <pre><code>with open(favicon_path, 'rb') as f:\n    file_hash = hashlib.md5(f.read()).hexdigest()\n</code></pre>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#5-support-multi-environnement-dans-un-seul-script","title":"5. Support Multi-Environnement dans un Seul Script","text":"<p>Le script d\u00e9tecte automatiquement son contexte : - D\u00e9veloppement : <code>project_root/ui/assets/favicons/favicon-32x32.png</code> - Docker : <code>/tmp/custom-favicon.png</code> (copi\u00e9 par Dockerfile)</p> <p>Cela \u00e9vite de dupliquer la logique entre dev et prod.</p>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#impact","title":"Impact","text":""},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#avant","title":"Avant","text":"<ul> <li>\u274c Flash visible du favicon par d\u00e9faut</li> <li>\u274c Bookmarks capturent le mauvais favicon</li> <li>\u274c Exp\u00e9rience utilisateur d\u00e9grad\u00e9e</li> </ul>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#apres","title":"Apr\u00e8s","text":"<ul> <li>\u2705 Aucun flash, favicon personnalis\u00e9 d\u00e8s le d\u00e9but</li> <li>\u2705 Bookmarks capturent le bon favicon</li> <li>\u2705 Automatisation compl\u00e8te (dev + prod)</li> <li>\u2705 Tests garantissent le bon fonctionnement</li> <li>\u2705 Documentation exhaustive</li> </ul>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#commandes-utiles","title":"Commandes Utiles","text":"<pre><code># Appliquer le patch manuellement\npython ui/assets/favicons/scripts/patch_streamlit_favicon.py\n\n# Restaurer l'original\npython ui/assets/favicons/scripts/patch_streamlit_favicon.py --restore\n\n# Tester le patch\npytest tests/integration/test_streamlit_patch.py -v\n\n# V\u00e9rifier l'\u00e9tat du patch\nls -la .venv/lib/python*/site-packages/streamlit/static/favicon.*\n</code></pre>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Streamlit Issue #9058 : https://github.com/streamlit/streamlit/issues/9058</li> <li>Discussion #74003 : https://discuss.streamlit.io/t/favicon-and-title-change-during-refresh/74003</li> <li>Discussion #30884 : https://discuss.streamlit.io/t/page-title-icon-flicker-before-override/30884</li> <li>Issue #76 : https://github.com/castorfou/lmelp/issues/76</li> <li>PR : (\u00e0 compl\u00e9ter apr\u00e8s cr\u00e9ation de la PR)</li> </ul>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#a-retenir-pour-le-futur","title":"\u00c0 Retenir pour le Futur","text":"<ol> <li>Streamlit 1.51.0 n'a pas d'option de configuration pour le favicon initial</li> <li>Le patch est n\u00e9cessaire tant que Streamlit n'impl\u00e9mente pas #9058</li> <li>Automatisation essentielle : int\u00e9grer dans postCreateCommand + Dockerfile</li> <li>Tests MD5 : bonne approche pour v\u00e9rifier des modifications de fichiers binaires</li> <li>Script r\u00e9versible : toujours backup avant de patcher</li> <li>Multi-environnement : un seul script pour dev + Docker gr\u00e2ce \u00e0 la d\u00e9tection de contexte</li> </ol>"},{"location":"claude/memory/251120-2342-streamlit-favicon-flash-fix/#conclusion","title":"Conclusion","text":"<p>Cette solution r\u00e9sout d\u00e9finitivement le probl\u00e8me du flash du favicon en : 1. Patchant directement l'installation Streamlit (seule solution viable) 2. Automatisant le patch pour qu'il survive aux reconstructions 3. Testant avec validation MD5 du patch 4. Documentant pour la maintenabilit\u00e9 future</p> <p>C'est une approche \"hacky\" mais c'est la seule solution recommand\u00e9e par la communaut\u00e9 en attendant une impl\u00e9mentation officielle dans Streamlit.</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/","title":"Fix du Patch Favicon dans Docker - Issue #78","text":"<p>Date: 2025-11-21 08:51 Issue: #78 - Ic\u00f4ne crown toujours visible dans l'image Docker Branche: <code>78-bug-icone-crown-toujours-visible-dans-limage-docker</code> Issue li\u00e9e: #76 (fix initial du favicon)</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#probleme","title":"Probl\u00e8me","text":"<p>Apr\u00e8s la r\u00e9solution de l'issue #76 qui corrigeait le flash du favicon, un nouveau bug persistait : - Le favicon personnalis\u00e9 (masque de th\u00e9\u00e2tre) fonctionnait en d\u00e9veloppement (devcontainer) - Mais dans l'image Docker, l'ancien favicon de Streamlit (couronne blanche) \u00e9tait toujours visible - Le patch appliqu\u00e9 dans le stage <code>builder</code> du Dockerfile ne se propageait pas au stage <code>runtime</code></p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#diagnostic-investigation-approfondie","title":"Diagnostic (Investigation approfondie)","text":""},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#1-bug-initial-dans-patch_streamlit_faviconpy","title":"1. Bug initial dans <code>patch_streamlit_favicon.py</code>","text":"<p>Probl\u00e8me d\u00e9couvert : Calcul incorrect du chemin du favicon personnalis\u00e9 (ligne 59-60)</p> <pre><code># \u274c CODE BUGU\u00c9 (ancien)\nproject_root = Path(__file__).resolve().parent.parent\ncustom_favicon = project_root / \"ui\" / \"assets\" / \"favicons\" / \"favicon-32x32.png\"\n</code></pre> <p>Ce code donnait : - <code>__file__</code> = <code>/path/to/ui/assets/favicons/scripts/patch_streamlit_favicon.py</code> - <code>.parent.parent</code> = <code>/path/to/ui/assets/favicons</code> - Chemin final = <code>/path/to/ui/assets/favicons/ui/assets/favicons/favicon-32x32.png</code> \u274c (duplication!)</p> <p>Solution : Simplification du calcul du chemin</p> <pre><code># \u2705 CODE CORRIG\u00c9\nscript_dir = Path(__file__).resolve().parent  # scripts/\nfavicons_dir = script_dir.parent  # favicons/\ncustom_favicon = favicons_dir / \"favicon-32x32.png\"\n</code></pre>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#2-probleme-docker-cache-cleaning-trop-precoce","title":"2. Probl\u00e8me Docker : Cache cleaning trop pr\u00e9coce","text":"<p>Probl\u00e8me : Dans le Dockerfile original, le nettoyage de <code>/tmp</code> intervenait AVANT la copie des fichiers du patch</p> <pre><code># \u274c BUGU\u00c9 (ligne 39)\nRUN uv pip install --system -r requirements.txt || \\\n    (grep -v \"dbus-python\" requirements.txt &gt; requirements-docker.txt &amp;&amp; \\\n     uv pip install --system -r requirements-docker.txt) &amp;&amp; \\\n    rm -rf /root/.cache/uv /tmp/*  # \u2190 Efface /tmp !\n\n# Puis on essayait de copier dans /tmp (trop tard !)\nCOPY ui/assets/favicons/favicon-32x32.png /tmp/custom-favicon.png\n</code></pre> <p>Solution : Retirer <code>/tmp/*</code> du cleanup initial (ligne 39)</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#3-probleme-docker-majeur-copy-entre-stages-multi-stage","title":"3. Probl\u00e8me Docker majeur : COPY entre stages multi-stage","text":"<p>D\u00e9couverte critique : Le patch fonctionnait dans le stage <code>builder</code> mais PAS dans <code>runtime</code> !</p> <p>Test effectu\u00e9 :</p> <pre><code># Build du stage builder uniquement\ndocker build --target builder -t lmelp-builder:debug -f docker/build/Dockerfile .\n\n# V\u00e9rification du favicon dans le builder\ndocker run --rm --entrypoint bash lmelp-builder:debug -c \\\n  \"md5sum /usr/local/lib/python3.11/site-packages/streamlit/static/favicon.png\"\n</code></pre> <p>R\u00e9sultat : MD5 = <code>42d91dcef2820c85b57b489f4e1b03cf</code> (notre favicon \u2705)</p> <p>Mais dans le runtime :</p> <pre><code>docker run --rm --entrypoint bash lmelp-test:issue-78 -c \\\n  \"md5sum /usr/local/lib/python3.11/site-packages/streamlit/static/favicon.png\"\n</code></pre> <p>R\u00e9sultat : MD5 = <code>20356bee5e4f7b010a2d19d765d94d6f</code> (ancien favicon Streamlit \u274c)</p> <p>Cause racine : Quand Docker copie <code>/usr/local</code> du builder vers le runtime avec <code>COPY --from=builder</code>, il peut utiliser un cache ou ne pas copier correctement les fichiers modifi\u00e9s APR\u00c8S l'installation des packages.</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#solution-finale","title":"Solution finale","text":"<p>D\u00e9placer le patch du stage <code>builder</code> vers le stage <code>runtime</code>, APR\u00c8S le COPY</p> <pre><code># Stage 2: Builder - Install Python dependencies\nFROM base AS builder\n\nWORKDIR /build\n\nRUN pip install --no-cache-dir uv\nCOPY .devcontainer/requirements.txt .\nRUN uv pip install --system -r requirements.txt || \\\n    (grep -v \"dbus-python\" requirements.txt &gt; requirements-docker.txt &amp;&amp; \\\n     uv pip install --system -r requirements-docker.txt) &amp;&amp; \\\n    rm -rf /root/.cache/uv /tmp/*\n\n# Stage 3: Runtime image\nFROM base AS runtime\n\nWORKDIR /app\n\n# Copy Python packages from builder\nCOPY --from=builder /usr/local /usr/local\n\n# \u2705 Patch Streamlit favicon APR\u00c8S avoir copi\u00e9 /usr/local\n# IMPORTANT: Must be done AFTER copying /usr/local from builder to ensure the patch persists\nCOPY ui/assets/favicons/favicon-32x32.png /tmp/custom-favicon.png\nCOPY ui/assets/favicons/scripts/patch_streamlit_favicon.py /tmp/patch_streamlit_favicon.py\nRUN python /tmp/patch_streamlit_favicon.py &amp;&amp; \\\n    rm -rf /tmp/*\n</code></pre> <p>Pourquoi \u00e7a fonctionne : 1. Les packages Python (dont Streamlit) sont install\u00e9s dans le builder 2. <code>/usr/local</code> est copi\u00e9 du builder vers runtime (\u00e9tat initial de Streamlit) 3. Le patch est appliqu\u00e9 DANS le runtime APR\u00c8S la copie 4. Les modifications persistent car elles sont faites directement dans l'image finale</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#modifications-effectuees","title":"Modifications effectu\u00e9es","text":""},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#1-uiassetsfaviconsscriptspatch_streamlit_faviconpy-lignes-56-78","title":"1. <code>ui/assets/favicons/scripts/patch_streamlit_favicon.py</code> (lignes 56-78)","text":"<p>Avant :</p> <pre><code>def get_custom_favicon_path():\n    project_root = Path(__file__).resolve().parent.parent\n    custom_favicon = project_root / \"ui\" / \"assets\" / \"favicons\" / \"favicon-32x32.png\"\n    # ...\n</code></pre> <p>Apr\u00e8s :</p> <pre><code>def get_custom_favicon_path():\n    \"\"\"Get the path to our custom favicon.\"\"\"\n    # First, check for Docker build context where file is copied to /tmp\n    docker_favicon = Path(\"/tmp/custom-favicon.png\")\n    if docker_favicon.exists():\n        return docker_favicon\n\n    # Standard project location: simplified path calculation\n    script_dir = Path(__file__).resolve().parent  # scripts/\n    favicons_dir = script_dir.parent  # favicons/\n    custom_favicon = favicons_dir / \"favicon-32x32.png\"\n\n    if custom_favicon.exists():\n        return custom_favicon\n\n    return custom_favicon\n</code></pre>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#2-dockerbuilddockerfile-lignes-35-54","title":"2. <code>docker/build/Dockerfile</code> (lignes 35-54)","text":"<p>Changements : - Ligne 39 : Retrait de <code>/tmp/*</code> du cleanup apr\u00e8s <code>uv pip install</code> - Lignes 41-47 : Suppression du patch du stage builder - Lignes 49-54 : Ajout du patch dans le stage runtime, APR\u00c8S <code>COPY --from=builder</code></p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#3-testsintegrationtest_streamlit_patchpy-lignes-112-151","title":"3. <code>tests/integration/test_streamlit_patch.py</code> (lignes 112-151)","text":"<p>Nouveau test : <code>test_get_custom_favicon_path_returns_valid_path()</code></p> <p>Ce test v\u00e9rifie que la fonction <code>get_custom_favicon_path()</code> retourne un chemin valide qui existe r\u00e9ellement.</p> <pre><code>def test_get_custom_favicon_path_returns_valid_path(self):\n    \"\"\"Test that get_custom_favicon_path() returns a path that exists.\"\"\"\n    from patch_streamlit_favicon import get_custom_favicon_path\n\n    custom_path = get_custom_favicon_path()\n\n    assert custom_path.exists()\n    assert custom_path.is_file()\n    assert custom_path.name == \"favicon-32x32.png\"\n</code></pre>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#tests-et-validation","title":"Tests et validation","text":""},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#tests-unitaires","title":"Tests unitaires","text":"<pre><code># Tests du patch Streamlit (6 tests)\npytest tests/integration/test_streamlit_patch.py -v\n</code></pre> <p>R\u00e9sultat : \u2705 6/6 tests passent</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#tests-complets","title":"Tests complets","text":"<pre><code>pytest tests/ -x\n</code></pre> <p>R\u00e9sultat : \u2705 283/283 tests passent</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#validation-docker","title":"Validation Docker","text":"<pre><code># Build de l'image\ndocker build -t lmelp-test -f docker/build/Dockerfile .\n\n# V\u00e9rification du MD5\ndocker run --rm --entrypoint bash lmelp-test -c \\\n  \"md5sum /usr/local/lib/python3.11/site-packages/streamlit/static/favicon.png\"\n</code></pre> <p>R\u00e9sultat : MD5 = <code>42d91dcef2820c85b57b489f4e1b03cf</code> \u2705 (notre favicon personnalis\u00e9)</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#validation-visuelle","title":"Validation visuelle","text":"<ol> <li>Lancer le container : <code>docker run --rm -p 8501:8501 lmelp-test</code></li> <li>Ouvrir le navigateur : http://localhost:8501</li> <li>Important : Vider le cache du navigateur (Ctrl+Shift+R)</li> <li>\u2705 Le masque de th\u00e9\u00e2tre s'affiche sans flash de la couronne</li> </ol>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#apprentissages-cles","title":"Apprentissages cl\u00e9s","text":""},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#1-multi-stage-docker-builds-et-modifications-de-fichiers","title":"1. Multi-stage Docker builds et modifications de fichiers","text":"<p>Le\u00e7on : Les modifications apport\u00e9es aux fichiers dans un stage builder peuvent ne pas persister lors d'un <code>COPY --from=builder</code>.</p> <p>Raison : Docker peut utiliser des caches de layers ou copier l'\u00e9tat initial des r\u00e9pertoires, pas l'\u00e9tat apr\u00e8s modifications.</p> <p>Solution : Appliquer les modifications dans le stage final (runtime), APR\u00c8S avoir copi\u00e9 les d\u00e9pendances.</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#2-chemins-relatifs-dans-les-scripts-python","title":"2. Chemins relatifs dans les scripts Python","text":"<p>Le\u00e7on : Calculer des chemins relatifs avec <code>.parent.parent</code> est fragile et source d'erreurs.</p> <p>Bonne pratique : - Utiliser des variables interm\u00e9diaires explicites (<code>script_dir</code>, <code>favicons_dir</code>) - Ajouter des commentaires pour documenter chaque \u00e9tape du calcul - Tester avec un test d\u00e9di\u00e9</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#3-priorite-docker-vs-developpement","title":"3. Priorit\u00e9 Docker vs d\u00e9veloppement","text":"<p>Strat\u00e9gie du script <code>patch_streamlit_favicon.py</code> : 1. D'abord : V\u00e9rifier <code>/tmp/custom-favicon.png</code> (contexte Docker) 2. Ensuite : Chercher dans le projet (contexte dev)</p> <p>Cette priorit\u00e9 garantit que le contexte Docker est toujours favoris\u00e9 quand il existe.</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#4-cache-navigateur-et-favicons","title":"4. Cache navigateur et favicons","text":"<p>Pi\u00e8ge : Les navigateurs cachent agressivement les favicons !</p> <p>Solution pour tester : - Vider compl\u00e8tement le cache (Ctrl+Shift+R ou Ctrl+F5) - Ou tester en navigation priv\u00e9e - Ou aller directement sur <code>/favicon.png</code> pour v\u00e9rifier</p>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#5-debugging-docker-multi-stage","title":"5. Debugging Docker multi-stage","text":"<p>Techniques utilis\u00e9es :</p> <pre><code># Build d'un stage sp\u00e9cifique\ndocker build --target builder -t debug-builder .\n\n# Inspection d'un stage\ndocker run --rm --entrypoint bash debug-builder -c \"commandes...\"\n\n# Ajout de logs temporaires dans RUN\nRUN echo \"=== Debug ===\" &amp;&amp; commande &amp;&amp; echo \"=== End ===\"\n</code></pre>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#impact","title":"Impact","text":""},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#avant","title":"Avant","text":"<ul> <li>\u274c Favicon personnalis\u00e9 ne fonctionnait pas dans Docker</li> <li>\u274c Couronne blanche (d\u00e9faut Streamlit) visible dans les containers</li> <li>\u274c Bug dans le calcul du chemin du script de patch</li> <li>\u274c Ordre incorrect des op\u00e9rations dans le Dockerfile</li> </ul>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#apres","title":"Apr\u00e8s","text":"<ul> <li>\u2705 Favicon personnalis\u00e9 fonctionne en dev ET en Docker</li> <li>\u2705 Aucun flash de la couronne lors du chargement</li> <li>\u2705 Chemin du favicon calcul\u00e9 correctement</li> <li>\u2705 Patch appliqu\u00e9 au bon moment dans le build Docker</li> <li>\u2705 6 tests de validation du patch (100% pass)</li> <li>\u2705 Architecture Docker propre et maintenable</li> </ul>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#fichiers-modifies","title":"Fichiers modifi\u00e9s","text":"<ol> <li><code>ui/assets/favicons/scripts/patch_streamlit_favicon.py</code> (+10 lignes, -5 lignes)</li> <li>Correction du calcul du chemin du favicon</li> <li> <p>Priorit\u00e9 \u00e0 <code>/tmp/custom-favicon.png</code> (Docker)</p> </li> <li> <p><code>docker/build/Dockerfile</code> (+6 lignes, -7 lignes)</p> </li> <li>D\u00e9placement du patch du builder vers runtime</li> <li>Retrait de <code>/tmp/*</code> du cleanup initial</li> <li> <p>Ajout de commentaires explicatifs</p> </li> <li> <p><code>tests/integration/test_streamlit_patch.py</code> (+40 lignes)</p> </li> <li>Nouveau test <code>test_get_custom_favicon_path_returns_valid_path()</code></li> </ol>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#statistiques","title":"Statistiques","text":"<ul> <li>Temps d'investigation : ~2h (tests Docker, debugging multi-stage)</li> <li>Lignes modifi\u00e9es : 56 (+56, -12)</li> <li>Tests ajout\u00e9s : 1 (total: 6 tests de patch favicon)</li> <li>Couverture : 283/283 tests passent (100%)</li> </ul>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#commandes-utiles","title":"Commandes utiles","text":"<pre><code># Build de l'image Docker\ndocker build -t lmelp:latest -f docker/build/Dockerfile .\n\n# Test du favicon dans l'image\ndocker run --rm --entrypoint bash lmelp:latest -c \\\n  \"md5sum /usr/local/lib/python3.11/site-packages/streamlit/static/favicon.png\"\n\n# Lancement du container\ndocker run --rm -p 8501:8501 lmelp:latest\n\n# Debug du stage builder\ndocker build --target builder -t lmelp-builder:debug -f docker/build/Dockerfile .\ndocker run --rm --entrypoint bash lmelp-builder:debug\n</code></pre>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Issue #78 : https://github.com/castorfou/lmelp/issues/78</li> <li>Issue #76 : https://github.com/castorfou/lmelp/issues/76 (fix initial du favicon)</li> <li>Streamlit Issue #9058 : https://github.com/streamlit/streamlit/issues/9058</li> <li>M\u00e9moire pr\u00e9c\u00e9dente : <code>251120-2342-streamlit-favicon-flash-fix.md</code></li> </ul>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#a-retenir-pour-le-futur","title":"\u00c0 retenir pour le futur","text":"<ol> <li>Docker multi-stage : Les modifications de fichiers doivent \u00eatre faites dans le stage final</li> <li>Calcul de chemins : Toujours simplifier et documenter les calculs de chemins relatifs</li> <li>Tests de chemins : Ajouter des tests qui v\u00e9rifient l'existence des fichiers retourn\u00e9s</li> <li>Cache navigateur : Toujours vider le cache lors des tests de favicons</li> <li>Debugging Docker : Utiliser <code>--target</code> pour inspecter les stages interm\u00e9diaires</li> <li>TDD sauve la vie : Le test RED a imm\u00e9diatement r\u00e9v\u00e9l\u00e9 le bug du chemin</li> </ol>"},{"location":"claude/memory/251121-0851-docker-favicon-patch-fix/#conclusion","title":"Conclusion","text":"<p>Cette issue a r\u00e9v\u00e9l\u00e9 deux bugs distincts :</p> <ol> <li>Bug logique dans <code>patch_streamlit_favicon.py</code> : calcul incorrect du chemin</li> <li>Bug d'architecture Docker : patch appliqu\u00e9 au mauvais moment (avant le COPY)</li> </ol> <p>La solution finale combine : - Correction du code Python (chemin simplifi\u00e9) - R\u00e9organisation du Dockerfile (patch dans runtime) - Tests robustes (validation du chemin)</p> <p>Le favicon personnalis\u00e9 fonctionne maintenant parfaitement en d\u00e9veloppement ET en production (Docker) ! \ud83c\udfad</p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/","title":"Impl\u00e9mentation du champ <code>masked</code> pour filtrer les \u00e9pisodes","text":"<p>Date: 23 novembre 2025, 20:53 Issue: #73 - Utiliser le champ masked des episodes Branche: <code>73-utiliser-le-champ-masked-des-episodes</code></p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#contexte","title":"Contexte","text":"<p>Le back-office lmelp (https://github.com/castorfou/back-office-lmelp/issues/107) a impl\u00e9ment\u00e9 un champ <code>masked</code> pour permettre de masquer certains \u00e9pisodes (comme les Goncourt ou les \u00e9pisodes mal d\u00e9tect\u00e9s) sans les supprimer de MongoDB. Ce d\u00e9veloppement synchronise le front-office pour utiliser ce champ et filtrer automatiquement les \u00e9pisodes masqu\u00e9s dans toutes les pages UI.</p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#problematique","title":"Probl\u00e9matique","text":"<ul> <li>Le champ <code>masked</code> n'existait pas dans le mod\u00e8le <code>Episode</code> du front-office</li> <li>Toutes les pages UI affichaient tous les \u00e9pisodes, y compris ceux marqu\u00e9s comme <code>masked=true</code> dans MongoDB</li> <li>Le compteur du dashboard affichait le nombre total d'\u00e9pisodes incluant les masqu\u00e9s</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#solution-implementee-approche-tdd","title":"Solution impl\u00e9ment\u00e9e (approche TDD)","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#1-ajout-du-champ-masked-au-modele-episode","title":"1. Ajout du champ <code>masked</code> au mod\u00e8le Episode","text":"<p>Fichier modifi\u00e9: <code>nbs/py mongo helper episodes.ipynb</code> \u2192 g\u00e9n\u00e8re <code>nbs/mongo_episode.py</code></p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#dans-episode__init__","title":"Dans <code>Episode.__init__</code>:","text":"<pre><code>if self.exists():\n    episode = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n    # ... autres champs ...\n    self.masked: bool = episode.get(\"masked\", False)  # \u2705 Nouveau\nelse:\n    # ... autres champs ...\n    self.masked = False  # \u2705 Nouveau\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#dans-episodekeep","title":"Dans <code>Episode.keep()</code>:","text":"<pre><code>self.collection.insert_one({\n    \"titre\": self.titre,\n    \"date\": self.date,\n    # ... autres champs ...\n    \"masked\": self.masked,  # \u2705 Nouveau\n})\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#dans-episodeto_dict","title":"Dans <code>Episode.to_dict()</code>:","text":"<pre><code>def to_dict(self) -&gt; Dict[str, Union[str, datetime, int, None, bool]]:  # \u2705 bool ajout\u00e9\n    return {\n        \"date\": self.date,\n        # ... autres champs ...\n        \"masked\": self.masked,  # \u2705 Nouveau\n    }\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#2-filtrage-automatique-dans-episodesget_entries","title":"2. Filtrage automatique dans <code>Episodes.get_entries()</code>","text":"<p>Logique de filtrage MongoDB:</p> <pre><code>def get_entries(self, request: Any = \"\", limit: int = -1, include_masked: bool = False):\n    \"\"\"Filtre par d\u00e9faut les \u00e9pisodes masqu\u00e9s.\"\"\"\n    if not include_masked:\n        # Filtre: masked != true OU masked n'existe pas (anciens \u00e9pisodes)\n        masked_filter = {\n            \"$or\": [\n                {\"masked\": {\"$ne\": True}},\n                {\"masked\": {\"$exists\": False}}\n            ]\n        }\n\n        if request and request != \"\":\n            # Combiner avec une requ\u00eate existante\n            final_request = {\"$and\": [request, masked_filter]}\n        else:\n            final_request = masked_filter\n    else:\n        # include_masked=True : pas de filtre\n        final_request = request if request != \"\" else {}\n\n    # Ex\u00e9cuter la requ\u00eate MongoDB\n    results = self.collection.find(final_request, {\"_id\": 1}).sort({\"date\": -1})\n    # ...\n</code></pre> <p>Avantages: - \u2705 Filtrage par d\u00e9faut transparent pour toutes les pages UI - \u2705 Backward compatible (\u00e9pisodes sans champ <code>masked</code> sont visibles) - \u2705 Option <code>include_masked=True</code> pour les pages d'administration - \u2705 Compatible avec les requ\u00eates existantes (combinaison via <code>$and</code>)</p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#3-correction-du-dashboard-avec-len_total_entries","title":"3. Correction du dashboard avec <code>len_total_entries()</code>","text":"<p>Avant:</p> <pre><code>def len_total_entries(self) -&gt; int:\n    return self.collection.estimated_document_count()  # \u274c Compte TOUT\n</code></pre> <p>Apr\u00e8s:</p> <pre><code>def len_total_entries(self, include_masked: bool = False) -&gt; int:\n    \"\"\"Compte les \u00e9pisodes en respectant le filtre masked.\"\"\"\n    if not include_masked:\n        masked_filter = {\n            \"$or\": [\n                {\"masked\": {\"$ne\": True}},\n                {\"masked\": {\"$exists\": False}}\n            ]\n        }\n        return self.collection.count_documents(masked_filter)  # \u2705 Filtre appliqu\u00e9\n    else:\n        return self.collection.estimated_document_count()\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#tests-tdd-red-green","title":"Tests (TDD - Red \u2192 Green)","text":"<p>Fichier: <code>tests/unit/test_mongo_episode.py</code></p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#tests-crees-5-tests","title":"Tests cr\u00e9\u00e9s (5 tests):","text":"<ol> <li>test_episode_has_masked_field: V\u00e9rifie que le champ existe</li> <li>test_episode_masked_default_value: V\u00e9rifie la valeur par d\u00e9faut <code>False</code></li> <li>test_episode_to_dict_includes_masked: V\u00e9rifie l'export dans <code>to_dict()</code></li> <li>test_episodes_get_entries_filters_masked_by_default: V\u00e9rifie le filtrage automatique</li> <li>test_episodes_get_entries_with_include_masked_true: V\u00e9rifie l'option <code>include_masked=True</code></li> </ol>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#resultats","title":"R\u00e9sultats:","text":"<ul> <li>\u2705 248 tests passent (dont 5 nouveaux)</li> <li>\u2705 Aucun test cass\u00e9</li> <li>\u2705 Couverture maintenue</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#workflow-de-developpement-collaboratif","title":"Workflow de d\u00e9veloppement collaboratif","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#methode-iterative-notebook-python","title":"M\u00e9thode it\u00e9rative notebook \u2194 Python:","text":"<ol> <li>Claude modifie <code>nbs/mongo_episode.py</code> (fichier g\u00e9n\u00e9r\u00e9)</li> <li>Utilisateur applique les modifications dans le notebook <code>nbs/py mongo helper episodes.ipynb</code></li> <li>Utilisateur ex\u00e9cute <code>nbdev_export</code> pour r\u00e9g\u00e9n\u00e9rer le <code>.py</code></li> <li>Claude v\u00e9rifie que la r\u00e9g\u00e9n\u00e9ration est correcte</li> <li>R\u00e9p\u00e9ter jusqu'\u00e0 impl\u00e9mentation compl\u00e8te</li> </ol> <p>Avantage: Permet de travailler sur la logique sans se perdre dans la structure JSON du notebook.</p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#impact-sur-les-pages-ui","title":"Impact sur les pages UI","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#pages-automatiquement-corrigees-sans-modification","title":"Pages automatiquement corrig\u00e9es (sans modification):","text":"<ul> <li>\u2705 ui/pages/1_episodes.py: Affiche uniquement les \u00e9pisodes non masqu\u00e9s (221 au lieu de 236)</li> <li>\u2705 ui/pages/4_avis_critiques.py: Liste uniquement les \u00e9pisodes non masqu\u00e9s pour g\u00e9n\u00e9rer des r\u00e9sum\u00e9s</li> <li>\u2705 Dashboard principal: Compteur correct du nombre d'\u00e9pisodes</li> </ul> <p>Raison: Toutes ces pages utilisent <code>Episodes.get_entries()</code> qui filtre maintenant par d\u00e9faut.</p>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#commandes-utilisees","title":"Commandes utilis\u00e9es","text":"<pre><code># Cr\u00e9er et checkout la branche feature depuis l'issue\ngh issue develop 73 --checkout\n\n# Lancer les tests sp\u00e9cifiques\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/unit/test_mongo_episode.py::TestMaskedField -v\n\n# Lancer tous les tests unitaires\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/unit/ -x -q\n\n# Exporter le notebook vers Python (fait par l'utilisateur)\nnbdev_export\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#apprentissages-cles","title":"Apprentissages cl\u00e9s","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#1-programmation-litteraire-avec-nbdev","title":"1. Programmation litt\u00e9raire avec nbdev","text":"<ul> <li>\u26a0\ufe0f Ne jamais modifier directement les fichiers <code>.py</code> dans <code>nbs/</code></li> <li>\u2705 Toujours modifier le notebook <code>.ipynb</code> source</li> <li>\u2705 Utiliser <code>nbdev_export</code> pour g\u00e9n\u00e9rer les modules Python</li> <li>\ud83d\udca1 Astuce: Modifier temporairement le <code>.py</code> pour valider la logique, puis reporter dans le notebook</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#2-filtrage-mongodb-avec-backward-compatibility","title":"2. Filtrage MongoDB avec backward compatibility","text":"<pre><code># Pattern pour filtrer un champ bool\u00e9en avec r\u00e9trocompatibilit\u00e9\n{\n    \"$or\": [\n        {\"field\": {\"$ne\": True}},      # field existe et n'est pas True\n        {\"field\": {\"$exists\": False}}  # field n'existe pas (anciens docs)\n    ]\n}\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#3-combinaison-de-requetes-mongodb","title":"3. Combinaison de requ\u00eates MongoDB","text":"<pre><code># Combiner un filtre avec une requ\u00eate existante\nif existing_request:\n    final_request = {\"$and\": [existing_request, new_filter]}\nelse:\n    final_request = new_filter\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#4-tdd-avec-mocks-pymongo","title":"4. TDD avec mocks PyMongo","text":"<p>Pi\u00e8ge identifi\u00e9: Quand un \u00e9pisode \"existe\" selon le mock, <code>.get(\"masked\", False)</code> retourne un <code>MagicMock</code> au lieu de <code>False</code>.</p> <p>Solution: Forcer le mock \u00e0 retourner <code>None</code> pour <code>find_one()</code>:</p> <pre><code>mock_collection.find_one.return_value = None  # Force \"n'existe pas\"\n</code></pre>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#fichiers-modifies","title":"Fichiers modifi\u00e9s","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#code-source","title":"Code source:","text":"<ul> <li><code>nbs/py mongo helper episodes.ipynb</code> (notebook source)</li> <li><code>nbs/mongo_episode.py</code> (g\u00e9n\u00e9r\u00e9 automatiquement)</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#tests","title":"Tests:","text":"<ul> <li><code>tests/unit/test_mongo_episode.py</code> (+5 tests, classe <code>TestMaskedField</code>)</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#pages-ui","title":"Pages UI:","text":"<ul> <li>\u274c Aucune modification n\u00e9cessaire (filtrage transparent via <code>get_entries()</code>)</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#metriques","title":"M\u00e9triques","text":"<ul> <li>Lignes ajout\u00e9es dans mongo_episode.py: ~40 lignes</li> <li>Lignes de tests ajout\u00e9es: ~110 lignes</li> <li>Tests: 5 nouveaux, 248 total passent</li> <li>Temps de d\u00e9veloppement: ~1h30 (TDD + it\u00e9rations collaboratives)</li> <li>Complexit\u00e9: Faible (ajout de champ + filtrage simple)</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#points-dattention-pour-le-futur","title":"Points d'attention pour le futur","text":""},{"location":"claude/memory/251123-2053-masked-field-implementation/#1-migration-de-donnees-non-necessaire-ici","title":"1. Migration de donn\u00e9es (non n\u00e9cessaire ici)","text":"<ul> <li>Les anciens \u00e9pisodes sans champ <code>masked</code> sont trait\u00e9s comme <code>masked=False</code> gr\u00e2ce au filtre <code>{\"$exists\": False}</code></li> <li>Aucune migration MongoDB requise</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#2-pages-dadministration-futures","title":"2. Pages d'administration futures","text":"<ul> <li>Si besoin d'afficher les \u00e9pisodes masqu\u00e9s, utiliser <code>get_entries(include_masked=True)</code></li> <li>Exemple: page de gestion des \u00e9pisodes masqu\u00e9s</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#3-scripts-de-traitement","title":"3. Scripts de traitement","text":"<ul> <li>Les scripts dans <code>scripts/</code> continuent de fonctionner sans modification</li> <li>V\u00e9rifier si certains scripts doivent traiter les \u00e9pisodes masqu\u00e9s</li> </ul>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#prochaines-etapes","title":"Prochaines \u00e9tapes","text":"<ol> <li>\u2705 Tests passent</li> <li>\u2705 UI fonctionnelle</li> <li>\u23f3 Commit et push</li> <li>\u23f3 V\u00e9rification CI/CD</li> <li>\u23f3 Cr\u00e9ation de la PR</li> <li>\u23f3 Documentation (CLAUDE.md, README.md si n\u00e9cessaire)</li> </ol>"},{"location":"claude/memory/251123-2053-masked-field-implementation/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Issue back-office: https://github.com/castorfou/back-office-lmelp/issues/107</li> <li>Issue front-office: #73</li> <li>Branche: <code>73-utiliser-le-champ-masked-des-episodes</code></li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/","title":"Migration Streamlit: use_container_width \u2192 width","text":"<p>Date: 2025-11-25 09:24 Issue: #80 Branch: <code>80-streamlit-use_container_width-is-deprecated</code> Type: Maintenance / Migration API</p>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#probleme","title":"Probl\u00e8me","text":"<p>Streamlit a d\u00e9pr\u00e9ci\u00e9 le param\u00e8tre <code>use_container_width</code> qui sera supprim\u00e9 apr\u00e8s le 31/12/2025. L'application affichait des warnings de d\u00e9pr\u00e9ciation au d\u00e9marrage :</p> <pre><code>Please replace `use_container_width` with `width`.\nuse_container_width will be removed after 2025-12-31.\n\nFor use_container_width=True, use width='stretch'.\nFor use_container_width=False, use width='content'.\n</code></pre>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#solution-implementee","title":"Solution impl\u00e9ment\u00e9e","text":""},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#migration-api-streamlit","title":"Migration API Streamlit","text":"<p>Remplacement syst\u00e9matique de <code>use_container_width=True</code> par <code>width='stretch'</code> dans tous les composants Streamlit.</p>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#fichiers-modifies","title":"Fichiers modifi\u00e9s","text":"<ol> <li>ui/pages/1_episodes.py (2 modifications)</li> <li>Ligne 58 : <code>st.dataframe(episodes_df, width='stretch')</code></li> <li> <p>Ligne 114 : <code>st.plotly_chart(fig, width='stretch')</code></p> </li> <li> <p>ui/pages/4_avis_critiques.py (2 modifications)</p> </li> <li>Ligne 362 : Bouton \"\u2b05\ufe0f Pr\u00e9c\u00e9dent\" - <code>width='stretch'</code></li> <li>Ligne 380 : Bouton \"Suivant \u27a1\ufe0f\" - <code>width='stretch'</code></li> </ol>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#methode-de-recherche","title":"M\u00e9thode de recherche","text":"<pre><code># Recherche exhaustive dans le dossier UI\ngrep -r \"use_container_width\" ui/\n\n# V\u00e9rification apr\u00e8s correction\ngrep -r \"use_container_width\" ui/  # Aucun r\u00e9sultat\n</code></pre>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#points-techniques","title":"Points techniques","text":""},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#composants-streamlit-concernes","title":"Composants Streamlit concern\u00e9s","text":"<ul> <li><code>st.dataframe()</code> - Affichage de tableaux de donn\u00e9es</li> <li><code>st.plotly_chart()</code> - Affichage de graphiques Plotly</li> <li><code>st.button()</code> - Boutons de navigation</li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#equivalence-api","title":"\u00c9quivalence API","text":"Ancien param\u00e8tre Nouveau param\u00e8tre Usage <code>use_container_width=True</code> <code>width='stretch'</code> Utilise toute la largeur du conteneur <code>use_container_width=False</code> <code>width='content'</code> Largeur adapt\u00e9e au contenu <p>Dans ce projet, toutes les occurrences utilisaient <code>=True</code>, donc migration vers <code>'stretch'</code>.</p>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#validation","title":"Validation","text":""},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#tests-automatises","title":"Tests automatis\u00e9s","text":"<ul> <li>\u2705 Tests UI : 14/14 pass\u00e9s</li> <li>\u2705 Tests unitaires : 255/255 pass\u00e9s</li> <li>\u2705 Aucune r\u00e9gression d\u00e9tect\u00e9e</li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#tests-manuels","title":"Tests manuels","text":"<ul> <li>\u2705 Page \"\u00c9pisodes\" : dataframe et graphique s'affichent correctement en pleine largeur</li> <li>\u2705 Page \"Avis critiques\" : boutons de navigation fonctionnent et occupent toute la largeur</li> <li>\u2705 Aucun warning de d\u00e9pr\u00e9ciation au d\u00e9marrage</li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#rendu-visuel","title":"Rendu visuel","text":"<p>Comportement strictement identique avant/apr\u00e8s la migration. Seule l'API interne change.</p>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#apprentissages","title":"Apprentissages","text":""},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#migration-dapi-deprecated","title":"Migration d'API deprecated","text":"<ol> <li>Recherche exhaustive : Utiliser <code>grep</code> pour identifier toutes les occurrences</li> <li>V\u00e9rification post-migration : Re-grep pour confirmer qu'aucune occurrence ne subsiste</li> <li>Tests de non-r\u00e9gression : Les tests existants suffisent pour ce type de migration</li> <li>Validation visuelle : Essentielle pour les modifications UI</li> </ol>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#bonnes-pratiques-streamlit","title":"Bonnes pratiques Streamlit","text":"<ul> <li>Suivre les migrations d'API pour \u00e9viter les breaking changes</li> <li>Les warnings de d\u00e9pr\u00e9ciation donnent toujours la migration exacte \u00e0 effectuer</li> <li>Pour les widgets, <code>width='stretch'</code> est \u00e9quivalent \u00e0 <code>use_container_width=True</code></li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#structure-des-tests-ui","title":"Structure des tests UI","text":"<p>Le projet a une bonne structure de tests UI dans <code>tests/ui/test_streamlit.py</code> : - Tests de configuration - Tests de composants - Tests de logique m\u00e9tier - Tests de compatibilit\u00e9 des types - Tests d'int\u00e9gration</p> <p>Ces tests ont permis de valider la migration sans r\u00e9gression.</p>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#impact","title":"Impact","text":"<ul> <li>Maintenance : Code \u00e0 jour avec les derni\u00e8res API Streamlit</li> <li>Stabilit\u00e9 : \u00c9vite les breaking changes apr\u00e8s le 31/12/2025</li> <li>Exp\u00e9rience utilisateur : Aucun changement visible, suppression des warnings</li> </ul>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#commandes-utiles","title":"Commandes utiles","text":"<pre><code># Rechercher use_container_width\ngrep -r \"use_container_width\" ui/\n\n# Tests UI uniquement\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/ui/ -v\n\n# Tests complets\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/ -k \"not integration\"\n</code></pre>"},{"location":"claude/memory/251125-0924-streamlit-deprecation-use-container-width/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Issue #80</li> <li>Documentation Streamlit : Migration de <code>use_container_width</code> vers <code>width</code></li> <li>PR : \u00c0 cr\u00e9er apr\u00e8s validation</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/","title":"Fix Portainer Logging Issues - Issue #83","text":"<p>Date: 2025-11-26 19:10 Issue: #83 - portainer - pas de log d'activite Branch: 83-portainer-pas-de-log-dactivite</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#probleme-initial","title":"Probl\u00e8me Initial","text":"<p>Les logs Portainer pour le conteneur lmelp pr\u00e9sentaient deux probl\u00e8mes :</p> <ol> <li>Affichage bizarre : Caract\u00e8re <code>^A</code> suivi de <code>b</code> dans les logs</li> <li>Absence de logs d'activit\u00e9 HTTP : Contrairement \u00e0 backoffice-frontend qui affiche des logs HTTP d\u00e9taill\u00e9s</li> </ol>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#logs-avant-correction","title":"Logs avant correction","text":"<pre><code>==================================\nlmelp - Le Masque et la Plume\n^Ab\n==================================\nStarting Streamlit web interface...\n</code></pre>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#analyse-du-probleme","title":"Analyse du Probl\u00e8me","text":""},{"location":"claude/memory/251126-1910-portainer-logging-fix/#probleme-1-caracteres-bizarres","title":"Probl\u00e8me 1 : Caract\u00e8res bizarres","text":"<ul> <li>Le caract\u00e8re <code>^A</code> (ASCII 0x01) est un caract\u00e8re de contr\u00f4le terminal</li> <li>Caus\u00e9 par la banni\u00e8re multi-lignes r\u00e9p\u00e9titive dans <code>entrypoint.sh</code></li> <li>Les lignes avec beaucoup de <code>=</code> cr\u00e9ent du bruit visuel</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#probleme-2-absence-de-logs-http","title":"Probl\u00e8me 2 : Absence de logs HTTP","text":"<ul> <li>Streamlit ne supporte PAS nativement le logging des requ\u00eates HTTP</li> <li>Contrairement \u00e0 nginx/apache qui loggent chaque requ\u00eate (GET, POST, status, IP, etc.)</li> <li>Les options de logging Streamlit concernent les logs internes de l'application, pas les requ\u00eates HTTP</li> <li>Pour avoir de vrais logs HTTP, il faudrait un reverse proxy nginx (hors scope de cette issue)</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#solution-implementee","title":"Solution Impl\u00e9ment\u00e9e","text":""},{"location":"claude/memory/251126-1910-portainer-logging-fix/#1-simplification-du-banner-de-demarrage","title":"1. Simplification du Banner de D\u00e9marrage","text":"<p>Fichier modifi\u00e9: <code>docker/build/entrypoint.sh</code></p> <pre><code># AVANT\necho \"==================================\"\necho \"lmelp - Le Masque et la Plume\"\necho \"Mode: $MODE\"\necho \"==================================\"\n\n# APR\u00c8S\necho \"[lmelp] Starting in $MODE mode...\"\n</code></pre> <p>B\u00e9n\u00e9fices: - Banner court et informatif - \u00c9limine les caract\u00e8res de contr\u00f4le - Format coh\u00e9rent avec les standards de logging</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#2-configuration-streamlit-pour-logs-propres","title":"2. Configuration Streamlit pour Logs Propres","text":"<p>Nouveau fichier: <code>.streamlit/config.toml</code></p> <pre><code>[server]\nport = 8501\naddress = \"0.0.0.0\"\nheadless = true\nenableCORS = true\nenableXsrfProtection = true\n\n[browser]\ngatherUsageStats = false\n\n[logger]\nlevel = \"info\"\nmessageFormat = \"%(asctime)s - %(levelname)s - %(message)s\"\n\n[theme]\nbase = \"light\"\nprimaryColor = \"#FF4B4B\"\n</code></pre> <p>Points cl\u00e9s: - <code>enableCORS = true</code> requis si <code>enableXsrfProtection = true</code> - Suppression de <code>enableClientLogs</code> (option invalide dans versions r\u00e9centes) - Format de log avec timestamp pour meilleure tra\u00e7abilit\u00e9</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#3-ajout-de-loption-logger-dans-entrypoint","title":"3. Ajout de l'Option Logger dans Entrypoint","text":"<pre><code>exec streamlit run ui/lmelp.py \\\n    --server.port=8501 \\\n    --server.address=0.0.0.0 \\\n    --server.headless=true \\\n    --logger.level=info  # \u2190 Ajout\u00e9\n</code></pre>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#4-copie-de-la-configuration-dans-docker","title":"4. Copie de la Configuration dans Docker","text":"<p>Fichier modifi\u00e9: <code>docker/build/Dockerfile</code></p> <pre><code># Copy application code\nCOPY nbs/ /app/nbs/\nCOPY ui/ /app/ui/\nCOPY scripts/ /app/scripts/\nCOPY .streamlit/ /app/.streamlit/  # \u2190 Ajout\u00e9\n</code></pre>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#tests-ajoutes","title":"Tests Ajout\u00e9s","text":"<p>Nouveau fichier: <code>tests/integration/test_streamlit_config.py</code></p> <p>8 tests ajout\u00e9s: 1. <code>test_streamlit_config_file_exists</code> - V\u00e9rifie pr\u00e9sence du fichier 2. <code>test_streamlit_config_contains_logging_settings</code> - Valide les sections logger, server, browser 3. <code>test_streamlit_config_message_format</code> - V\u00e9rifie format avec timestamp/level/message 4. <code>test_entrypoint_exists</code> - V\u00e9rifie pr\u00e9sence du script 5. <code>test_entrypoint_simplified_banner</code> - Valide le nouveau banner 6. <code>test_entrypoint_logger_level_option</code> - V\u00e9rifie l'option --logger.level=info 7. <code>test_dockerfile_exists</code> - V\u00e9rifie pr\u00e9sence du Dockerfile 8. <code>test_dockerfile_copies_streamlit_config</code> - Valide la copie de .streamlit/</p> <p>R\u00e9sultats: - \u2705 8/8 tests passent - \u2705 Suite compl\u00e8te : 296/296 tests passent - \u2705 Black formatting OK - \u2705 Mypy typecheck OK</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#resultats-apres-correction","title":"R\u00e9sultats Apr\u00e8s Correction","text":""},{"location":"claude/memory/251126-1910-portainer-logging-fix/#logs-de-demarrage-propres","title":"Logs de d\u00e9marrage propres","text":"<pre><code>[lmelp] Starting in web mode...\n\n  You can now view your Streamlit app in your browser.\n\n  URL: http://0.0.0.0:8501\n</code></pre>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#ce-qui-sera-visible-dans-portainer","title":"Ce qui sera visible dans Portainer","text":"<p>\u2705 Logs de d\u00e9marrage propres (sans <code>^A</code> + <code>b</code>) \u2705 Logs d'erreurs applicatives Streamlit \u2705 Logs de sant\u00e9 du healthcheck Docker \u2705 Logs applicatifs (print, logging Python)</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#ce-qui-ne-sera-pas-visible","title":"Ce qui NE sera PAS visible","text":"<p>\u274c Logs de requ\u00eates HTTP individuelles (GET /, POST /api/..., status codes)</p> <p>Raison: Limitation native de Streamlit - n\u00e9cessiterait un reverse proxy nginx pour avoir ces logs</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#fichiers-modifies","title":"Fichiers Modifi\u00e9s","text":"<ol> <li><code>.streamlit/config.toml</code> (nouveau)</li> <li><code>docker/build/entrypoint.sh</code></li> <li><code>docker/build/Dockerfile</code></li> <li><code>tests/integration/test_streamlit_config.py</code> (nouveau)</li> </ol>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#apprentissages-cles","title":"Apprentissages Cl\u00e9s","text":""},{"location":"claude/memory/251126-1910-portainer-logging-fix/#limitation-streamlit","title":"Limitation Streamlit","text":"<ul> <li>Streamlit n'est pas un serveur web classique - il ne loggue pas les requ\u00eates HTTP</li> <li>Les options de logging Streamlit concernent uniquement les logs internes de l'application</li> <li>Pour du monitoring HTTP d\u00e9taill\u00e9, il faut une couche suppl\u00e9mentaire (nginx, middleware custom)</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#configuration-cors","title":"Configuration CORS","text":"<ul> <li><code>enableCORS</code> doit \u00eatre <code>true</code> si <code>enableXsrfProtection</code> est <code>true</code></li> <li>Streamlit force cette contrainte pour la s\u00e9curit\u00e9 (protection CSRF via cookies)</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#options-de-configuration-streamlit","title":"Options de Configuration Streamlit","text":"<ul> <li><code>logger.enableClientLogs</code> n'existe plus dans les versions r\u00e9centes</li> <li>Toujours v\u00e9rifier la documentation de la version utilis\u00e9e</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#docker-entrypoint-best-practices","title":"Docker Entrypoint Best Practices","text":"<ul> <li>Banni\u00e8res courtes et informatives</li> <li>Format <code>[service] Action...</code> est standard</li> <li>\u00c9viter les caract\u00e8res de contr\u00f4le qui peuvent \u00eatre mal interpr\u00e9t\u00e9s par les viewers de logs</li> </ul>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#recommandations-futures","title":"Recommandations Futures","text":""},{"location":"claude/memory/251126-1910-portainer-logging-fix/#pour-de-vrais-logs-http","title":"Pour de vrais logs HTTP","text":"<p>Si besoin absolu de logs HTTP style nginx, cr\u00e9er une nouvelle issue pour : - Ajouter nginx comme reverse proxy devant Streamlit - Configurer nginx pour logger les requ\u00eates (format combined) - Modifier docker-compose pour inclure nginx</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#monitoring-alternatif","title":"Monitoring Alternatif","text":"<p>Alternatives \u00e0 consid\u00e9rer : - Utiliser le healthcheck Docker (<code>/_stcore/health</code>) pour monitoring uptime - Logger les actions utilisateur dans l'application Streamlit elle-m\u00eame - Utiliser un APM (Application Performance Monitoring) comme Datadog, New Relic</p>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#commandes-de-validation","title":"Commandes de Validation","text":"<pre><code># Tester localement\n./ui/lmelp_ui.sh\n\n# Tester l'entrypoint Docker\nbash docker/build/entrypoint.sh\n\n# Lancer les tests\nPYTHONPATH=/workspaces/lmelp/src uv run pytest tests/integration/test_streamlit_config.py -v\n\n# Build et test Docker\ndocker build -t lmelp:test -f docker/build/Dockerfile .\ndocker run -p 8501:8501 -e DB_HOST=172.17.0.1 lmelp:test\n</code></pre>"},{"location":"claude/memory/251126-1910-portainer-logging-fix/#conclusion","title":"Conclusion","text":"<p>\u2705 Probl\u00e8me 1 r\u00e9solu : Banner propre, pas de caract\u00e8res bizarres \u26a0\ufe0f Probl\u00e8me 2 partiellement r\u00e9solu : Logs Streamlit propres, mais pas de logs HTTP (limitation native)</p> <p>L'issue #83 est consid\u00e9r\u00e9e comme r\u00e9solue pour le scope initial (banner et logs visibles). Les logs HTTP d\u00e9taill\u00e9s n\u00e9cessiteraient une architecture diff\u00e9rente (reverse proxy) et devraient faire l'objet d'une issue s\u00e9par\u00e9e si requis.</p>"},{"location":"deployment/docker-local-usage/","title":"Utilisation Docker en local","text":"<p>Ce guide explique comment utiliser lmelp avec Docker sur votre machine locale (PC Linux/Mac/Windows).</p>"},{"location":"deployment/docker-local-usage/#prerequis","title":"\ud83d\udccb Pr\u00e9requis","text":"<ul> <li>Docker install\u00e9 et fonctionnel</li> <li>MongoDB install\u00e9 et accessible sur votre machine h\u00f4te</li> <li>Git configur\u00e9 pour acc\u00e9der au d\u00e9p\u00f4t</li> </ul>"},{"location":"deployment/docker-local-usage/#configuration-mongodb","title":"\ud83d\udd27 Configuration MongoDB","text":""},{"location":"deployment/docker-local-usage/#configuration-du-reseau","title":"Configuration du r\u00e9seau","text":"<p>Pour que le conteneur Docker puisse se connecter \u00e0 MongoDB sur votre machine h\u00f4te, MongoDB doit \u00eatre configur\u00e9 pour accepter les connexions depuis le r\u00e9seau Docker.</p> <p>1. Identifier l'adresse IP du bridge Docker :</p> <pre><code>ip addr show docker0 | grep inet\n# R\u00e9sultat typique : inet 172.17.0.1/16\n</code></pre> <p>2. Modifier la configuration MongoDB :</p> <p>\u00c9ditez <code>/etc/mongod.conf</code> :</p> <pre><code>net:\n  port: 27017\n  bindIp: 127.0.0.1,172.17.0.1  # Ajouter l'IP du bridge Docker\n</code></pre> <p>Ou pour accepter toutes les connexions (moins s\u00e9curis\u00e9) :</p> <pre><code>net:\n  port: 27017\n  bindIp: 0.0.0.0\n</code></pre> <p>3. Red\u00e9marrer MongoDB :</p> <pre><code>sudo systemctl restart mongod\n</code></pre> <p>4. V\u00e9rifier que MongoDB \u00e9coute sur la bonne interface :</p> <pre><code>sudo netstat -tulpn | grep 27017\n# Devrait montrer : 0.0.0.0:27017 ou 172.17.0.1:27017\n</code></pre>"},{"location":"deployment/docker-local-usage/#utilisation-du-script-de-test","title":"\ud83d\ude80 Utilisation du script de test","text":"<p>Un script est fourni pour faciliter le test local en mode interactif :</p> <p>Utilisation :</p> <pre><code>./docker/test-local.sh\n</code></pre> <p>Caract\u00e9ristiques : - \u2705 Pull automatique des derniers changements - \u2705 Build de l'image Docker - \u2705 Nettoyage des anciens conteneurs (sauf devcontainer) - \u2705 Lancement en mode interactif - \u2705 Logs affich\u00e9s en direct dans le terminal - \u26a0\ufe0f Terminal bloqu\u00e9 (utiliser Ctrl+C pour arr\u00eater)</p> <p>Utilisation recommand\u00e9e : - Pour d\u00e9boguer et voir les logs en temps r\u00e9el - Pour des tests rapides - Pour d\u00e9veloppement actif</p>"},{"location":"deployment/docker-local-usage/#gestion-du-conteneur","title":"\ud83d\udcca Gestion du conteneur","text":""},{"location":"deployment/docker-local-usage/#voir-les-logs","title":"Voir les logs","text":"<pre><code># Logs en temps r\u00e9el\ndocker logs -f lmelp-local\n\n# Derni\u00e8res 50 lignes\ndocker logs --tail 50 lmelp-local\n\n# Logs depuis les 10 derni\u00e8res minutes\ndocker logs --since 10m lmelp-local\n</code></pre>"},{"location":"deployment/docker-local-usage/#arreter-le-conteneur","title":"Arr\u00eater le conteneur","text":"<pre><code># Arr\u00eat propre\ndocker stop lmelp-local\n\n# Arr\u00eat forc\u00e9 et suppression\ndocker rm -f lmelp-local\n</code></pre>"},{"location":"deployment/docker-local-usage/#redemarrer-le-conteneur","title":"Red\u00e9marrer le conteneur","text":"<pre><code>docker restart lmelp-local\n</code></pre>"},{"location":"deployment/docker-local-usage/#voir-le-statut","title":"Voir le statut","text":"<pre><code># Voir tous les conteneurs lmelp\ndocker ps -a | grep lmelp\n\n# Voir les conteneurs en cours d'ex\u00e9cution\ndocker ps | grep lmelp\n</code></pre>"},{"location":"deployment/docker-local-usage/#acceder-au-shell-du-conteneur","title":"Acc\u00e9der au shell du conteneur","text":"<pre><code>docker exec -it lmelp-local bash\n</code></pre>"},{"location":"deployment/docker-local-usage/#acces-a-linterface-web","title":"\ud83c\udf10 Acc\u00e8s \u00e0 l'interface web","text":"<p>Une fois le conteneur lanc\u00e9 :</p> <p>URL : http://localhost:8501</p> <p>L'application Streamlit est accessible sur le port 8501 de votre machine h\u00f4te.</p> <p>Note : Le devcontainer utilise aussi le port 8501 (avec <code>network=host</code>). Assurez-vous qu'une seule instance tourne \u00e0 la fois.</p>"},{"location":"deployment/docker-local-usage/#configuration","title":"\u2699\ufe0f Configuration","text":"<p>Les scripts configurent automatiquement :</p> Variable Valeur Description <code>DB_HOST</code> <code>172.17.0.1</code> Adresse du bridge Docker pour acc\u00e9der au MongoDB du h\u00f4te <code>DB_NAME</code> <code>masque_et_la_plume</code> Nom de la base de donn\u00e9es <code>DB_LOGS</code> <code>true</code> Active les logs MongoDB Port <code>8501:8501</code> Port de l'interface web"},{"location":"deployment/docker-local-usage/#depannage","title":"\ud83d\udc1b D\u00e9pannage","text":""},{"location":"deployment/docker-local-usage/#erreur-connection-refused-mongodb","title":"Erreur : \"Connection refused\" (MongoDB)","text":"<p>Sympt\u00f4me :</p> <pre><code>ServerSelectionTimeoutError: 172.17.0.1:27017: [Errno 111] Connection refused\n</code></pre> <p>Solutions :</p> <ol> <li> <p>V\u00e9rifier que MongoDB tourne : <code>bash    sudo systemctl status mongod</code></p> </li> <li> <p>V\u00e9rifier la configuration bindIp : <code>bash    grep bindIp /etc/mongod.conf    # Devrait montrer : bindIp: 0.0.0.0 ou bindIp: 127.0.0.1,172.17.0.1</code></p> </li> <li> <p>V\u00e9rifier que MongoDB \u00e9coute sur la bonne interface : <code>bash    sudo netstat -tulpn | grep 27017</code></p> </li> <li> <p>Red\u00e9marrer MongoDB apr\u00e8s changement de config : <code>bash    sudo systemctl restart mongod</code></p> </li> </ol>"},{"location":"deployment/docker-local-usage/#erreur-port-is-already-allocated","title":"Erreur : \"port is already allocated\"","text":"<p>Sympt\u00f4me :</p> <pre><code>Error: Bind for 0.0.0.0:8501 failed: port is already allocated\n</code></pre> <p>Cause : Le devcontainer ou une autre instance Streamlit utilise d\u00e9j\u00e0 le port 8501.</p> <p>Solutions :</p> <ol> <li>Arr\u00eater le devcontainer si il tourne :</li> <li>Dans VS Code: Fermer la fen\u00eatre devcontainer</li> <li> <p>Ou arr\u00eater le conteneur: <code>docker stop vsc-lmelp-...</code></p> </li> <li> <p>V\u00e9rifier les processus utilisant le port : <code>bash    sudo lsof -i :8501</code></p> </li> <li> <p>Arr\u00eater l'ancien conteneur de test si pr\u00e9sent : <code>bash    docker stop lmelp-local</code></p> </li> </ol>"},{"location":"deployment/docker-local-usage/#erreur-localeerror-unsupported-locale-setting","title":"Erreur : \"locale.Error: unsupported locale setting\"","text":"<p>Sympt\u00f4me :</p> <pre><code>locale.Error: unsupported locale setting (fr_FR.UTF-8)\n</code></pre> <p>Solution : Ce probl\u00e8me est d\u00e9j\u00e0 corrig\u00e9 dans le Dockerfile. Si vous le rencontrez : 1. Assurez-vous d'utiliser la derni\u00e8re version de l'image 2. Rebuild l'image : <code>docker build -f docker/Dockerfile -t lmelp:local .</code></p>"},{"location":"deployment/docker-local-usage/#linterface-web-ne-charge-pas","title":"L'interface web ne charge pas","text":"<p>Solutions :</p> <ol> <li> <p>V\u00e9rifier que le conteneur tourne : <code>bash    docker ps | grep lmelp-local</code></p> </li> <li> <p>Voir les logs pour erreurs : <code>bash    docker logs lmelp-local</code></p> </li> <li> <p>V\u00e9rifier le port mapping : <code>bash    docker port lmelp-local    # Devrait montrer : 8501/tcp -&gt; 0.0.0.0:8501</code></p> </li> </ol>"},{"location":"deployment/docker-local-usage/#workflow-de-developpement","title":"\ud83d\udd04 Workflow de d\u00e9veloppement","text":""},{"location":"deployment/docker-local-usage/#tests-rapides-avec-rebuild","title":"Tests rapides avec rebuild","text":"<pre><code># Lancer le script de test (mode interactif)\n./docker/test-local.sh\n\n# Ctrl+C pour arr\u00eater\n# Modifier le code\n# Relancer\n./docker/test-local.sh\n</code></pre>"},{"location":"deployment/docker-local-usage/#notes-importantes","title":"\ud83d\udcdd Notes importantes","text":"<ol> <li> <p>Pull automatique : Les scripts font automatiquement un <code>git pull</code> avant le build. Assurez-vous d'avoir commit\u00e9 vos changements locaux.</p> </li> <li> <p>Nettoyage : Les scripts arr\u00eatent et suppriment automatiquement les anciens conteneurs <code>lmelp</code> avant de lancer le nouveau.</p> </li> <li> <p>Image locale : Les scripts cr\u00e9ent une image nomm\u00e9e <code>lmelp:local</code> qui reste sur votre machine. Pour la supprimer :    <code>bash    docker rmi lmelp:local</code></p> </li> <li> <p>Donn\u00e9es persistantes : Les conteneurs n'ont pas de volumes mont\u00e9s pour les donn\u00e9es. Les donn\u00e9es sont stock\u00e9es dans MongoDB sur le h\u00f4te.</p> </li> </ol>"},{"location":"deployment/docker-local-usage/#voir-aussi","title":"\ud83d\udd17 Voir aussi","text":"<ul> <li>Configuration Docker compl\u00e8te - Plan de dockerisation complet</li> <li>Configuration GitHub Actions - CI/CD et d\u00e9ploiement automatis\u00e9</li> <li>README Docker - Documentation technique Docker</li> </ul>"},{"location":"deployment/github-actions-setup/","title":"GitHub Actions Setup for Docker CI/CD","text":"<p>This guide explains how to configure GitHub Actions to automatically build and publish Docker images for lmelp.</p>"},{"location":"deployment/github-actions-setup/#overview","title":"Overview","text":"<p>The CI/CD pipeline automatically: 1. Builds Docker image on push to <code>main</code> or version tags (<code>v*.*.*</code>) 2. Publishes image to GitHub Container Registry (ghcr.io) 3. Triggers Portainer webhook for auto-deployment on NAS (optional)</p>"},{"location":"deployment/github-actions-setup/#workflow-configuration","title":"Workflow Configuration","text":"<p>The workflow is defined in <code>.github/workflows/docker-publish.yml</code>.</p>"},{"location":"deployment/github-actions-setup/#triggers","title":"Triggers","text":"<ul> <li>Push to <code>main</code>: Builds and tags as <code>latest</code></li> <li>Version tags (<code>v1.0.0</code>, <code>v1.2.3</code>, etc.): Builds and tags with version</li> <li>Manual: Can be triggered manually via GitHub Actions UI</li> </ul>"},{"location":"deployment/github-actions-setup/#tags-strategy","title":"Tags Strategy","text":"Git Action Docker Tags Generated Push to <code>main</code> <code>latest</code>, <code>main</code> Tag <code>v1.2.3</code> <code>latest</code>, <code>v1.2.3</code>, <code>v1.2</code>, <code>v1</code>, <code>1.2.3</code>, <code>1.2</code>, <code>1</code> PR #42 <code>pr-42</code>"},{"location":"deployment/github-actions-setup/#github-secrets-configuration","title":"GitHub Secrets Configuration","text":""},{"location":"deployment/github-actions-setup/#required-secrets","title":"Required Secrets","text":""},{"location":"deployment/github-actions-setup/#github_token-automatic","title":"<code>GITHUB_TOKEN</code> (automatic)","text":"<ul> <li>Description: Automatically provided by GitHub Actions</li> <li>Purpose: Authenticate to GitHub Container Registry</li> <li>Configuration: None needed - automatically available</li> </ul>"},{"location":"deployment/github-actions-setup/#optional-secrets","title":"Optional Secrets","text":""},{"location":"deployment/github-actions-setup/#portainer_webhook_url","title":"<code>PORTAINER_WEBHOOK_URL</code>","text":"<ul> <li>Description: Webhook URL from Portainer for auto-deployment</li> <li>Purpose: Trigger automatic deployment on NAS when new image is pushed</li> <li>Required: Only if you want auto-deployment on NAS</li> </ul> <p>How to configure:</p> <ol> <li>Get webhook URL from Portainer:</li> <li>Open Portainer web UI</li> <li>Navigate to your lmelp stack</li> <li>Go to \"Webhooks\" section</li> <li>Create a new webhook</li> <li> <p>Copy the webhook URL (format: <code>https://portainer.your-nas.com/api/webhooks/xxx</code>)</p> </li> <li> <p>Add to GitHub:</p> </li> <li>Go to your repository: https://github.com/castorfou/lmelp</li> <li>Click <code>Settings</code> \u2192 <code>Secrets and variables</code> \u2192 <code>Actions</code></li> <li>Click <code>New repository secret</code></li> <li>Name: <code>PORTAINER_WEBHOOK_URL</code></li> <li>Value: Paste the webhook URL from Portainer</li> <li>Click <code>Add secret</code></li> </ol>"},{"location":"deployment/github-actions-setup/#permissions","title":"Permissions","text":"<p>The workflow requires the following permissions (already configured):</p> <pre><code>permissions:\n  contents: read    # Read repository code\n  packages: write   # Publish to GitHub Container Registry\n</code></pre>"},{"location":"deployment/github-actions-setup/#first-time-setup","title":"First Time Setup","text":""},{"location":"deployment/github-actions-setup/#1-enable-github-container-registry","title":"1. Enable GitHub Container Registry","text":"<p>GitHub Container Registry (ghcr.io) is enabled by default for public repositories. For private repositories:</p> <ol> <li>Go to repository <code>Settings</code> \u2192 <code>Packages</code></li> <li>Ensure packages are enabled</li> </ol>"},{"location":"deployment/github-actions-setup/#2-test-the-workflow","title":"2. Test the Workflow","text":"<p>Option A: Manual trigger 1. Go to <code>Actions</code> tab in GitHub 2. Select <code>Build and Publish Docker Image</code> 3. Click <code>Run workflow</code> 4. Select branch <code>main</code> 5. Click <code>Run workflow</code></p> <p>Option B: Push to main</p> <pre><code># Make a small change\necho \"# Docker deployment\" &gt;&gt; docs/deployment/README.md\ngit add docs/deployment/README.md\ngit commit -m \"Trigger Docker build\"\ngit push origin main\n</code></pre> <p>Option C: Create a version tag</p> <pre><code>git tag v0.1.0\ngit push origin v0.1.0\n</code></pre>"},{"location":"deployment/github-actions-setup/#3-monitor-build","title":"3. Monitor Build","text":"<ol> <li>Go to <code>Actions</code> tab in GitHub</li> <li>Click on the running workflow</li> <li>Watch the build progress</li> <li>Estimated time: 10-15 minutes (first build with cache)</li> </ol>"},{"location":"deployment/github-actions-setup/#4-verify-published-image","title":"4. Verify Published Image","text":"<p>After successful build:</p> <ol> <li>Go to repository main page</li> <li>Click <code>Packages</code> (right sidebar)</li> <li>You should see <code>lmelp</code> package listed</li> <li>Click on it to see all tags</li> </ol> <p>Or via command line:</p> <pre><code># List available tags\ndocker pull ghcr.io/castorfou/lmelp:latest\n\n# View image details\ndocker inspect ghcr.io/castorfou/lmelp:latest\n</code></pre>"},{"location":"deployment/github-actions-setup/#using-the-published-image","title":"Using the Published Image","text":""},{"location":"deployment/github-actions-setup/#pull-latest-version","title":"Pull Latest Version","text":"<pre><code>docker pull ghcr.io/castorfou/lmelp:latest\n</code></pre>"},{"location":"deployment/github-actions-setup/#pull-specific-version","title":"Pull Specific Version","text":"<pre><code>docker pull ghcr.io/castorfou/lmelp:v1.0.0\n</code></pre>"},{"location":"deployment/github-actions-setup/#use-in-docker-compose","title":"Use in docker-compose","text":"<p>The <code>docker-compose.yml</code> already references the published image:</p> <pre><code>services:\n  app:\n    image: ghcr.io/castorfou/lmelp:latest\n</code></pre> <p>Update to latest:</p> <pre><code>cd docker/deployment/\ndocker compose pull &amp;&amp; docker compose up -d\n</code></pre>"},{"location":"deployment/github-actions-setup/#build-cache","title":"Build Cache","text":"<p>The workflow uses GitHub Actions cache to speed up builds:</p> <ul> <li>First build: ~10-15 minutes (no cache)</li> <li>Subsequent builds: ~5-8 minutes (with cache)</li> </ul> <p>Cache is automatically managed by GitHub Actions.</p>"},{"location":"deployment/github-actions-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/github-actions-setup/#build-fails-with-permission-denied","title":"Build fails with \"permission denied\"","text":"<p>Cause: <code>GITHUB_TOKEN</code> doesn't have write access to packages</p> <p>Solution: 1. Check repository settings 2. Ensure packages are enabled for the repository</p>"},{"location":"deployment/github-actions-setup/#portainer-webhook-not-triggered","title":"Portainer webhook not triggered","text":"<p>Cause: <code>PORTAINER_WEBHOOK_URL</code> secret not configured or incorrect</p> <p>Solution: 1. Verify webhook URL in Portainer 2. Check secret is correctly configured in GitHub 3. Check workflow logs for webhook call errors</p>"},{"location":"deployment/github-actions-setup/#build-takes-too-long","title":"Build takes too long","text":"<p>Cause: Large ML models (Whisper, Transformers) need to be downloaded</p> <p>Solution: This is normal for first build. Subsequent builds use cache.</p>"},{"location":"deployment/github-actions-setup/#out-of-disk-space-during-build","title":"Out of disk space during build","text":"<p>Cause: GitHub Actions runners have limited space</p> <p>Solution: - The Dockerfile uses multi-stage build to minimize size - Clean up unnecessary files in <code>.dockerignore</code> - If still failing, review Dockerfile for optimization</p>"},{"location":"deployment/github-actions-setup/#manual-build-and-push","title":"Manual Build and Push","text":"<p>For testing or emergency deployments:</p> <pre><code># Build locally\ndocker build -f docker/build/Dockerfile -t ghcr.io/castorfou/lmelp:manual .\n\n# Login to GitHub Container Registry\necho $GITHUB_TOKEN | docker login ghcr.io -u castorfou --password-stdin\n\n# Push\ndocker push ghcr.io/castorfou/lmelp:manual\n</code></pre>"},{"location":"deployment/github-actions-setup/#release-process","title":"Release Process","text":"<p>To create a new release:</p> <pre><code># Create and push tag\ngit tag -a v1.0.0 -m \"Release version 1.0.0\"\ngit push origin v1.0.0\n\n# GitHub Actions will automatically:\n# 1. Build image\n# 2. Tag as v1.0.0, v1.0, v1, latest\n# 3. Push to ghcr.io\n# 4. Trigger Portainer webhook (if configured)\n</code></pre>"},{"location":"deployment/github-actions-setup/#workflow-status-badge","title":"Workflow Status Badge","text":"<p>Add to README.md:</p> <pre><code>[![Docker Build](https://github.com/castorfou/lmelp/actions/workflows/docker-publish.yml/badge.svg)](https://github.com/castorfou/lmelp/actions/workflows/docker-publish.yml)\n</code></pre>"},{"location":"deployment/github-actions-setup/#next-steps","title":"Next Steps","text":"<p>After CI/CD is configured:</p> <ol> <li>Configure Portainer on NAS (to be created)</li> <li>Setup reverse proxy (to be created)</li> <li>Configure monitoring (to be created)</li> </ol>"},{"location":"deployment/github-actions-setup/#references","title":"References","text":"<ul> <li>GitHub Actions Documentation</li> <li>GitHub Container Registry</li> <li>Docker Build Action</li> <li>Docker Metadata Action</li> </ul>"},{"location":"deployment/issue-dockerisation/","title":"Dockerisation et d\u00e9ploiement multi-environnement","text":""},{"location":"deployment/issue-dockerisation/#objectif","title":"Objectif","text":"<p>Packager l'application lmelp (Le Masque et la Plume) sous forme de conteneur Docker et permettre son d\u00e9ploiement aussi bien sur NAS Synology DS 923+ qu'en local sur PC avec gestion automatis\u00e9e des mises \u00e0 jour.</p>"},{"location":"deployment/issue-dockerisation/#architecture-cible","title":"Architecture cible","text":""},{"location":"deployment/issue-dockerisation/#conteneurs","title":"Conteneurs","text":"<ul> <li>Application Streamlit : Interface web + scripts de traitement (port 8501)</li> <li>MongoDB :</li> <li>Sur NAS : Utilisation du conteneur existant <code>mongo</code> (pas de nouveau conteneur)</li> <li>Sur PC : Conteneur MongoDB local ou service MongoDB install\u00e9</li> </ul>"},{"location":"deployment/issue-dockerisation/#reseau","title":"R\u00e9seau","text":"<ul> <li>Connexion au r\u00e9seau bridge Docker existant (NAS) ou r\u00e9seau d\u00e9di\u00e9 (PC)</li> <li>Application se connecte \u00e0 MongoDB via <code>mongodb://mongo:27017/masque_et_la_plume</code> (NAS) ou <code>mongodb://localhost:27017/masque_et_la_plume</code> (PC)</li> <li>Reverse proxy via Application Portal Synology : <code>lmelp.ascot63.synology.me</code> (NAS uniquement)</li> </ul>"},{"location":"deployment/issue-dockerisation/#volumes-docker","title":"Volumes Docker","text":"<pre><code>lmelp-audios/     \u2192 /app/audios      # Fichiers audio t\u00e9l\u00e9charg\u00e9s (plusieurs Go)\nlmelp-db-backup/  \u2192 /app/db          # Sauvegardes MongoDB\nlmelp-logs/       \u2192 /app/logs        # Logs applicatifs (optionnel)\n</code></pre>"},{"location":"deployment/issue-dockerisation/#pipeline-cicd","title":"Pipeline CI/CD","text":"<pre><code>Git push/tag \u2192 GitHub Actions \u2192 Build image \u2192 ghcr.io \u2192\n  \u251c\u2500\u2500 Webhook Portainer \u2192 D\u00e9ploiement NAS\n  \u2514\u2500\u2500 Pull manuel \u2192 D\u00e9ploiement PC local\n</code></pre>"},{"location":"deployment/issue-dockerisation/#configuration","title":"Configuration","text":""},{"location":"deployment/issue-dockerisation/#application-streamlit","title":"Application Streamlit","text":"<p>Variables d'environnement requises :</p> <pre><code># Base de donn\u00e9es\nDB_HOST=mongo                              # ou localhost pour PC\nDB_NAME=masque_et_la_plume\nDB_LOGS=true\n\n# Flux RSS\nRSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml\n\n# APIs LLM (au moins une requise)\nAZURE_API_KEY=sk-...\nAZURE_ENDPOINT=https://....openai.azure.com/\nOPENAI_API_KEY=sk-...\nGEMINI_API_KEY=...\n\n# Google Services (optionnel)\nGOOGLE_PROJECT_ID=...\nGOOGLE_CUSTOM_SEARCH_API_KEY=...\nSEARCH_ENGINE_ID=...\n\n# Chemins\nAUDIO_BASE_PATH=/app/audios\n</code></pre>"},{"location":"deployment/issue-dockerisation/#tags-docker","title":"Tags Docker","text":"<ul> <li><code>latest</code> : Derni\u00e8re version stable (auto-d\u00e9ploy\u00e9e via webhook sur NAS)</li> <li><code>v1.0.0</code>, <code>v1.1.0</code>, etc. : Versions sp\u00e9cifiques</li> <li>Repository : <code>ghcr.io/castorfou/lmelp</code></li> </ul>"},{"location":"deployment/issue-dockerisation/#phase-1-preparation-du-dockerfile","title":"Phase 1 : Pr\u00e9paration du Dockerfile","text":""},{"location":"deployment/issue-dockerisation/#taches","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#creer-dockerdockerfile","title":"\u2705 Cr\u00e9er <code>docker/Dockerfile</code>","text":"<pre><code># Multi-stage build optimis\u00e9 pour taille et performance\nFROM python:3.11-slim as base\n\n# Stage 1: Build dependencies\nFROM base as builder\nWORKDIR /build\nRUN pip install uv\nCOPY .devcontainer/requirements.txt .\nRUN uv pip install --system -r requirements.txt\n\n# Stage 2: Runtime\nFROM base as runtime\nWORKDIR /app\n\n# Copier Python + deps depuis builder\nCOPY --from=builder /usr/local /usr/local\n\n# Copier code source\nCOPY nbs/ /app/nbs/\nCOPY ui/ /app/ui/\nCOPY scripts/ /app/scripts/\n\n# Cr\u00e9er r\u00e9pertoires pour volumes\nRUN mkdir -p /app/audios /app/db /app/logs\n\n# Exposer port Streamlit\nEXPOSE 8501\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\\n  CMD curl -f http://localhost:8501/_stcore/health || exit 1\n\n# Point d'entr\u00e9e\nCMD [\"uv\", \"run\", \"streamlit\", \"run\", \"ui/lmelp.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n</code></pre> <p>Caract\u00e9ristiques : - Multi-stage build pour optimiser la taille - Utilise <code>uv</code> pour gestion rapide des d\u00e9pendances - Image de base Python 3.11 slim - Healthcheck int\u00e9gr\u00e9 pour monitoring - Port 8501 expos\u00e9 - Support des volumes pour donn\u00e9es persistantes</p>"},{"location":"deployment/issue-dockerisation/#creer-dockerdocker-composeyml-pour-pc-local","title":"\u2705 Cr\u00e9er <code>docker/docker-compose.yml</code> (pour PC local)","text":"<pre><code>version: '3.8'\n\nservices:\n  mongodb:\n    image: mongo:7\n    container_name: lmelp-mongodb\n    restart: unless-stopped\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - lmelp-mongodb-data:/data/db\n    environment:\n      - MONGO_INITDB_DATABASE=masque_et_la_plume\n    networks:\n      - lmelp-network\n\n  app:\n    image: ghcr.io/castorfou/lmelp:latest\n    container_name: lmelp-app\n    restart: unless-stopped\n    depends_on:\n      - mongodb\n    ports:\n      - \"8501:8501\"\n    volumes:\n      - lmelp-audios:/app/audios\n      - lmelp-db-backup:/app/db\n      - lmelp-logs:/app/logs\n    environment:\n      # Base de donn\u00e9es\n      - DB_HOST=mongodb\n      - DB_NAME=masque_et_la_plume\n      - DB_LOGS=true\n      # Flux RSS\n      - RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml\n      # APIs (\u00e0 configurer via .env)\n      - AZURE_API_KEY=${AZURE_API_KEY}\n      - AZURE_ENDPOINT=${AZURE_ENDPOINT}\n      - GEMINI_API_KEY=${GEMINI_API_KEY}\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      # Chemins\n      - AUDIO_BASE_PATH=/app/audios\n    networks:\n      - lmelp-network\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/_stcore/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\nvolumes:\n  lmelp-mongodb-data:\n  lmelp-audios:\n  lmelp-db-backup:\n  lmelp-logs:\n\nnetworks:\n  lmelp-network:\n    driver: bridge\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-dockerdocker-composenasyml-pour-nas-synology","title":"\u2705 Cr\u00e9er <code>docker/docker-compose.nas.yml</code> (pour NAS Synology)","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    image: ghcr.io/castorfou/lmelp:latest\n    container_name: lmelp-app\n    restart: unless-stopped\n    ports:\n      - \"8501:8501\"\n    volumes:\n      - lmelp-audios:/app/audios\n      - lmelp-db-backup:/app/db\n      - lmelp-logs:/app/logs\n    environment:\n      # Base de donn\u00e9es (utilise MongoDB existant)\n      - DB_HOST=mongo\n      - DB_NAME=masque_et_la_plume\n      - DB_LOGS=true\n      # Flux RSS\n      - RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml\n      # APIs (\u00e0 configurer dans Portainer)\n      - AZURE_API_KEY=${AZURE_API_KEY}\n      - AZURE_ENDPOINT=${AZURE_ENDPOINT}\n      - GEMINI_API_KEY=${GEMINI_API_KEY}\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      # Chemins\n      - AUDIO_BASE_PATH=/app/audios\n    networks:\n      - bridge  # R\u00e9seau existant avec conteneur mongo\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/_stcore/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\nvolumes:\n  lmelp-audios:\n  lmelp-db-backup:\n  lmelp-logs:\n\nnetworks:\n  bridge:\n    external: true  # Utilise r\u00e9seau existant\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-dockerenvtemplate","title":"\u2705 Cr\u00e9er <code>docker/.env.template</code>","text":"<pre><code># Copier ce fichier vers .env et remplir les valeurs\n\n# APIs LLM (au moins une requise)\nAZURE_API_KEY=\nAZURE_ENDPOINT=\nOPENAI_API_KEY=\nGEMINI_API_KEY=\n\n# Google Services (optionnel)\nGOOGLE_PROJECT_ID=\nGOOGLE_CUSTOM_SEARCH_API_KEY=\nSEARCH_ENGINE_ID=\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-dockerignore","title":"\u2705 Cr\u00e9er <code>.dockerignore</code>","text":"<pre><code># Git\n.git/\n.github/\n.gitignore\n\n# Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\n.venv/\nvenv/\nENV/\nenv/\n\n# Tests\ntests/\nhtmlcov/\n.coverage\n.pytest_cache/\n\n# Documentation\ndocs/\nsite/\n*.md\n!CLAUDE.md\n\n# Development\n.devcontainer/\n.vscode/\n*.ipynb_checkpoints/\n\n# Data (ne pas inclure dans l'image)\naudios/\ndb/\n*.db\n*.sqlite\n\n# Notebooks (d\u00e9j\u00e0 convertis en .py)\nnbs/*.ipynb\n\n# Build artifacts\ndist/\nbuild/\n*.egg-info/\n\n# Logs\n*.log\nlogs/\n\n# Environment\n.env\n.env.*\n!.env.template\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-dockerentrypointsh-optionnel-pour-scripts-batch","title":"\u2705 Cr\u00e9er <code>docker/entrypoint.sh</code> (optionnel, pour scripts batch)","text":"<pre><code>#!/bin/bash\nset -e\n\n# Mode d'ex\u00e9cution : web (Streamlit) ou batch (scripts)\nMODE=${LMELP_MODE:-web}\n\nif [ \"$MODE\" = \"web\" ]; then\n    echo \"Starting Streamlit web interface...\"\n    exec uv run streamlit run ui/lmelp.py --server.port=8501 --server.address=0.0.0.0\nelif [ \"$MODE\" = \"batch-update\" ]; then\n    echo \"Running RSS update script...\"\n    exec python scripts/update_emissions.py\nelif [ \"$MODE\" = \"batch-transcribe\" ]; then\n    echo \"Running transcription script...\"\n    exec python scripts/get_all_transcriptions.py\nelif [ \"$MODE\" = \"batch-authors\" ]; then\n    echo \"Running author extraction script...\"\n    exec python scripts/store_all_auteurs_from_all_episodes.py\nelse\n    echo \"Unknown mode: $MODE\"\n    echo \"Available modes: web, batch-update, batch-transcribe, batch-authors\"\n    exit 1\nfi\n</code></pre>"},{"location":"deployment/issue-dockerisation/#phase-2-cicd-github-actions","title":"Phase 2 : CI/CD GitHub Actions","text":""},{"location":"deployment/issue-dockerisation/#taches_1","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#creer-githubworkflowsdocker-publishyml","title":"\u2705 Cr\u00e9er <code>.github/workflows/docker-publish.yml</code>","text":"<pre><code>name: Build and Publish Docker Image\n\non:\n  push:\n    branches:\n      - main\n    tags:\n      - 'v*.*.*'\n  workflow_dispatch:\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to GitHub Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n            type=raw,value=latest,enable={{is_default_branch}}\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          file: docker/Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Trigger Portainer Webhook (NAS deployment)\n        if: github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')\n        run: |\n          curl -X POST ${{ secrets.PORTAINER_WEBHOOK_URL }}\n        continue-on-error: true\n</code></pre>"},{"location":"deployment/issue-dockerisation/#configurer-github-secrets","title":"\u2705 Configurer GitHub secrets","text":"<p>Aller dans <code>Settings &gt; Secrets and variables &gt; Actions</code> et ajouter :</p> <ul> <li><code>PORTAINER_WEBHOOK_URL</code> : URL du webhook Portainer pour d\u00e9ploiement automatique sur NAS</li> </ul> <p>Note : <code>GITHUB_TOKEN</code> est automatiquement fourni par GitHub Actions.</p>"},{"location":"deployment/issue-dockerisation/#tester-build-local","title":"\u2705 Tester build local","text":"<pre><code># Build de l'image\ndocker build -f docker/Dockerfile -t lmelp:test .\n\n# Test de l'image\ndocker run --rm -p 8501:8501 \\\n  -e DB_HOST=localhost \\\n  -e GEMINI_API_KEY=your_key \\\n  lmelp:test\n\n# Acc\u00e9der \u00e0 http://localhost:8501\n</code></pre>"},{"location":"deployment/issue-dockerisation/#phase-3-configuration-nas-synology-portainer","title":"Phase 3 : Configuration NAS Synology (Portainer)","text":""},{"location":"deployment/issue-dockerisation/#taches_2","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#verifiercreer-reseau-docker-partage","title":"\u2705 V\u00e9rifier/cr\u00e9er r\u00e9seau Docker partag\u00e9","text":"<pre><code># SSH sur le NAS\nssh admin@nas-synology\n\n# V\u00e9rifier que le conteneur mongo est sur le r\u00e9seau bridge\ndocker network inspect bridge\n\n# Si n\u00e9cessaire, connecter mongo au r\u00e9seau\ndocker network connect bridge mongo\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-stack-portainer","title":"\u2705 Cr\u00e9er stack Portainer","text":"<ol> <li>Ouvrir Portainer web UI</li> <li>Aller dans <code>Stacks &gt; Add stack</code></li> <li>Name: <code>lmelp</code></li> <li>Build method: Repository (ou Web editor avec docker-compose.nas.yml)</li> <li>Repository URL: <code>https://github.com/castorfou/lmelp</code></li> <li>Repository reference: <code>main</code></li> <li>Compose path: <code>docker/docker-compose.nas.yml</code></li> </ol>"},{"location":"deployment/issue-dockerisation/#configurer-variables-denvironnement-dans-portainer","title":"\u2705 Configurer variables d'environnement dans Portainer","text":"<p>Dans l'onglet Environment variables de la stack :</p> <pre><code>AZURE_API_KEY=sk-...\nAZURE_ENDPOINT=https://....openai.azure.com/\nGEMINI_API_KEY=...\nOPENAI_API_KEY=...\nGOOGLE_PROJECT_ID=...\nGOOGLE_CUSTOM_SEARCH_API_KEY=...\nSEARCH_ENGINE_ID=...\n</code></pre>"},{"location":"deployment/issue-dockerisation/#configurer-webhook-portainer","title":"\u2705 Configurer webhook Portainer","text":"<ol> <li>Dans la stack <code>lmelp</code>, aller dans Webhooks</li> <li>Cliquer sur Add webhook</li> <li>Copier l'URL g\u00e9n\u00e9r\u00e9e (format : <code>https://portainer.nas/api/webhooks/xxx</code>)</li> <li>Ajouter cette URL dans GitHub Secrets comme <code>PORTAINER_WEBHOOK_URL</code></li> </ol>"},{"location":"deployment/issue-dockerisation/#configurer-limites-de-ressources","title":"\u2705 Configurer limites de ressources","text":"<p>Dans Portainer, \u00e9diter le service <code>lmelp-app</code> : - Memory limit: 4 GB (Whisper + Transformers = lourd) - CPU limit: 2 cores - Restart policy: Unless stopped</p>"},{"location":"deployment/issue-dockerisation/#phase-4-configuration-pc-local","title":"Phase 4 : Configuration PC local","text":""},{"location":"deployment/issue-dockerisation/#taches_3","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#creer-fichier-env-local","title":"\u2705 Cr\u00e9er fichier <code>.env</code> local","text":"<pre><code>cd lmelp/docker/\ncp .env.template .env\n# \u00c9diter .env avec vos cl\u00e9s API\n</code></pre>"},{"location":"deployment/issue-dockerisation/#lancer-avec-docker-compose","title":"\u2705 Lancer avec Docker Compose","text":"<pre><code># Premi\u00e8re fois : pull de l'image\ndocker compose -f docker/docker-compose.yml pull\n\n# Lancer les services\ndocker compose -f docker/docker-compose.yml up -d\n\n# Voir les logs\ndocker compose -f docker/docker-compose.yml logs -f\n\n# Acc\u00e9der \u00e0 l'application\nopen http://localhost:8501\n</code></pre>"},{"location":"deployment/issue-dockerisation/#scripts-de-gestion-creation-de-helpers","title":"\u2705 Scripts de gestion (cr\u00e9ation de helpers)","text":"<p>Cr\u00e9er <code>docker/scripts/start.sh</code> :</p> <pre><code>#!/bin/bash\ndocker compose -f docker/docker-compose.yml up -d\n</code></pre> <p>Cr\u00e9er <code>docker/scripts/stop.sh</code> :</p> <pre><code>#!/bin/bash\ndocker compose -f docker/docker-compose.yml down\n</code></pre> <p>Cr\u00e9er <code>docker/scripts/update.sh</code> :</p> <pre><code>#!/bin/bash\ndocker compose -f docker/docker-compose.yml pull\ndocker compose -f docker/docker-compose.yml up -d\n</code></pre> <p>Cr\u00e9er <code>docker/scripts/logs.sh</code> :</p> <pre><code>#!/bin/bash\ndocker compose -f docker/docker-compose.yml logs -f\n</code></pre> <p>Cr\u00e9er <code>docker/scripts/backup-db.sh</code> :</p> <pre><code>#!/bin/bash\n# Backup MongoDB depuis le conteneur\ndocker exec lmelp-mongodb mongodump \\\n  --db masque_et_la_plume \\\n  --out /data/db/backup/$(date +%Y%m%d_%H%M%S)\n</code></pre>"},{"location":"deployment/issue-dockerisation/#phase-5-reverse-proxy-synology-nas-uniquement","title":"Phase 5 : Reverse Proxy Synology (NAS uniquement)","text":""},{"location":"deployment/issue-dockerisation/#taches_4","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#configurer-application-portal","title":"\u2705 Configurer Application Portal","text":"<ol> <li>Ouvrir Control Panel &gt; Login Portal &gt; Advanced &gt; Reverse Proxy</li> <li>Cliquer Create</li> <li>Configuration :</li> <li>Reverse Proxy Name: lmelp</li> <li>Source:<ul> <li>Protocol: HTTPS</li> <li>Hostname: lmelp.ascot63.synology.me</li> <li>Port: 443</li> <li>Enable HSTS: \u2713</li> </ul> </li> <li>Destination:<ul> <li>Protocol: HTTP</li> <li>Hostname: localhost</li> <li>Port: 8501</li> </ul> </li> <li>Custom Headers : <code>WebSocket: true</code></li> </ol>"},{"location":"deployment/issue-dockerisation/#configurer-certificat-ssl","title":"\u2705 Configurer certificat SSL","text":"<ol> <li>Aller dans Control Panel &gt; Security &gt; Certificate</li> <li>Utiliser un certificat existant ou cr\u00e9er un nouveau Let's Encrypt</li> <li>Assigner le certificat \u00e0 lmelp.ascot63.synology.me</li> </ol>"},{"location":"deployment/issue-dockerisation/#tester-acces-externe","title":"\u2705 Tester acc\u00e8s externe","text":"<pre><code># Test depuis Internet\ncurl -I https://lmelp.ascot63.synology.me\n\n# V\u00e9rifier dans navigateur\nopen https://lmelp.ascot63.synology.me\n</code></pre>"},{"location":"deployment/issue-dockerisation/#phase-6-scripts-batch-en-conteneur","title":"Phase 6 : Scripts batch en conteneur","text":""},{"location":"deployment/issue-dockerisation/#taches_5","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#creer-service-docker-pour-scripts-batch","title":"\u2705 Cr\u00e9er service Docker pour scripts batch","text":"<p>Optionnel : Ajouter dans <code>docker-compose.yml</code> un service pour les t\u00e2ches planifi\u00e9es :</p> <pre><code>  batch-worker:\n    image: ghcr.io/castorfou/lmelp:latest\n    container_name: lmelp-batch\n    restart: \"no\"  # Lancer manuellement ou via cron\n    depends_on:\n      - mongodb\n    volumes:\n      - lmelp-audios:/app/audios\n      - lmelp-db-backup:/app/db\n    environment:\n      # M\u00eame config que app\n      - DB_HOST=mongodb\n      - LMELP_MODE=batch-update  # ou batch-transcribe, batch-authors\n    networks:\n      - lmelp-network\n</code></pre>"},{"location":"deployment/issue-dockerisation/#creer-taches-planifiees-cron-sur-nas","title":"\u2705 Cr\u00e9er t\u00e2ches planifi\u00e9es (cron sur NAS)","text":"<pre><code># SSH sur NAS\nsudo crontab -e\n\n# Ajouter :\n# Mise \u00e0 jour RSS quotidienne \u00e0 6h\n0 6 * * * docker run --rm --network bridge \\\n  -e DB_HOST=mongo -e LMELP_MODE=batch-update \\\n  ghcr.io/castorfou/lmelp:latest\n\n# Transcription hebdomadaire dimanche 2h\n0 2 * * 0 docker run --rm --network bridge \\\n  -v lmelp-audios:/app/audios \\\n  -e DB_HOST=mongo -e LMELP_MODE=batch-transcribe \\\n  ghcr.io/castorfou/lmelp:latest\n</code></pre>"},{"location":"deployment/issue-dockerisation/#phase-7-documentation","title":"Phase 7 : Documentation","text":""},{"location":"deployment/issue-dockerisation/#taches_6","title":"T\u00e2ches","text":""},{"location":"deployment/issue-dockerisation/#creer-docsdeploymentdocker-setupmd","title":"\u2705 Cr\u00e9er <code>docs/deployment/docker-setup.md</code>","text":"<p>Documentation compl\u00e8te de l'architecture Docker : - Sch\u00e9ma d'architecture - Pr\u00e9requis syst\u00e8me - Ressources requises - R\u00e9seau Docker</p>"},{"location":"deployment/issue-dockerisation/#creer-docsdeploymentlocal-deploymentmd","title":"\u2705 Cr\u00e9er <code>docs/deployment/local-deployment.md</code>","text":"<p>Guide de d\u00e9ploiement sur PC local : - Installation Docker Desktop - Configuration .env - Commandes docker-compose - Acc\u00e8s \u00e0 l'application</p>"},{"location":"deployment/issue-dockerisation/#creer-docsdeploymentnas-deploymentmd","title":"\u2705 Cr\u00e9er <code>docs/deployment/nas-deployment.md</code>","text":"<p>Guide de d\u00e9ploiement sur NAS Synology : - Configuration Portainer - Variables d'environnement - Webhook configuration - Reverse proxy Application Portal - Troubleshooting sp\u00e9cifique NAS</p>"},{"location":"deployment/issue-dockerisation/#creer-docsdeploymentupdate-guidemd","title":"\u2705 Cr\u00e9er <code>docs/deployment/update-guide.md</code>","text":"<p>Guide de mise \u00e0 jour : - Mise \u00e0 jour automatique (webhook) - Mise \u00e0 jour manuelle locale - Mise \u00e0 jour vers version sp\u00e9cifique - Rollback vers version pr\u00e9c\u00e9dente - Gestion des migrations de donn\u00e9es</p>"},{"location":"deployment/issue-dockerisation/#creer-docsdeploymenttroubleshootingmd","title":"\u2705 Cr\u00e9er <code>docs/deployment/troubleshooting.md</code>","text":"<p>Guide de d\u00e9pannage : - Probl\u00e8mes courants (connexion MongoDB, APIs, transcription) - Consultation des logs - V\u00e9rification sant\u00e9 des conteneurs - Tests de connectivit\u00e9 - Nettoyage et maintenance</p>"},{"location":"deployment/issue-dockerisation/#mettre-a-jour-readmemd","title":"\u2705 Mettre \u00e0 jour <code>README.md</code>","text":"<p>Ajouter section compl\u00e8te sur le d\u00e9ploiement Docker :</p> <pre><code>## D\u00e9ploiement Docker\n\n### \ud83d\udc33 D\u00e9ploiement local (PC)\n\nvoir [Guide de d\u00e9ploiement local](docs/deployment/local-deployment.md)\n\n```bash\ncd docker/\ncp .env.template .env\n# \u00c9diter .env avec vos cl\u00e9s API\ndocker compose up -d\n</code></pre> <p>Acc\u00e9der \u00e0 http://localhost:8501</p>"},{"location":"deployment/issue-dockerisation/#deploiement-nas-synology","title":"\ud83d\udda5\ufe0f D\u00e9ploiement NAS Synology","text":"<p>voir Guide de d\u00e9ploiement NAS</p> <p>D\u00e9ploiement automatique via Portainer + GitHub Actions webhook.</p>"},{"location":"deployment/issue-dockerisation/#images-docker","title":"\ud83d\udce6 Images Docker","text":"<p>Images disponibles sur GitHub Container Registry : - <code>ghcr.io/castorfou/lmelp:latest</code> - Derni\u00e8re version stable - <code>ghcr.io/castorfou/lmelp:v1.0.0</code> - Versions sp\u00e9cifiques</p>"},{"location":"deployment/issue-dockerisation/#mise-a-jour","title":"\ud83d\udd04 Mise \u00e0 jour","text":"<p>voir Guide de mise \u00e0 jour</p> <pre><code>\n#### \u2705 Cr\u00e9er `docs/deployment/batch-processing.md`\n\nDocumentation des scripts batch en conteneur :\n- Utilisation du mode batch\n- Scripts disponibles\n- Configuration cron\n- Logs et monitoring\n\n## Phase 8 : Tests et validation\n\n### T\u00e2ches\n\n#### \u2705 Test build local des images\n\n```bash\n# Build\ndocker build -f docker/Dockerfile -t lmelp:test .\n\n# V\u00e9rifier taille\ndocker images lmelp:test\n\n# V\u00e9rifier layers\ndocker history lmelp:test\n\n# Test d\u00e9marrage\ndocker run --rm -p 8501:8501 \\\n  -e DB_HOST=localhost \\\n  -e GEMINI_API_KEY=test \\\n  lmelp:test\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - Taille image &lt; 3 GB (avec transformers + torch) - D\u00e9marrage &lt; 30 secondes - Healthcheck OK apr\u00e8s d\u00e9marrage</p>"},{"location":"deployment/issue-dockerisation/#test-docker-compose-local-complet","title":"\u2705 Test docker-compose local complet","text":"<pre><code># D\u00e9marrer tous les services\ndocker compose -f docker/docker-compose.yml up -d\n\n# V\u00e9rifier statut\ndocker compose -f docker/docker-compose.yml ps\n\n# V\u00e9rifier logs\ndocker compose -f docker/docker-compose.yml logs app\n\n# V\u00e9rifier MongoDB\ndocker exec -it lmelp-mongodb mongosh --eval \"db.adminCommand('ping')\"\n\n# Test interface web\ncurl http://localhost:8501\n\n# Test API MongoDB depuis app\ndocker exec -it lmelp-app python -c \"\nfrom nbs.mongo import get_mongodb_client\nclient = get_mongodb_client()\nprint(client.server_info())\n\"\n\n# Arr\u00eater\ndocker compose -f docker/docker-compose.yml down\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - Tous les services d\u00e9marrent sans erreur - Application Streamlit accessible - Connexion MongoDB fonctionnelle - Volumes persistants cr\u00e9\u00e9s</p>"},{"location":"deployment/issue-dockerisation/#test-deploiement-nas-portainer","title":"\u2705 Test d\u00e9ploiement NAS Portainer","text":"<ol> <li>D\u00e9ployer stack via Portainer</li> <li>V\u00e9rifier logs dans Portainer UI</li> <li>V\u00e9rifier connexion au MongoDB existant :    <code>bash    docker exec -it lmelp-app python -c \"    from nbs.mongo import get_mongodb_client    client = get_mongodb_client()    print(client.list_database_names())    \"</code></li> <li>Tester interface web via reverse proxy : https://lmelp.ascot63.synology.me</li> </ol> <p>Crit\u00e8res de succ\u00e8s : - Stack d\u00e9ploy\u00e9e sans erreur - Connexion \u00e0 MongoDB externe OK - Interface accessible via domaine Synology - HTTPS fonctionnel avec certificat valide</p>"},{"location":"deployment/issue-dockerisation/#test-webhook-auto-deploy","title":"\u2705 Test webhook auto-deploy","text":"<pre><code># Push sur main\ngit push origin main\n\n# V\u00e9rifier GitHub Actions\n# https://github.com/castorfou/lmelp/actions\n\n# V\u00e9rifier logs Portainer pour auto-deploy\n# V\u00e9rifier que nouvelle version est d\u00e9ploy\u00e9e\ndocker exec -it lmelp-app python -c \"import sys; print(sys.version)\"\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - Build GitHub Actions r\u00e9ussie - Image publi\u00e9e sur ghcr.io - Webhook d\u00e9clench\u00e9 automatiquement - Stack Portainer mise \u00e0 jour - Application red\u00e9marr\u00e9e avec nouvelle version</p>"},{"location":"deployment/issue-dockerisation/#test-rollback","title":"\u2705 Test rollback","text":"<pre><code># M\u00e9thode 1 : Via Portainer\n# 1. \u00c9diter stack\n# 2. Changer image vers version pr\u00e9c\u00e9dente (ex: v1.0.0)\n# 3. Update stack\n\n# M\u00e9thode 2 : En local\ndocker compose -f docker/docker-compose.yml down\ndocker pull ghcr.io/castorfou/lmelp:v1.0.0\n# \u00c9diter docker-compose.yml : image: ghcr.io/castorfou/lmelp:v1.0.0\ndocker compose -f docker/docker-compose.yml up -d\n\n# V\u00e9rifier que l'application fonctionne avec ancienne version\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - Rollback vers version pr\u00e9c\u00e9dente sans perte de donn\u00e9es - Application fonctionnelle - Volumes pr\u00e9serv\u00e9s</p>"},{"location":"deployment/issue-dockerisation/#test-scripts-batch","title":"\u2705 Test scripts batch","text":"<pre><code># Test mise \u00e0 jour RSS\ndocker run --rm --network lmelp-network \\\n  -e DB_HOST=mongodb \\\n  -e LMELP_MODE=batch-update \\\n  -e RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml \\\n  ghcr.io/castorfou/lmelp:latest\n\n# V\u00e9rifier dans MongoDB que les \u00e9pisodes sont ajout\u00e9s\ndocker exec -it lmelp-mongodb mongosh masque_et_la_plume \\\n  --eval \"db.episodes.countDocuments()\"\n\n# Test transcription (avec \u00e9pisode de test)\ndocker run --rm --network lmelp-network \\\n  -v lmelp-audios:/app/audios \\\n  -e DB_HOST=mongodb \\\n  -e LMELP_MODE=batch-transcribe \\\n  -e GEMINI_API_KEY=$GEMINI_API_KEY \\\n  ghcr.io/castorfou/lmelp:latest\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - Scripts s'ex\u00e9cutent sans erreur - Donn\u00e9es ajout\u00e9es/modifi\u00e9es dans MongoDB - Fichiers audio persist\u00e9s dans volume - Logs clairs et informatifs</p>"},{"location":"deployment/issue-dockerisation/#test-performance-et-ressources","title":"\u2705 Test performance et ressources","text":"<pre><code># Surveiller ressources pendant utilisation\ndocker stats lmelp-app\n\n# Test charge : ouvrir plusieurs pages Streamlit\n# V\u00e9rifier utilisation CPU/RAM\n\n# Test transcription : surveiller pendant transcription d'un \u00e9pisode\ndocker stats lmelp-app\n</code></pre> <p>Crit\u00e8res de succ\u00e8s : - RAM &lt; 4 GB pendant utilisation normale - RAM &lt; 8 GB pendant transcription Whisper - CPU &lt; 100% en moyenne - Pas de memory leak apr\u00e8s plusieurs heures</p>"},{"location":"deployment/issue-dockerisation/#specifications-techniques","title":"Sp\u00e9cifications techniques","text":""},{"location":"deployment/issue-dockerisation/#ressources-nas","title":"Ressources NAS","text":"<ul> <li>RAM : 40 Go disponibles</li> <li>Stockage : 20 To disponibles</li> <li>Mod\u00e8le : Synology DS 923+</li> <li>R\u00e9seau : Accessible depuis Internet</li> </ul>"},{"location":"deployment/issue-dockerisation/#limites-de-ressources-conteneurs","title":"Limites de ressources conteneurs","text":"<pre><code>deploy:\n  resources:\n    limits:\n      cpus: '2'\n      memory: 4G\n    reservations:\n      cpus: '1'\n      memory: 2G\n</code></pre> <p>Justification : - Whisper + Transformers = mod\u00e8les lourds en RAM - Transcription = intensif CPU - 4 GB permet de charger les mod\u00e8les ML confortablement</p>"},{"location":"deployment/issue-dockerisation/#healthchecks","title":"Healthchecks","text":"<pre><code>healthcheck:\n  test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/_stcore/health\"]\n  interval: 30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s  # Temps de chargement des mod\u00e8les ML\n</code></pre>"},{"location":"deployment/issue-dockerisation/#taille-estimee-des-images","title":"Taille estim\u00e9e des images","text":"<ul> <li>Image finale : ~2.5-3 GB (avec torch, transformers)</li> <li>Volumes :</li> <li><code>lmelp-audios</code> : 50-100 GB (audio MP3 des \u00e9pisodes)</li> <li><code>lmelp-db-backup</code> : 1-5 GB (dumps MongoDB)</li> <li><code>lmelp-logs</code> : &lt; 100 MB</li> </ul>"},{"location":"deployment/issue-dockerisation/#structure-finale-du-projet","title":"Structure finale du projet","text":"<pre><code>lmelp/\n\u251c\u2500\u2500 docker/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 docker-compose.yml         # PC local\n\u2502   \u251c\u2500\u2500 docker-compose.nas.yml     # NAS Synology\n\u2502   \u251c\u2500\u2500 .env.template\n\u2502   \u251c\u2500\u2500 entrypoint.sh\n\u2502   \u2514\u2500\u2500 scripts/\n\u2502       \u251c\u2500\u2500 start.sh\n\u2502       \u251c\u2500\u2500 stop.sh\n\u2502       \u251c\u2500\u2500 update.sh\n\u2502       \u251c\u2500\u2500 logs.sh\n\u2502       \u2514\u2500\u2500 backup-db.sh\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 docker-publish.yml\n\u251c\u2500\u2500 .dockerignore\n\u2514\u2500\u2500 docs/\n    \u2514\u2500\u2500 deployment/\n        \u251c\u2500\u2500 docker-setup.md\n        \u251c\u2500\u2500 local-deployment.md\n        \u251c\u2500\u2500 nas-deployment.md\n        \u251c\u2500\u2500 update-guide.md\n        \u251c\u2500\u2500 troubleshooting.md\n        \u2514\u2500\u2500 batch-processing.md\n</code></pre>"},{"location":"deployment/issue-dockerisation/#notes-importantes","title":"Notes importantes","text":"<ul> <li>\u26a0\ufe0f Pas de conteneur MongoDB sur NAS : Utiliser le conteneur <code>mongo</code> existant</li> <li>\u26a0\ufe0f MongoDB sur PC : Inclus dans docker-compose.yml local</li> <li>\u26a0\ufe0f R\u00e9seau Docker :</li> <li>NAS : Connecter au r\u00e9seau du conteneur mongo existant</li> <li>PC : R\u00e9seau d\u00e9di\u00e9 <code>lmelp-network</code></li> <li>\u26a0\ufe0f Volumes : Persister les fichiers audio (plusieurs Go)</li> <li>\u26a0\ufe0f Secrets : Toutes les API keys via variables d'environnement (Portainer sur NAS, .env sur PC)</li> <li>\u26a0\ufe0f Mod\u00e8les ML : T\u00e9l\u00e9charg\u00e9s au premier lancement (Whisper, Transformers) \u2192 temps de d\u00e9marrage initial long</li> <li>\u26a0\ufe0f Transcription : Op\u00e9ration TR\u00c8S co\u00fbteuse en ressources (RAM + CPU/GPU)</li> <li>\u26a0\ufe0f Webhook : Actif uniquement sur NAS pour auto-deploy, PC fait pull manuel</li> </ul>"},{"location":"deployment/issue-dockerisation/#criteres-de-succes","title":"Crit\u00e8res de succ\u00e8s","text":"<p>\u2705 Image Docker build\u00e9e et publi\u00e9e sur ghcr.io \u2705 Application d\u00e9ploy\u00e9e et accessible sur :   - PC local : http://localhost:8501   - NAS : https://lmelp.ascot63.synology.me \u2705 Connexion MongoDB fonctionnelle (externe sur NAS, locale sur PC) \u2705 Volumes persistants pour audios et backups \u2705 Webhook GitHub \u2192 Portainer fonctionnel (d\u00e9ploiement automatique NAS) \u2705 Scripts batch ex\u00e9cutables en conteneur \u2705 Possibilit\u00e9 de rollback vers version pr\u00e9c\u00e9dente \u2705 Documentation compl\u00e8te du d\u00e9ploiement et de la maintenance \u2705 Tests de performance passants (RAM &lt; 4 GB utilisation normale) \u2705 Healthchecks fonctionnels</p>"},{"location":"deployment/issue-dockerisation/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Configuration MongoDB existante</li> <li>Documentation Portainer</li> <li>GitHub Container Registry</li> <li>Synology Application Portal</li> <li>Docker Compose File Reference</li> <li>Streamlit Docker Deployment</li> </ul>"},{"location":"deployment/issue-dockerisation/#prochaines-etapes","title":"Prochaines \u00e9tapes","text":"<ol> <li>Commencer par Phase 1 : Cr\u00e9ation des Dockerfiles</li> <li>Tester build local et fonctionnement de base</li> <li>Setup CI/CD GitHub Actions</li> <li>D\u00e9ploiement test sur PC local</li> <li>D\u00e9ploiement production sur NAS avec webhook</li> <li>Documentation et validation finale</li> </ol>"}]}