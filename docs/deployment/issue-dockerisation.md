# Dockerisation et d√©ploiement multi-environnement

## Objectif

Packager l'application **lmelp** (Le Masque et la Plume) sous forme de conteneur Docker et permettre son d√©ploiement aussi bien sur NAS Synology DS 923+ qu'en local sur PC avec gestion automatis√©e des mises √† jour.

## Architecture cible

### Conteneurs

- **Application Streamlit** : Interface web + scripts de traitement (port 8501)
- **MongoDB** :
  - Sur NAS : Utilisation du conteneur existant `mongo` (pas de nouveau conteneur)
  - Sur PC : Conteneur MongoDB local ou service MongoDB install√©

### R√©seau

- Connexion au r√©seau bridge Docker existant (NAS) ou r√©seau d√©di√© (PC)
- Application se connecte √† MongoDB via `mongodb://mongo:27017/masque_et_la_plume` (NAS) ou `mongodb://localhost:27017/masque_et_la_plume` (PC)
- Reverse proxy via Application Portal Synology : `lmelp.ascot63.synology.me` (NAS uniquement)

### Volumes Docker

```
lmelp-audios/     ‚Üí /app/audios      # Fichiers audio t√©l√©charg√©s (plusieurs Go)
lmelp-db-backup/  ‚Üí /app/db          # Sauvegardes MongoDB
lmelp-logs/       ‚Üí /app/logs        # Logs applicatifs (optionnel)
```

### Pipeline CI/CD

```
Git push/tag ‚Üí GitHub Actions ‚Üí Build image ‚Üí ghcr.io ‚Üí
  ‚îú‚îÄ‚îÄ Webhook Portainer ‚Üí D√©ploiement NAS
  ‚îî‚îÄ‚îÄ Pull manuel ‚Üí D√©ploiement PC local
```

## Configuration

### Application Streamlit

**Variables d'environnement requises :**

```bash
# Base de donn√©es
DB_HOST=mongo                              # ou localhost pour PC
DB_NAME=masque_et_la_plume
DB_LOGS=true

# Flux RSS
RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml

# APIs LLM (au moins une requise)
AZURE_API_KEY=sk-...
AZURE_ENDPOINT=https://....openai.azure.com/
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...

# Google Services (optionnel)
GOOGLE_PROJECT_ID=...
GOOGLE_CUSTOM_SEARCH_API_KEY=...
SEARCH_ENGINE_ID=...

# Chemins
AUDIO_BASE_PATH=/app/audios
```

### Tags Docker

- `latest` : Derni√®re version stable (auto-d√©ploy√©e via webhook sur NAS)
- `v1.0.0`, `v1.1.0`, etc. : Versions sp√©cifiques
- Repository : `ghcr.io/castorfou/lmelp`

## Phase 1 : Pr√©paration du Dockerfile

### T√¢ches

#### ‚úÖ Cr√©er `docker/Dockerfile`

```dockerfile
# Multi-stage build optimis√© pour taille et performance
FROM python:3.11-slim as base

# Stage 1: Build dependencies
FROM base as builder
WORKDIR /build
RUN pip install uv
COPY .devcontainer/requirements.txt .
RUN uv pip install --system -r requirements.txt

# Stage 2: Runtime
FROM base as runtime
WORKDIR /app

# Copier Python + deps depuis builder
COPY --from=builder /usr/local /usr/local

# Copier code source
COPY nbs/ /app/nbs/
COPY ui/ /app/ui/
COPY scripts/ /app/scripts/

# Cr√©er r√©pertoires pour volumes
RUN mkdir -p /app/audios /app/db /app/logs

# Exposer port Streamlit
EXPOSE 8501

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8501/_stcore/health || exit 1

# Point d'entr√©e
CMD ["uv", "run", "streamlit", "run", "ui/lmelp.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Caract√©ristiques :**
- Multi-stage build pour optimiser la taille
- Utilise `uv` pour gestion rapide des d√©pendances
- Image de base Python 3.11 slim
- Healthcheck int√©gr√© pour monitoring
- Port 8501 expos√©
- Support des volumes pour donn√©es persistantes

#### ‚úÖ Cr√©er `docker/docker-compose.yml` (pour PC local)

```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:7
    container_name: lmelp-mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - lmelp-mongodb-data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=masque_et_la_plume
    networks:
      - lmelp-network

  app:
    image: ghcr.io/castorfou/lmelp:latest
    container_name: lmelp-app
    restart: unless-stopped
    depends_on:
      - mongodb
    ports:
      - "8501:8501"
    volumes:
      - lmelp-audios:/app/audios
      - lmelp-db-backup:/app/db
      - lmelp-logs:/app/logs
    environment:
      # Base de donn√©es
      - DB_HOST=mongodb
      - DB_NAME=masque_et_la_plume
      - DB_LOGS=true
      # Flux RSS
      - RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml
      # APIs (√† configurer via .env)
      - AZURE_API_KEY=${AZURE_API_KEY}
      - AZURE_ENDPOINT=${AZURE_ENDPOINT}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Chemins
      - AUDIO_BASE_PATH=/app/audios
    networks:
      - lmelp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  lmelp-mongodb-data:
  lmelp-audios:
  lmelp-db-backup:
  lmelp-logs:

networks:
  lmelp-network:
    driver: bridge
```

#### ‚úÖ Cr√©er `docker/docker-compose.nas.yml` (pour NAS Synology)

```yaml
version: '3.8'

services:
  app:
    image: ghcr.io/castorfou/lmelp:latest
    container_name: lmelp-app
    restart: unless-stopped
    ports:
      - "8501:8501"
    volumes:
      - lmelp-audios:/app/audios
      - lmelp-db-backup:/app/db
      - lmelp-logs:/app/logs
    environment:
      # Base de donn√©es (utilise MongoDB existant)
      - DB_HOST=mongo
      - DB_NAME=masque_et_la_plume
      - DB_LOGS=true
      # Flux RSS
      - RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml
      # APIs (√† configurer dans Portainer)
      - AZURE_API_KEY=${AZURE_API_KEY}
      - AZURE_ENDPOINT=${AZURE_ENDPOINT}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Chemins
      - AUDIO_BASE_PATH=/app/audios
    networks:
      - bridge  # R√©seau existant avec conteneur mongo
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  lmelp-audios:
  lmelp-db-backup:
  lmelp-logs:

networks:
  bridge:
    external: true  # Utilise r√©seau existant
```

#### ‚úÖ Cr√©er `docker/.env.template`

```bash
# Copier ce fichier vers .env et remplir les valeurs

# APIs LLM (au moins une requise)
AZURE_API_KEY=
AZURE_ENDPOINT=
OPENAI_API_KEY=
GEMINI_API_KEY=

# Google Services (optionnel)
GOOGLE_PROJECT_ID=
GOOGLE_CUSTOM_SEARCH_API_KEY=
SEARCH_ENGINE_ID=
```

#### ‚úÖ Cr√©er `.dockerignore`

```
# Git
.git/
.github/
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
.venv/
venv/
ENV/
env/

# Tests
tests/
htmlcov/
.coverage
.pytest_cache/

# Documentation
docs/
site/
*.md
!CLAUDE.md

# Development
.devcontainer/
.vscode/
*.ipynb_checkpoints/

# Data (ne pas inclure dans l'image)
audios/
db/
*.db
*.sqlite

# Notebooks (d√©j√† convertis en .py)
nbs/*.ipynb

# Build artifacts
dist/
build/
*.egg-info/

# Logs
*.log
logs/

# Environment
.env
.env.*
!.env.template
```

#### ‚úÖ Cr√©er `docker/entrypoint.sh` (optionnel, pour scripts batch)

```bash
#!/bin/bash
set -e

# Mode d'ex√©cution : web (Streamlit) ou batch (scripts)
MODE=${LMELP_MODE:-web}

if [ "$MODE" = "web" ]; then
    echo "Starting Streamlit web interface..."
    exec uv run streamlit run ui/lmelp.py --server.port=8501 --server.address=0.0.0.0
elif [ "$MODE" = "batch-update" ]; then
    echo "Running RSS update script..."
    exec python scripts/update_emissions.py
elif [ "$MODE" = "batch-transcribe" ]; then
    echo "Running transcription script..."
    exec python scripts/get_all_transcriptions.py
elif [ "$MODE" = "batch-authors" ]; then
    echo "Running author extraction script..."
    exec python scripts/store_all_auteurs_from_all_episodes.py
else
    echo "Unknown mode: $MODE"
    echo "Available modes: web, batch-update, batch-transcribe, batch-authors"
    exit 1
fi
```

## Phase 2 : CI/CD GitHub Actions

### T√¢ches

#### ‚úÖ Cr√©er `.github/workflows/docker-publish.yml`

```yaml
name: Build and Publish Docker Image

on:
  push:
    branches:
      - main
    tags:
      - 'v*.*.*'
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=semver,pattern={{major}}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Trigger Portainer Webhook (NAS deployment)
        if: github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')
        run: |
          curl -X POST ${{ secrets.PORTAINER_WEBHOOK_URL }}
        continue-on-error: true
```

#### ‚úÖ Configurer GitHub secrets

Aller dans `Settings > Secrets and variables > Actions` et ajouter :

- `PORTAINER_WEBHOOK_URL` : URL du webhook Portainer pour d√©ploiement automatique sur NAS

**Note :** `GITHUB_TOKEN` est automatiquement fourni par GitHub Actions.

#### ‚úÖ Tester build local

```bash
# Build de l'image
docker build -f docker/Dockerfile -t lmelp:test .

# Test de l'image
docker run --rm -p 8501:8501 \
  -e DB_HOST=localhost \
  -e GEMINI_API_KEY=your_key \
  lmelp:test

# Acc√©der √† http://localhost:8501
```

## Phase 3 : Configuration NAS Synology (Portainer)

### T√¢ches

#### ‚úÖ V√©rifier/cr√©er r√©seau Docker partag√©

```bash
# SSH sur le NAS
ssh admin@nas-synology

# V√©rifier que le conteneur mongo est sur le r√©seau bridge
docker network inspect bridge

# Si n√©cessaire, connecter mongo au r√©seau
docker network connect bridge mongo
```

#### ‚úÖ Cr√©er stack Portainer

1. Ouvrir Portainer web UI
2. Aller dans `Stacks > Add stack`
3. **Name:** `lmelp`
4. **Build method:** Repository (ou Web editor avec docker-compose.nas.yml)
5. **Repository URL:** `https://github.com/castorfou/lmelp`
6. **Repository reference:** `main`
7. **Compose path:** `docker/docker-compose.nas.yml`

#### ‚úÖ Configurer variables d'environnement dans Portainer

Dans l'onglet **Environment variables** de la stack :

```
AZURE_API_KEY=sk-...
AZURE_ENDPOINT=https://....openai.azure.com/
GEMINI_API_KEY=...
OPENAI_API_KEY=...
GOOGLE_PROJECT_ID=...
GOOGLE_CUSTOM_SEARCH_API_KEY=...
SEARCH_ENGINE_ID=...
```

#### ‚úÖ Configurer webhook Portainer

1. Dans la stack `lmelp`, aller dans **Webhooks**
2. Cliquer sur **Add webhook**
3. Copier l'URL g√©n√©r√©e (format : `https://portainer.nas/api/webhooks/xxx`)
4. Ajouter cette URL dans GitHub Secrets comme `PORTAINER_WEBHOOK_URL`

#### ‚úÖ Configurer limites de ressources

Dans Portainer, √©diter le service `lmelp-app` :
- **Memory limit:** 4 GB (Whisper + Transformers = lourd)
- **CPU limit:** 2 cores
- **Restart policy:** Unless stopped

## Phase 4 : Configuration PC local

### T√¢ches

#### ‚úÖ Cr√©er fichier `.env` local

```bash
cd lmelp/docker/
cp .env.template .env
# √âditer .env avec vos cl√©s API
```

#### ‚úÖ Lancer avec Docker Compose

```bash
# Premi√®re fois : pull de l'image
docker compose -f docker/docker-compose.yml pull

# Lancer les services
docker compose -f docker/docker-compose.yml up -d

# Voir les logs
docker compose -f docker/docker-compose.yml logs -f

# Acc√©der √† l'application
open http://localhost:8501
```

#### ‚úÖ Scripts de gestion (cr√©ation de helpers)

Cr√©er `docker/scripts/start.sh` :
```bash
#!/bin/bash
docker compose -f docker/docker-compose.yml up -d
```

Cr√©er `docker/scripts/stop.sh` :
```bash
#!/bin/bash
docker compose -f docker/docker-compose.yml down
```

Cr√©er `docker/scripts/update.sh` :
```bash
#!/bin/bash
docker compose -f docker/docker-compose.yml pull
docker compose -f docker/docker-compose.yml up -d
```

Cr√©er `docker/scripts/logs.sh` :
```bash
#!/bin/bash
docker compose -f docker/docker-compose.yml logs -f
```

Cr√©er `docker/scripts/backup-db.sh` :
```bash
#!/bin/bash
# Backup MongoDB depuis le conteneur
docker exec lmelp-mongodb mongodump \
  --db masque_et_la_plume \
  --out /data/db/backup/$(date +%Y%m%d_%H%M%S)
```

## Phase 5 : Reverse Proxy Synology (NAS uniquement)

### T√¢ches

#### ‚úÖ Configurer Application Portal

1. Ouvrir **Control Panel > Login Portal > Advanced > Reverse Proxy**
2. Cliquer **Create**
3. **Configuration :**
   - **Reverse Proxy Name:** lmelp
   - **Source:**
     - Protocol: HTTPS
     - Hostname: lmelp.ascot63.synology.me
     - Port: 443
     - Enable HSTS: ‚úì
   - **Destination:**
     - Protocol: HTTP
     - Hostname: localhost
     - Port: 8501
   - **Custom Headers :**
     ```
     WebSocket: true
     ```

#### ‚úÖ Configurer certificat SSL

1. Aller dans **Control Panel > Security > Certificate**
2. Utiliser un certificat existant ou cr√©er un nouveau Let's Encrypt
3. Assigner le certificat √† lmelp.ascot63.synology.me

#### ‚úÖ Tester acc√®s externe

```bash
# Test depuis Internet
curl -I https://lmelp.ascot63.synology.me

# V√©rifier dans navigateur
open https://lmelp.ascot63.synology.me
```

## Phase 6 : Scripts batch en conteneur

### T√¢ches

#### ‚úÖ Cr√©er service Docker pour scripts batch

Optionnel : Ajouter dans `docker-compose.yml` un service pour les t√¢ches planifi√©es :

```yaml
  batch-worker:
    image: ghcr.io/castorfou/lmelp:latest
    container_name: lmelp-batch
    restart: "no"  # Lancer manuellement ou via cron
    depends_on:
      - mongodb
    volumes:
      - lmelp-audios:/app/audios
      - lmelp-db-backup:/app/db
    environment:
      # M√™me config que app
      - DB_HOST=mongodb
      - LMELP_MODE=batch-update  # ou batch-transcribe, batch-authors
    networks:
      - lmelp-network
```

#### ‚úÖ Cr√©er t√¢ches planifi√©es (cron sur NAS)

```bash
# SSH sur NAS
sudo crontab -e

# Ajouter :
# Mise √† jour RSS quotidienne √† 6h
0 6 * * * docker run --rm --network bridge \
  -e DB_HOST=mongo -e LMELP_MODE=batch-update \
  ghcr.io/castorfou/lmelp:latest

# Transcription hebdomadaire dimanche 2h
0 2 * * 0 docker run --rm --network bridge \
  -v lmelp-audios:/app/audios \
  -e DB_HOST=mongo -e LMELP_MODE=batch-transcribe \
  ghcr.io/castorfou/lmelp:latest
```

## Phase 7 : Documentation

### T√¢ches

#### ‚úÖ Cr√©er `docs/deployment/docker-setup.md`

Documentation compl√®te de l'architecture Docker :
- Sch√©ma d'architecture
- Pr√©requis syst√®me
- Ressources requises
- R√©seau Docker

#### ‚úÖ Cr√©er `docs/deployment/local-deployment.md`

Guide de d√©ploiement sur PC local :
- Installation Docker Desktop
- Configuration .env
- Commandes docker-compose
- Acc√®s √† l'application

#### ‚úÖ Cr√©er `docs/deployment/nas-deployment.md`

Guide de d√©ploiement sur NAS Synology :
- Configuration Portainer
- Variables d'environnement
- Webhook configuration
- Reverse proxy Application Portal
- Troubleshooting sp√©cifique NAS

#### ‚úÖ Cr√©er `docs/deployment/update-guide.md`

Guide de mise √† jour :
- Mise √† jour automatique (webhook)
- Mise √† jour manuelle locale
- Mise √† jour vers version sp√©cifique
- Rollback vers version pr√©c√©dente
- Gestion des migrations de donn√©es

#### ‚úÖ Cr√©er `docs/deployment/troubleshooting.md`

Guide de d√©pannage :
- Probl√®mes courants (connexion MongoDB, APIs, transcription)
- Consultation des logs
- V√©rification sant√© des conteneurs
- Tests de connectivit√©
- Nettoyage et maintenance

#### ‚úÖ Mettre √† jour `README.md`

Ajouter section compl√®te sur le d√©ploiement Docker :

```markdown
## D√©ploiement Docker

### üê≥ D√©ploiement local (PC)

voir [Guide de d√©ploiement local](docs/deployment/local-deployment.md)

```bash
cd docker/
cp .env.template .env
# √âditer .env avec vos cl√©s API
docker compose up -d
```

Acc√©der √† http://localhost:8501

### üñ•Ô∏è D√©ploiement NAS Synology

voir [Guide de d√©ploiement NAS](docs/deployment/nas-deployment.md)

D√©ploiement automatique via Portainer + GitHub Actions webhook.

### üì¶ Images Docker

Images disponibles sur GitHub Container Registry :
- `ghcr.io/castorfou/lmelp:latest` - Derni√®re version stable
- `ghcr.io/castorfou/lmelp:v1.0.0` - Versions sp√©cifiques

### üîÑ Mise √† jour

voir [Guide de mise √† jour](docs/deployment/update-guide.md)
```

#### ‚úÖ Cr√©er `docs/deployment/batch-processing.md`

Documentation des scripts batch en conteneur :
- Utilisation du mode batch
- Scripts disponibles
- Configuration cron
- Logs et monitoring

## Phase 8 : Tests et validation

### T√¢ches

#### ‚úÖ Test build local des images

```bash
# Build
docker build -f docker/Dockerfile -t lmelp:test .

# V√©rifier taille
docker images lmelp:test

# V√©rifier layers
docker history lmelp:test

# Test d√©marrage
docker run --rm -p 8501:8501 \
  -e DB_HOST=localhost \
  -e GEMINI_API_KEY=test \
  lmelp:test
```

**Crit√®res de succ√®s :**
- Taille image < 3 GB (avec transformers + torch)
- D√©marrage < 30 secondes
- Healthcheck OK apr√®s d√©marrage

#### ‚úÖ Test docker-compose local complet

```bash
# D√©marrer tous les services
docker compose -f docker/docker-compose.yml up -d

# V√©rifier statut
docker compose -f docker/docker-compose.yml ps

# V√©rifier logs
docker compose -f docker/docker-compose.yml logs app

# V√©rifier MongoDB
docker exec -it lmelp-mongodb mongosh --eval "db.adminCommand('ping')"

# Test interface web
curl http://localhost:8501

# Test API MongoDB depuis app
docker exec -it lmelp-app python -c "
from nbs.mongo import get_mongodb_client
client = get_mongodb_client()
print(client.server_info())
"

# Arr√™ter
docker compose -f docker/docker-compose.yml down
```

**Crit√®res de succ√®s :**
- Tous les services d√©marrent sans erreur
- Application Streamlit accessible
- Connexion MongoDB fonctionnelle
- Volumes persistants cr√©√©s

#### ‚úÖ Test d√©ploiement NAS Portainer

1. D√©ployer stack via Portainer
2. V√©rifier logs dans Portainer UI
3. V√©rifier connexion au MongoDB existant :
   ```bash
   docker exec -it lmelp-app python -c "
   from nbs.mongo import get_mongodb_client
   client = get_mongodb_client()
   print(client.list_database_names())
   "
   ```
4. Tester interface web via reverse proxy : https://lmelp.ascot63.synology.me

**Crit√®res de succ√®s :**
- Stack d√©ploy√©e sans erreur
- Connexion √† MongoDB externe OK
- Interface accessible via domaine Synology
- HTTPS fonctionnel avec certificat valide

#### ‚úÖ Test webhook auto-deploy

```bash
# Push sur main
git push origin main

# V√©rifier GitHub Actions
# https://github.com/castorfou/lmelp/actions

# V√©rifier logs Portainer pour auto-deploy
# V√©rifier que nouvelle version est d√©ploy√©e
docker exec -it lmelp-app python -c "import sys; print(sys.version)"
```

**Crit√®res de succ√®s :**
- Build GitHub Actions r√©ussie
- Image publi√©e sur ghcr.io
- Webhook d√©clench√© automatiquement
- Stack Portainer mise √† jour
- Application red√©marr√©e avec nouvelle version

#### ‚úÖ Test rollback

```bash
# M√©thode 1 : Via Portainer
# 1. √âditer stack
# 2. Changer image vers version pr√©c√©dente (ex: v1.0.0)
# 3. Update stack

# M√©thode 2 : En local
docker compose -f docker/docker-compose.yml down
docker pull ghcr.io/castorfou/lmelp:v1.0.0
# √âditer docker-compose.yml : image: ghcr.io/castorfou/lmelp:v1.0.0
docker compose -f docker/docker-compose.yml up -d

# V√©rifier que l'application fonctionne avec ancienne version
```

**Crit√®res de succ√®s :**
- Rollback vers version pr√©c√©dente sans perte de donn√©es
- Application fonctionnelle
- Volumes pr√©serv√©s

#### ‚úÖ Test scripts batch

```bash
# Test mise √† jour RSS
docker run --rm --network lmelp-network \
  -e DB_HOST=mongodb \
  -e LMELP_MODE=batch-update \
  -e RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml \
  ghcr.io/castorfou/lmelp:latest

# V√©rifier dans MongoDB que les √©pisodes sont ajout√©s
docker exec -it lmelp-mongodb mongosh masque_et_la_plume \
  --eval "db.episodes.countDocuments()"

# Test transcription (avec √©pisode de test)
docker run --rm --network lmelp-network \
  -v lmelp-audios:/app/audios \
  -e DB_HOST=mongodb \
  -e LMELP_MODE=batch-transcribe \
  -e GEMINI_API_KEY=$GEMINI_API_KEY \
  ghcr.io/castorfou/lmelp:latest
```

**Crit√®res de succ√®s :**
- Scripts s'ex√©cutent sans erreur
- Donn√©es ajout√©es/modifi√©es dans MongoDB
- Fichiers audio persist√©s dans volume
- Logs clairs et informatifs

#### ‚úÖ Test performance et ressources

```bash
# Surveiller ressources pendant utilisation
docker stats lmelp-app

# Test charge : ouvrir plusieurs pages Streamlit
# V√©rifier utilisation CPU/RAM

# Test transcription : surveiller pendant transcription d'un √©pisode
docker stats lmelp-app
```

**Crit√®res de succ√®s :**
- RAM < 4 GB pendant utilisation normale
- RAM < 8 GB pendant transcription Whisper
- CPU < 100% en moyenne
- Pas de memory leak apr√®s plusieurs heures

## Sp√©cifications techniques

### Ressources NAS

- **RAM :** 40 Go disponibles
- **Stockage :** 20 To disponibles
- **Mod√®le :** Synology DS 923+
- **R√©seau :** Accessible depuis Internet

### Limites de ressources conteneurs

```yaml
deploy:
  resources:
    limits:
      cpus: '2'
      memory: 4G
    reservations:
      cpus: '1'
      memory: 2G
```

**Justification :**
- Whisper + Transformers = mod√®les lourds en RAM
- Transcription = intensif CPU
- 4 GB permet de charger les mod√®les ML confortablement

### Healthchecks

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s  # Temps de chargement des mod√®les ML
```

### Taille estim√©e des images

- **Image finale :** ~2.5-3 GB (avec torch, transformers)
- **Volumes :**
  - `lmelp-audios` : 50-100 GB (audio MP3 des √©pisodes)
  - `lmelp-db-backup` : 1-5 GB (dumps MongoDB)
  - `lmelp-logs` : < 100 MB

## Structure finale du projet

```
lmelp/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml         # PC local
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.nas.yml     # NAS Synology
‚îÇ   ‚îú‚îÄ‚îÄ .env.template
‚îÇ   ‚îú‚îÄ‚îÄ entrypoint.sh
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ start.sh
‚îÇ       ‚îú‚îÄ‚îÄ stop.sh
‚îÇ       ‚îú‚îÄ‚îÄ update.sh
‚îÇ       ‚îú‚îÄ‚îÄ logs.sh
‚îÇ       ‚îî‚îÄ‚îÄ backup-db.sh
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ docker-publish.yml
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ deployment/
        ‚îú‚îÄ‚îÄ docker-setup.md
        ‚îú‚îÄ‚îÄ local-deployment.md
        ‚îú‚îÄ‚îÄ nas-deployment.md
        ‚îú‚îÄ‚îÄ update-guide.md
        ‚îú‚îÄ‚îÄ troubleshooting.md
        ‚îî‚îÄ‚îÄ batch-processing.md
```

## Notes importantes

- ‚ö†Ô∏è **Pas de conteneur MongoDB sur NAS** : Utiliser le conteneur `mongo` existant
- ‚ö†Ô∏è **MongoDB sur PC** : Inclus dans docker-compose.yml local
- ‚ö†Ô∏è **R√©seau Docker** :
  - NAS : Connecter au r√©seau du conteneur mongo existant
  - PC : R√©seau d√©di√© `lmelp-network`
- ‚ö†Ô∏è **Volumes** : Persister les fichiers audio (plusieurs Go)
- ‚ö†Ô∏è **Secrets** : Toutes les API keys via variables d'environnement (Portainer sur NAS, .env sur PC)
- ‚ö†Ô∏è **Mod√®les ML** : T√©l√©charg√©s au premier lancement (Whisper, Transformers) ‚Üí temps de d√©marrage initial long
- ‚ö†Ô∏è **Transcription** : Op√©ration **TR√àS** co√ªteuse en ressources (RAM + CPU/GPU)
- ‚ö†Ô∏è **Webhook** : Actif uniquement sur NAS pour auto-deploy, PC fait pull manuel

## Crit√®res de succ√®s

‚úÖ Image Docker build√©e et publi√©e sur ghcr.io
‚úÖ Application d√©ploy√©e et accessible sur :
  - PC local : http://localhost:8501
  - NAS : https://lmelp.ascot63.synology.me
‚úÖ Connexion MongoDB fonctionnelle (externe sur NAS, locale sur PC)
‚úÖ Volumes persistants pour audios et backups
‚úÖ Webhook GitHub ‚Üí Portainer fonctionnel (d√©ploiement automatique NAS)
‚úÖ Scripts batch ex√©cutables en conteneur
‚úÖ Possibilit√© de rollback vers version pr√©c√©dente
‚úÖ Documentation compl√®te du d√©ploiement et de la maintenance
‚úÖ Tests de performance passants (RAM < 4 GB utilisation normale)
‚úÖ Healthchecks fonctionnels

## R√©f√©rences

- [Configuration MongoDB existante](../mongo.md)
- [Documentation Portainer](https://docs.portainer.io/)
- [GitHub Container Registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry)
- [Synology Application Portal](https://kb.synology.com/en-global/DSM/help/DSM/AdminCenter/application_appportal_config)
- [Docker Compose File Reference](https://docs.docker.com/compose/compose-file/)
- [Streamlit Docker Deployment](https://docs.streamlit.io/knowledge-base/tutorials/deploy/docker)

## Prochaines √©tapes

1. Commencer par Phase 1 : Cr√©ation des Dockerfiles
2. Tester build local et fonctionnement de base
3. Setup CI/CD GitHub Actions
4. D√©ploiement test sur PC local
5. D√©ploiement production sur NAS avec webhook
6. Documentation et validation finale
