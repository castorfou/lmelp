- [pour developper ðŸ’»](#pour-developper-)
  - [environnements de dev python ðŸ](#environnements-de-dev-python-)
  - [pre-commit â±ï¸](#pre-commit-ï¸)
  - [config vscode ðŸ–¥ï¸](#config-vscode-ï¸)
- [pour utiliser ðŸš€](#pour-utiliser-)
  - [ffmpeg ðŸŽžï¸](#ffmpeg-ï¸)
  - [locale FR ðŸ‡«ðŸ‡·](#locale-fr-)
  - [ulimit âš™ï¸](#ulimit-ï¸)
  - [`.env` ðŸŒ](#env-)
    - [rss info ðŸŽ™ï¸](#rss-info-ï¸)
    - [web info ðŸŒ](#web-info-)
    - [db info ðŸ—„ï¸](#db-info-ï¸)
    - [llm, llamaindex ðŸ¤–](#llm-llamaindex-)
  - [streamlit ðŸ–±ï¸](#streamlit-ï¸)


# pour developper ðŸ’»

## environnements de dev python ðŸ

vscode utilisera automatiquement le devcontainer definit dans le repo sous `.devcontainer`

je garde quand meme le script de creation d'environnement whisper depuis `envs/whisper.txt` âœ¨  qui contient ce qu il faut pour whisper, feedparser, transformers (huggingface), dotenv, mongo, streamlit ðŸ› ï¸

## pre-commit â±ï¸

dans devcontainer, pre-commit est deja configure sinon

`pre-commit install` âœ…

## config vscode ðŸ–¥ï¸

en cas de message `"Visual Studio Code is unable to watch for file changes in this large workspace" (error ENOSPC)` [see vscode linux page](https://code.visualstudio.com/docs/setup/linux#_visual-studio-code-is-unable-to-watch-for-file-changes-in-this-large-workspace-error-enospc) âš ï¸

```bash
# add fs.inotify.max_user_watches=524288 to /etc/sysctl.conf
sudo sysctl -p # to apply directly
cat /proc/sys/fs/inotify/max_user_watches # to control it is applied
```
  
or add `files.watcherExclude` directive in `.vscode/settings.json` ðŸ“

# pour utiliser ðŸš€

## ffmpeg ðŸŽžï¸

ffmpeg is required to load audio files from filename for whisper use (transcription d'un mp3) ðŸŽ§

install, it is available in snap (4.3.1) ðŸ“¦

## locale FR ðŸ‡«ðŸ‡·

en cas d'erreur de type `locale.Error: unsupported locale setting` â—

verifier avec `locale -a` que `fr_FR.UTF-8` soit installÃ©e. ðŸ”

Sinon le faire avec 

```bash
sudo apt-get install language-pack-fr-base
locale -a
```

## ulimit âš™ï¸

j'ai du augmenter l'ulimit de mon systeme pour utiliser whisper pour eviter l'erreur `Too many open files` ðŸš«

Avec ce parametre je n'ai plus le probleme: `ulimit -n 4096` âœ”ï¸  
Je l'ai ajoute dans `.zshrc` ðŸ“

## `.env` ðŸŒ

https://pypi.org/project/python-dotenv/ ðŸ’¡

> Python-dotenv reads key-value pairs from a .env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles. ðŸ“‹

creer `.env` Ã  la racine du repo avec ðŸ—ï¸

### rss info ðŸŽ™ï¸

L'adresse du flux RSS du podcast du Masque et la Plume ðŸŽ§

si absent `https://radiofrance-podcast.net/podcast09/rss_14007.xml` est utilisÃ© par defaut ðŸ”„  

```
RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml
```

### web info ðŸŒ

Le lien vers la page web stockee du masque listant les episodes "legacy" historiques ðŸ“œ

si absent `db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html` est utilisÃ© par defaut ðŸ”„  

```
WEB_LMELP_FILENAME=db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html
```

### db info ðŸ—„ï¸

pour tout ce qui concerne la base mongo ðŸ›¢ï¸

```
DB_HOST=localhost # Ã  changer avec nas923 par exemple
DB_NAME="masque_et_la_plume"
DB_LOGS=true # si prÃ©sent et valant true, va enregistrer toutes les operations dans la collection logs
```

### llm, llamaindex ðŸ¤–

```
# gemini 
GEMINI_API_KEY=
# gemini vertex
GOOGLE_PROJECT_ID=
GOOGLE_AUTH_FILE=

# openai
OPENAI_API_KEY=

# azure openai
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_VERSION=
```

gemini llm, GEMINI_API_KEY dispo Ã  ðŸš€

from https://console.cloud.google.com/apis/credentials ðŸ”‘

gemini vertex (llamaindex), GOOGLE_PROJECT_ID ðŸ§­

from https://console.cloud.google.com ðŸŒ

gemini vertex (llamaindex), GOOGLE_AUTH_FILE ðŸ“‚

follow instructions at https://stackoverflow.com/a/69941050 ðŸ“˜

## streamlit ðŸ–±ï¸

3 ways to run it: from vscode, from devcontainer, from host

from **vscode**: palette > run task > run streamlit ðŸš€

from **devcontainer** terminal: `ui/lmelp_ui.sh` âš¡

from **host** terminal: 

```bash
#!/bin/bash 

source ~/git/lmelp/scripts/from_host/get_container.sh

container=$(get_container)
echo "Using container: $container"

# Execute the UI script in the found container as the user vscode.
docker exec -u vscode "$container" /workspaces/lmelp/ui/lmelp_ui.sh
```