- [pour developper ğŸ’»](#pour-developper-)
  - [environnements de dev python ğŸ](#environnements-de-dev-python-)
  - [pre-commit â±ï¸](#pre-commit-ï¸)
  - [config vscode ğŸ–¥ï¸](#config-vscode-ï¸)
- [pour utiliser ğŸš€](#pour-utiliser-)
  - [ffmpeg ğŸï¸](#ffmpeg-ï¸)
  - [locale FR ğŸ‡«ğŸ‡·](#locale-fr-)
  - [ulimit âš™ï¸](#ulimit-ï¸)
  - [`.env` ğŸŒ](#env-)
    - [rss info ğŸ™ï¸](#rss-info-ï¸)
    - [web info ğŸŒ](#web-info-)
    - [db info ğŸ—„ï¸](#db-info-ï¸)
    - [llm, llamaindex ğŸ¤–](#llm-llamaindex-)
    - [SerpApi ğŸ”](#serpapi-)
  - [streamlit ğŸ–±ï¸](#streamlit-ï¸)


# pour developper ğŸ’»

## environnements de dev python ğŸ

vscode utilisera automatiquement le devcontainer definit dans le repo sous `.devcontainer`

je garde quand meme le script de creation d'environnement whisper depuis `envs/whisper.txt` âœ¨  qui contient ce qu il faut pour whisper, feedparser, transformers (huggingface), dotenv, mongo, streamlit ğŸ› ï¸

## pre-commit â±ï¸

dans devcontainer, pre-commit est deja configure sinon

`pre-commit install` âœ…

## config vscode ğŸ–¥ï¸

en cas de message `"Visual Studio Code is unable to watch for file changes in this large workspace" (error ENOSPC)` [see vscode linux page](https://code.visualstudio.com/docs/setup/linux#_visual-studio-code-is-unable-to-watch-for-file-changes-in-this-large-workspace-error-enospc) âš ï¸

```bash
# add fs.inotify.max_user_watches=524288 to /etc/sysctl.conf
sudo sysctl -p # to apply directly
cat /proc/sys/fs/inotify/max_user_watches # to control it is applied
```
  
or add `files.watcherExclude` directive in `.vscode/settings.json` ğŸ“

# pour utiliser ğŸš€

## ffmpeg ğŸï¸

ffmpeg is required to load audio files from filename for whisper use (transcription d'un mp3) ğŸ§

install, it is available in snap (4.3.1) ğŸ“¦

## locale FR ğŸ‡«ğŸ‡·

en cas d'erreur de type `locale.Error: unsupported locale setting` â—

verifier avec `locale -a` que `fr_FR.UTF-8` soit installÃ©e. ğŸ”

Sinon le faire avec 

```bash
sudo apt-get install language-pack-fr-base
locale -a
```

## ulimit âš™ï¸

j'ai du augmenter l'ulimit de mon systeme pour utiliser whisper pour eviter l'erreur `Too many open files` ğŸš«

Avec ce parametre je n'ai plus le probleme: `ulimit -n 4096` âœ”ï¸  
Je l'ai ajoute dans `.zshrc` ğŸ“

## `.env` ğŸŒ

https://pypi.org/project/python-dotenv/ ğŸ’¡

> Python-dotenv reads key-value pairs from a .env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles. ğŸ“‹

creer `.env` Ã  la racine du repo avec ğŸ—ï¸

### rss info ğŸ™ï¸

L'adresse du flux RSS du podcast du Masque et la Plume ğŸ§

si absent `https://radiofrance-podcast.net/podcast09/rss_14007.xml` est utilisÃ© par defaut ğŸ”„  

```
RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml
```

### web info ğŸŒ

Le lien vers la page web stockee du masque listant les episodes "legacy" historiques ğŸ“œ

si absent `db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html` est utilisÃ© par defaut ğŸ”„  

```
WEB_LMELP_FILENAME=db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html
```

### db info ğŸ—„ï¸

pour tout ce qui concerne la base mongo ğŸ›¢ï¸

```
DB_HOST=localhost # Ã  changer avec nas923 par exemple
DB_NAME="masque_et_la_plume"
DB_LOGS=true # si prÃ©sent et valant true, va enregistrer toutes les operations dans la collection logs
```

### llm, llamaindex ğŸ¤–

```
# gemini 
GEMINI_API_KEY=
# gemini vertex
GOOGLE_PROJECT_ID=
GOOGLE_AUTH_FILE=

# openai
OPENAI_API_KEY=

# azure openai
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_VERSION=
```

gemini llm, GEMINI_API_KEY dispo Ã  ğŸš€

from https://console.cloud.google.com/apis/credentials ğŸ”‘

gemini vertex (llamaindex), GOOGLE_PROJECT_ID ğŸ§­

from https://console.cloud.google.com ğŸŒ

gemini vertex (llamaindex), GOOGLE_AUTH_FILE ğŸ“‚

follow instructions at https://stackoverflow.com/a/69941050 ğŸ“˜

### SerpApi ğŸ”

to request search engines ğŸŒŸ

with

```text
SERP_API_KEY
```

## streamlit ğŸ–±ï¸

from vscode: palette > run task > run streamlit ğŸš€

or from terminal: `ui/lmelp_ui.sh` âš¡
