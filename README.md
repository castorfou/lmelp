- [pour developper ðŸ’»](#pour-developper-)
  - [environnements de dev python ðŸ](#environnements-de-dev-python-)
  - [pre-commit â±ï¸](#pre-commit-ï¸)
  - [config vscode ðŸ–¥ï¸](#config-vscode-ï¸)
  - [tests unitaires ðŸ§ª](#tests-unitaires-)
- [ðŸ˜€ Ã  propos de la doc](#-Ã -propos-de-la-doc)
- [pour utiliser ðŸš€](#pour-utiliser-)
  - [ðŸ’¾ base de donnÃ©es mongodb](#-base-de-donnÃ©es-mongodb)
  - [ffmpeg ðŸŽžï¸](#ffmpeg-ï¸)
  - [locale FR ðŸ‡«ðŸ‡·](#locale-fr-)
  - [ulimit âš™ï¸](#ulimit-ï¸)
  - [`.env` ðŸŒ](#env-)
    - [rss info ðŸŽ™ï¸](#rss-info-ï¸)
    - [web info ðŸŒ](#web-info-)
    - [db info ðŸ—„ï¸](#db-info-ï¸)
    - [llm, llamaindex, litellm ðŸ¤–](#llm-llamaindex-litellm-)
    - [websearch](#websearch)
  - [streamlit ðŸ–±ï¸](#streamlit-ï¸)


# pour developper ðŸ’»

## environnements de dev python ðŸ

vscode utilisera automatiquement le devcontainer definit dans le repo sous `.devcontainer`

je garde quand meme le script de creation d'environnement whisper depuis `envs/whisper.txt` âœ¨  qui contient ce qu il faut pour whisper, feedparser, transformers (huggingface), dotenv, mongo, streamlit ðŸ› ï¸

## pre-commit â±ï¸

dans devcontainer, pre-commit est deja configure sinon

`pre-commit install` âœ…

## config vscode ðŸ–¥ï¸

en cas de message `"Visual Studio Code is unable to watch for file changes in this large workspace" (error ENOSPC)` [see vscode linux page](https://code.visualstudio.com/docs/setup/linux#_visual-studio-code-is-unable-to-watch-for-file-changes-in-this-large-workspace-error-enospc) âš ï¸

```bash
# add fs.inotify.max_user_watches=524288 to /etc/sysctl.d/99-custom-inotify.conf
sudo sysctl -p # to apply directly
cat /proc/sys/fs/inotify/max_user_watches # to control it is applied
```
  
or add `files.watcherExclude` directive in `.vscode/settings.json` ðŸ“

pour quelques astuces liÃ©es Ã  vscode : [Vscode hints (sur github pages)](https://castorfou.github.io/lmelp/readme_vscode_hints/)

## tests unitaires ðŸ§ª

Le projet utilise **pytest** pour les tests unitaires avec une couverture de code Ã©levÃ©e.

**Infrastructure CI/CD :**
- âœ… **GitHub Actions** : Tests automatiques sur chaque push/PR
- âœ… **DÃ©pendances optimisÃ©es** : `tests/requirements.txt` (sans PyTorch/ML)
- âœ… **Mocking avancÃ©** : torch, transformers, dbus mockÃ©s pour CI/CD
- âœ… **Coverage 72%+** : Couverture actuelle avec 214 tests
- âœ… **Linting automatique** : flake8, black, isort

```bash
# Lancer tous les tests
pytest

# Tests avec couverture 
pytest --cov=nbs --cov-report=term-missing

# Tests spÃ©cifiques
pytest tests/unit/test_config.py -v
```

**Structure des tests :**
- `tests/unit/` : Tests unitaires par module
- `tests/fixtures/` : DonnÃ©es de test et utilitaires
- `tests/requirements.txt` : **DÃ©pendances minimales pour tests**
- `tests/conftest.py` : Configuration et fixtures globales
- `.env.test` : Variables d'environnement de test
- `.github/workflows/tests.yml` : **CI/CD GitHub Actions**

**Documentation complÃ¨te :** [Guide des tests unitaires](https://castorfou.github.io/lmelp/readme_unit_test/) ðŸ“‹

# ðŸ˜€ Ã  propos de la doc

on change la doc depuis `docs` (gÃ©nie) ðŸ˜Š

- APIs ðŸš€
- Quelques astuces ou choix de conception ðŸ”

Mkdocs+github actions ramasse tout cela (branche main uniquement) et publie sur le [github pages du projet](https://castorfou.github.io/lmelp/) ðŸ“¦

ExpliquÃ© Ã  https://castorfou.github.io/lmelp/readme_doc/ ðŸ‘


# pour utiliser ðŸš€

## ðŸ’¾ base de donnÃ©es mongodb

mongodb est utilisÃ©e pour conserver toutes les donnÃ©es de l'application ([voir schÃ©ma](https://castorfou.github.io/lmelp/readme_data_model/)). ðŸ“Š  
pour conserver une sauvegarde de la base, lancer depuis devcontainer `scripts/backup_mongodb.sh` ðŸš€

si les liens ont Ã©tÃ© faits dans `~/bin/lmelp`, alors lancer depuis host `~/bin/lmelp/backup_mongodb.sh`

penser Ã  le faire rÃ©guiliÃ©rement, il n'y a aucun rappel.

## ffmpeg ðŸŽžï¸

ffmpeg is required to load audio files from filename for whisper use (transcription d'un mp3) ðŸŽ§

install, it is available in snap (4.3.1) ðŸ“¦

## locale FR ðŸ‡«ðŸ‡·

en cas d'erreur de type `locale.Error: unsupported locale setting` â—

verifier avec `locale -a` que `fr_FR.UTF-8` soit installÃ©e. ðŸ”

Sinon le faire avec 

```bash
sudo apt-get install language-pack-fr-base
locale -a
```

## ulimit âš™ï¸

j'ai du augmenter l'ulimit de mon systeme pour utiliser whisper pour eviter l'erreur `Too many open files` ðŸš«

Avec ce parametre je n'ai plus le probleme: `ulimit -n 4096` âœ”ï¸  
Je l'ai ajoute dans `.zshrc` ðŸ“

## `.env` ðŸŒ

https://pypi.org/project/python-dotenv/ ðŸ’¡

> Python-dotenv reads key-value pairs from a .env file and can set them as environment variables. It helps in the development of applications following the 12-factor principles. ðŸ“‹

creer `.env` Ã  la racine du repo avec ðŸ—ï¸

### rss info ðŸŽ™ï¸

L'adresse du flux RSS du podcast du Masque et la Plume ðŸŽ§

si absent `https://radiofrance-podcast.net/podcast09/rss_14007.xml` est utilisÃ© par defaut ðŸ”„  

```
RSS_LMELP_URL=https://radiofrance-podcast.net/podcast09/rss_14007.xml
```

### web info ðŸŒ

Le lien vers la page web stockee du masque listant les episodes "legacy" historiques ðŸ“œ

si absent `db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html` est utilisÃ© par defaut ðŸ”„  

```
WEB_LMELP_FILENAME=db/Ã€ Ã©couter plus tard I Radio France/Ã€ Ã©couter plus tard I Radio France.html
```

### db info ðŸ—„ï¸

pour tout ce qui concerne la base mongo ðŸ›¢ï¸

```
DB_HOST=localhost # Ã  changer avec nas923 par exemple
DB_NAME="masque_et_la_plume"
DB_LOGS=true # si prÃ©sent et valant true, va enregistrer toutes les operations dans la collection logs
```

### llm, llamaindex, litellm ðŸ¤–

```
# gemini 
GEMINI_API_KEY=
# gemini vertex
GOOGLE_PROJECT_ID=
GOOGLE_AUTH_FILE=

# openai
OPENAI_API_KEY=

# azure openai
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_VERSION=
```

gemini llm, GEMINI_API_KEY dispo Ã  ðŸš€

from https://console.cloud.google.com/apis/credentials ðŸ”‘

gemini vertex (llamaindex), GOOGLE_PROJECT_ID ðŸ§­

from https://console.cloud.google.com ðŸŒ

gemini vertex (llamaindex), GOOGLE_AUTH_FILE ðŸ“‚

follow instructions at https://stackoverflow.com/a/69941050 ðŸ“˜

Et pour les modeles locaux **LiteLLM**
```
LITELLM_API_KEY
```

### websearch

We need these 2 keys.

```GOOGLE_CUSTOM_SEARCH_API_KEY

SEARCH_ENGINE_ID
```

more details at [readme Google](docs/readme_google.md)

## streamlit ðŸ–±ï¸

3 ways to run it: from vscode, from devcontainer, from host

from **vscode**: palette > run task > run streamlit ðŸš€

from **devcontainer** terminal: `ui/lmelp_ui.sh` âš¡

from **host** terminal: 

```bash
#!/bin/bash 

source ~/git/lmelp/scripts/from_host/get_container.sh

container=$(get_container)
echo "Using container: $container"

# Execute the UI script in the found container as the user vscode.
docker exec -u vscode "$container" /workspaces/lmelp/ui/lmelp_ui.sh
```