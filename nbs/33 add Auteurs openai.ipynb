{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "je vais manipuler des noms d'auteurs que je vais extraire d'une transcription. la transcription a ete cree a partir d'un enregistrement audio donc le risque est d'avoir des erreurs dans l'orthographe de cet auteur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for Author Name Handling System\n",
    "- Create a class to handle author names with fuzzy matching\n",
    "- Store reference names in a dictionary/database\n",
    "- Implement fuzzy string matching using Levenshtein distance\n",
    "- Add methods to suggest corrections for misspelled names\n",
    "- Include confidence scoring for matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self, reference_authors: List[str] = None):\n",
    "        \"\"\"Initialize with a list of known author names\"\"\"\n",
    "        self.reference_authors = set(reference_authors) if reference_authors else set()\n",
    "\n",
    "    def add_reference_author(self, author: str) -> None:\n",
    "        \"\"\"Add a new reference author to the set\"\"\"\n",
    "        self.reference_authors.add(author.strip())\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Find the best matching reference author for a given name\n",
    "        Returns: (best_match, score)\n",
    "        \"\"\"\n",
    "        if not name or not self.reference_authors:\n",
    "            return None, 0\n",
    "\n",
    "        # Find best match using token set ratio for better partial matching\n",
    "        best_match, score = process.extractOne(\n",
    "            name, self.reference_authors, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        if not name or not self.reference_authors:\n",
    "            return []\n",
    "\n",
    "        # Get top N matches with scores\n",
    "        matches = process.extract(\n",
    "            name, self.reference_authors, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with some reference authors\n",
    "    reference_authors = [\n",
    "        \"Victor Hugo\",\n",
    "        \"Albert Camus\",\n",
    "        \"Simone de Beauvoir\",\n",
    "        \"Marcel Proust\",\n",
    "        \"Ã‰mile Zola\",\n",
    "    ]\n",
    "\n",
    "    matcher = AuthorMatcher(reference_authors)\n",
    "\n",
    "    # Test with a misspelled name\n",
    "    test_name = \"Viktor Hugo\"\n",
    "    best_match, score = matcher.find_best_match(test_name)\n",
    "    print(f\"Input: {test_name}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "\n",
    "    # Get suggestions\n",
    "    suggestions = matcher.suggest_corrections(test_name)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pas mal mais l'inconvenient c'est qu'il faut les auteurs de reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avec un llm pour obtenir la liste d'auteurs de reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import get_azure_llm\n",
    "\n",
    "llm = get_azure_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(\"Explain how AI works\")\n",
    "print(response.text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, ChatResponse\n",
    "import json\n",
    "\n",
    "llm = get_azure_llm(\"gpt-4o-mini\")\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"AuthorList\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Authors_by_Guillaume\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A list of authors' names\",\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"Authors_by_Guillaume\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def get_authors_json(query):\n",
    "    response = llm.chat(\n",
    "        messages=[\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=\"You are a helpful assistant that returns a JSON list of strings.\",\n",
    "            ),\n",
    "            # ChatMessage(role=\"user\", content=f\"{query}. Please provide the response in JSON format as a list of strings, following this schema: ['author1', 'author2', ...]\")\n",
    "            ChatMessage(role=\"user\", content=f\"{query}. \"),\n",
    "        ],\n",
    "        response_format=response_schema,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "query = \"List 5 famous science fiction authors\"\n",
    "json_response = get_authors_json(query)\n",
    "\n",
    "# print(\"Raw response:\", json_response)  # Debug\n",
    "\n",
    "try:\n",
    "    json_dict = json.loads(json_response.message.content)\n",
    "    # ...\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    print(\"Raw response:\", json_response)\n",
    "json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, ChatResponse\n",
    "import json\n",
    "\n",
    "llm = get_azure_llm(\"gpt-4o-mini\")\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"AuthorList\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Authors_by_Guillaume\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A list of authors' names\",\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"Authors_by_Guillaume\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def get_authors_json(query):\n",
    "    response = llm.chat(\n",
    "        messages=[\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=\"You are a helpful assistant that returns a JSON list of strings.\",\n",
    "            ),\n",
    "            # ChatMessage(role=\"user\", content=f\"{query}. Please provide the response in JSON format as a list of strings, following this schema: ['author1', 'author2', ...]\")\n",
    "            ChatMessage(role=\"user\", content=f\"{query}. \"),\n",
    "        ],\n",
    "        response_format=response_schema,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "query = \"List 5 famous science fiction authors\"\n",
    "json_response = get_authors_json(query)\n",
    "\n",
    "# print(\"Raw response:\", json_response)  # Debug\n",
    "\n",
    "try:\n",
    "    json_dict = json.loads(json_response.message.content)\n",
    "    # ...\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error parsing JSON:\", e)\n",
    "    print(\"Raw response:\", json_response)\n",
    "json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_azure_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self, cache_file: str = \"french_authors_cache.json\"):\n",
    "        \"\"\"Initialize with gemini client and cache\"\"\"\n",
    "        self.client = get_azure_llm()\n",
    "        self.cache_file = Path(cache_file)\n",
    "        self.reference_authors = self._load_or_fetch_authors()\n",
    "\n",
    "    def _load_or_fetch_authors(self) -> List[str]:\n",
    "        \"\"\"Load authors from cache or fetch from OpenAI\"\"\"\n",
    "        if self.cache_file.exists():\n",
    "            with open(self.cache_file, \"r\") as f:\n",
    "                return json.load(f)\n",
    "\n",
    "        # Fetch from OpenAI if cache doesn't exist\n",
    "        prompt = \"\"\"\n",
    "        You are a literary expert assistant.\n",
    "\n",
    "        Give me a list of 100 important French authors, including contemporary ones, \n",
    "        that might be discussed in \"Le Masque et la Plume\". \n",
    "        Return only a JSON array of names, no other text.\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.client.complete(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        # complete avec la logique de cache\n",
    "        with open(self.cache_file, \"w\") as f:\n",
    "            json.dump(authors, f)\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference author\"\"\"\n",
    "        if not name:\n",
    "            return None, 0\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            name, self.reference_authors, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        return process.extract(\n",
    "            name, self.reference_authors, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "\n",
    "def test_auteur(autor):\n",
    "    matcher = AuthorMatcher()\n",
    "    best_match, score = matcher.find_best_match(autor)\n",
    "    print(f\"Input: {autor}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "    suggestions = matcher.suggest_corrections(autor)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")\n",
    "\n",
    "\n",
    "test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le probleme c'est que si j'utilise un auteur moins connu qui n'est pas dans les 100 ca ne va pas marcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auteur(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et avec des accents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auteur(\"Gael Faye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca ca marche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avec un llm pour retourner les auteurs dont le nom ressemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_azure_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with gemini client\"\"\"\n",
    "        self.client = get_azure_llm()\n",
    "\n",
    "    def _fetch_author(self, autor) -> List[str]:\n",
    "        \"\"\"fetch from gemini\"\"\"\n",
    "\n",
    "        # Fetch from gemini\n",
    "        prompt = (\n",
    "            \"\"\"\n",
    "        Tu es un agent expert en littÃ©rature.\n",
    "        Donne moi quelques auteurs dont le nom s'approche de celui-ci : \"\"\"\n",
    "            + autor\n",
    "            + \"\"\"\n",
    "\n",
    "        S'il s'agit deja d'un auteur connu, retourne moi juste son nom. S'il y a une erreur dans le nom que je t'ai donne, corrige moi en me donnant le nom de l'auteur que tu penses que j'ai voulu dire.\n",
    "\n",
    "        Je veux que tu me donnes le prenom puis le nom dans cet ordre. Par exemple \"Marcel Pagnol\" ou \"Victor Hugo\".\n",
    "        Ces auteurs sont susceptibles d'etre discutes dans \"Le Masque et la Plume\".\n",
    "\n",
    "        Si tu me retournes plusieurs auteurs, fais le sous forme de liste par exemple si tu as identifie \"auteur 1\" et \"auteur 2\" alors retourne [\"auteur 1\", \"auteur 2\"]\n",
    "\n",
    "        Retourne uniquement un tableau JSON de noms, pas de texte supplÃ©mentaire.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        response = self.client.complete(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference author\"\"\"\n",
    "        if not name:\n",
    "            return None, 0\n",
    "\n",
    "        fetch_author = self._fetch_author(name)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return None, 0\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            name, fetch_author, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        fetch_author = self._fetch_author(name)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return []\n",
    "        return process.extract(\n",
    "            name, fetch_author, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "\n",
    "def test_auteur(autor):\n",
    "    matcher = AuthorMatcher()\n",
    "    best_match, score = matcher.find_best_match(autor)\n",
    "    print(f\"Input: {autor}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "    suggestions = matcher.suggest_corrections(autor)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")\n",
    "\n",
    "\n",
    "test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auteur(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "est-ce que ca marche avec des auteurs recents ? premiers romans ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auteur(\"Jeanne RiviÃ¨re\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = AuthorMatcher()\n",
    "matcher._fetch_author(\"Jeanne RiviÃ¨re\")\n",
    "# matcher._fetch_author(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca ne marche pas du tout avec les auteurs recents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# en fournissant la description de l'episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on va tester avec l'episode du 26 janvier 2025 \n",
    "\n",
    "et \"Jeanne RiviÃ¨re\" qui vient d'ecrire son 1er roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mongo_episode import Episode\n",
    "import datetime\n",
    "\n",
    "episode_26janv2025 = Episode.from_date(datetime.date(2025, 1, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_26janv2025.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_azure_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorEpisodeMatcher:\n",
    "    def __init__(self, episode: Episode):\n",
    "        \"\"\"un agent qui va verifier les auteurs d'un episode\n",
    "        episode : episode qui contient notamment un titre et une description\n",
    "        \"\"\"\n",
    "        self.client = get_azure_llm()\n",
    "        self.episode = episode\n",
    "\n",
    "    def _potentiels_auteurs(self, auteur: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        on cherche avec llm une liste de potentiels auteurs qui pourraient correspondre Ã  l'auteur donnÃ©\n",
    "        auteur : ce qu'on cherche\n",
    "\n",
    "        cette liste sera utilise par find_best_match pour trouver le meilleur match\n",
    "        \"\"\"\n",
    "\n",
    "        description = (\n",
    "            \" titre : \" + self.episode.titre\n",
    "        )  # + \" \\n description : \" + self.episode.description\n",
    "\n",
    "        # prompt pour llm\n",
    "        prompt = (\n",
    "            \"\"\"\n",
    "        Tu es un agent expert en littÃ©rature.\n",
    "\n",
    "        J'ai entendu parler d'un auteur evoque dans un episode du \"Masque et la Plume\" dont le nom ressemble Ã  celui-ci : \"\"\"\n",
    "            + auteur\n",
    "            + \"\"\"\n",
    "\n",
    "        Je dis ressemble parce que j'ai entendu le nom Ã  la radio et je ne suis pas sÃ»r de l'orthographe exacte de son nom.\n",
    "\n",
    "        J'ai aussi le titre et lq description de cet episode du \"Masque et la Plume\" qui peuvent t'aider Ã  trouver cet auteur. \n",
    "        Les voici : \"\"\"\n",
    "            + description\n",
    "            + \"\"\"\n",
    "\n",
    "        Il est possible que le nom apparaisse dans le titre ou la description, dans ce cas utilise le car ces sources sont plus fiables que le nom que je t'ai donne.\n",
    "        \n",
    "        Cependant il est possible que le nom n'y apparaisse pas, dans ce cas recherche dans ce que tu connais en tant qu'expert en littÃ©rature.\n",
    "        \n",
    "        S'il s'agit deja d'un auteur que tu connaissais, retourne moi juste son nom. S'il y a une erreur dans le nom que je t'ai donne, corrige moi en me donnant le nom de l'auteur que tu penses que j'ai voulu dire.\n",
    "\n",
    "        Je veux que tu me donnes le prenom puis le nom dans cet ordre. Par exemple \"Marcel Pagnol\" ou \"Victor Hugo\".\n",
    "\n",
    "        Si tu me retournes plusieurs auteurs car tu as des doutes, fais le sous forme de liste par exemple si tu as identifie \"auteur 1\" et \"auteur 2\" alors retourne [\"auteur 1\", \"auteur 2\"]\n",
    "\n",
    "        Retourne uniquement un tableau JSON de noms, pas de texte supplÃ©mentaire.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        response = self.client.complete(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, auteur: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference auteur\n",
    "        en utilisant thefuzz process.extractOne\n",
    "\n",
    "        retourne None, 0 si aucun auteur n'est renseignÃ©\n",
    "        retourne None, -1 si aucun auteur de reference n'est trouvÃ©\n",
    "        retourne None, score si le score est inferieur Ã  min_score\n",
    "\n",
    "        et sinon retourne le meilleur match et son score\n",
    "\n",
    "        Returns: (best_match, score)\n",
    "        \"\"\"\n",
    "        if not auteur:\n",
    "            return None, 0\n",
    "\n",
    "        fetch_author = self._potentiels_auteurs(auteur)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return None, -1\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            auteur, fetch_author, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def test_auteur(self, autor):\n",
    "        best_match, score = self.find_best_match(autor)\n",
    "        print(f\"Input: {autor}\")\n",
    "        print(f\"fetch autors : {self._potentiels_auteurs(autor)}\")\n",
    "        print(f\"Best match: {best_match} (score: {score})\")\n",
    "        return best_match, score\n",
    "\n",
    "\n",
    "matcher_26janv2025 = AuthorEpisodeMatcher(episode_26janv2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_26janv2025.test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_26janv2025.test_auteur(\"Jeanne RiviÃ¨re\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_26janv2025.test_auteur(\"Jeanne Riviere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c'est pas parfait c'est le cote un peu schostastique du llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essayons avec la transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = episode_26janv2025.transcription\n",
    "\n",
    "prompt_transcription = f\"\"\"\n",
    "\n",
    "Je vais te donner la transcription d'un episode d'une emission de radio qui s'appelle le masque et la plume sur France Inter.\n",
    "Cet episode dure 1h et porte sur des livres. Il y a des intervenants qui parlent des livres qu'ils ont lus. Ils ne sont parfois pas d'accord.\n",
    "\n",
    "Voici la transcription:\n",
    "{transcription}\n",
    "\n",
    "Je veux que tu identifies l'ensemble des livres dont on parle dans cette emission.\n",
    "Et que tu me restitues cette liste de livres en separant auteur et titre. Si l'editeur est mentionne tu peux aussi le noter.\n",
    "\n",
    "Tu me restitueras cette liste sous la forme d'un tableau au format markdown. Avec une colonne pour l'auteur, une colonne pour le titre et une colonne pour l'editeur si il est mentionne.\n",
    "\n",
    "Et tu me donneras une lsite au format python des auteurs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_azure_llm()\n",
    "\n",
    "llm.complete(prompt_transcription).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Voici le tableau markdown listant les livres mentionnÃ©s dans l\\'Ã©mission, avec auteur, titre et Ã©diteur :\\n\\n\n",
    "\n",
    "| Auteur             | Titre                         | Ã‰diteur           |\n",
    "|----------------------|---------------------------------|--------------------|\n",
    "| Haruki Murakami     | La CitÃ© aux murs incertains      |                    |\n",
    "| Constantin Alexandrakis | L\\'HospitalitÃ© au dÃ©mon         |                    |\n",
    "| Leila Slimani        | J\\'emporterai le feu            | Gallimard          |\n",
    "| Nathalie Azoulay     | Toutes les vies de ThÃ©o        | POL                |\n",
    "| Johann Svar          | (Titre non spÃ©cifiÃ©)            |                    |\n",
    "| Pierre Lemaitre     | Un avenir radieux              | Calmann LÃ©vy       |\n",
    "| Jeanne RiviÃ¨re       | Lorraine Brulle                | Gallimard (collection Signe) |\n",
    "| Milena Agus          | Le vent passe et la nuit aussi | Liana LÃ©vy         |\n",
    "| Christian Laval      | Marx en AmÃ©rique               | Chambon             |\n",
    "| Guillaume Lebrun     | RavagÃ© de splendeur            | Bourgois           |\n",
    "| Sally Rooney         | Normal People                  | Livre de Poche     |\n",
    "| Jean-Patrick Manchette | (Titre non spÃ©cifiÃ©, biographie)| Gallimard          |\n",
    "| Bob Dylan            | (Titre non spÃ©cifiÃ©, biographie)|                    |\n",
    "\n",
    "\n",
    "Voici la liste des auteurs au format Python\n",
    "\n",
    "```python\n",
    "auteurs = [\"Haruki Murakami\", \"Constantin Alexandrakis\", \"Leila Slimani\", \"Nathalie Azoulay\", \"Johann Svar\", \"Pierre Lemaitre\", \"Jeanne RiviÃ¨re\", \"Milena Agus\", \"Christian Laval\", \"Guillaume Lebrun\", \"Sally Rooney\", \"Jean-Patrick Manchette\", \"Bob Dylan\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auteurs = [\n",
    "    \"Haruki Murakami\",\n",
    "    \"Constantin Alexandrakis\",\n",
    "    \"Leila Slimani\",\n",
    "    \"Nathalie Azoulay\",\n",
    "    \"Johann Svar\",\n",
    "    \"Pierre Lemaitre\",\n",
    "    \"Jeanne RiviÃ¨re\",\n",
    "    \"Milena Agus\",\n",
    "    \"Christian Laval\",\n",
    "    \"Guillaume Lebrun\",\n",
    "    \"Sally Rooney\",\n",
    "    \"Jean-Patrick Manchette\",\n",
    "    \"Bob Dylan\",\n",
    "]\n",
    "\n",
    "auteurs_corrects = []\n",
    "auteurs_inconnus = []\n",
    "\n",
    "for auteur in auteurs:\n",
    "    best_match, score = matcher_26janv2025.test_auteur(auteur)\n",
    "    if score >= 80:\n",
    "        auteurs_corrects.append(best_match)\n",
    "    else:\n",
    "        auteurs_inconnus.append(auteur)\n",
    "\n",
    "print(\"Auteurs corrects : \", auteurs_corrects)\n",
    "print(\"Auteurs inconnus : \", auteurs_inconnus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from llm import load_env\n",
    "import os\n",
    "\n",
    "load_env()\n",
    "serpapi_key = os.getenv(\"SERP_API_KEY\")\n",
    "\n",
    "params = {\n",
    "    \"api_key\": serpapi_key,\n",
    "    \"engine\": \"google\",\n",
    "    \"q\": auteurs_inconnus[0],\n",
    "    \"location\": \"Paris, France\",\n",
    "    \"google_domain\": \"google.com\",\n",
    "    \"gl\": \"fr\",\n",
    "    \"hl\": \"fr\",\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_incertitude_auteur = f\"\"\"\n",
    "\n",
    "Voici le resultat d'une requete google concernant un probable auteur inconnu de mon llm : {auteurs_inconnus[0]}\n",
    "\n",
    "La requete est au format dict avec du json a l'interieur.\n",
    "\n",
    "Est-ce que tu peux analyser le contenu de cette requete et me dire si oui ou non {auteurs_inconnus[0]} est un auteur de livres, et accompagner ta reponse d'un pourcentage de certitude\n",
    "\n",
    "100% de certitude signifie que tu es certain que {auteurs_inconnus[0]} est un auteur de livres\n",
    "\n",
    "50% tu es ni sure ni pas sure que {auteurs_inconnus[0]} est un auteur de livres\n",
    "\n",
    "0% tu es certain que {auteurs_inconnus[0]} n'est pas un auteur de livres\n",
    "\n",
    "Voici le contenu de la requete google : {results}\n",
    "\n",
    "\n",
    "Tu repondras uniquement avec un dictionnaire qui va contenir 3 entrees :\n",
    "\n",
    "- \"auteur\" : le nom de l'auteur, eventuellement corrige si j'ai oublie des accents ou une faute de frappe\n",
    "- \"certitude\" : le pourcentage de certitude de 0 Ã  100, un entier\n",
    "- \"analyse\" : une analyse de la requete google\n",
    "\n",
    "je ne veux pas d'autres choses que ce dictionnaire car je veux utiliser telle quelle ta reponse pour la suite de mon programme ecrit en python\n",
    "\n",
    "ca veut dire que tu dois commencer ta reponse par un \"{\" et la terminer par un \"}\" et que tu ne dois pas ajouter de texte supplementaire\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "answer = llm.complete(prompt_incertitude_auteur).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "answer_dict = ast.literal_eval(answer)\n",
    "answer_dict[\"certitude\"], answer_dict[\"auteur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from llm import load_env\n",
    "import os\n",
    "\n",
    "load_env()\n",
    "api_key = os.getenv(\"GOOGLE_CUSTOM_SEARCH_API_KEY\")\n",
    "cse_id = os.getenv(\"SEARCH_ENGINE_ID\")\n",
    "\n",
    "if not api_key or not cse_id:\n",
    "    raise ValueError(\n",
    "        \"Les variables d'environnement GOOGLE_SEARCH_API_KEY et GOOGLE_CSE_ID doivent Ãªtre dÃ©finies.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Fonction de recherche Google\n",
    "def google_search(query):\n",
    "    try:\n",
    "        service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "        res = service.cse().list(q=query, cx=cse_id).execute()\n",
    "\n",
    "        results = []\n",
    "        for item in res.get(\"items\", []):\n",
    "            title = item.get(\"title\")\n",
    "            snippet = item.get(\"snippet\")\n",
    "            link = item.get(\"link\")\n",
    "            results.append({\"title\": title, \"snippet\": snippet, \"link\": link})\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche Google: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "user_query = auteurs_inconnus[0]\n",
    "response = google_search(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = google_search(auteurs_inconnus[0])\n",
    "\n",
    "prompt_incertitude_auteur = f\"\"\"\n",
    "\n",
    "Voici le resultat d'une requete google concernant un probable auteur inconnu de mon llm : {auteurs_inconnus[0]}\n",
    "\n",
    "La requete est au format dict avec du json a l'interieur.\n",
    "\n",
    "Est-ce que tu peux analyser le contenu de cette requete et me dire si oui ou non {auteurs_inconnus[0]} est un auteur de livres, et accompagner ta reponse d'un pourcentage de certitude\n",
    "\n",
    "100% de certitude signifie que tu es certain que {auteurs_inconnus[0]} est un auteur de livres\n",
    "\n",
    "50% tu es ni sure ni pas sure que {auteurs_inconnus[0]} est un auteur de livres\n",
    "\n",
    "0% tu es certain que {auteurs_inconnus[0]} n'est pas un auteur de livres\n",
    "\n",
    "Voici le contenu de la requete google : {results}\n",
    "\n",
    "\n",
    "Tu repondras uniquement avec un dictionnaire qui va contenir 3 entrees :\n",
    "\n",
    "- \"auteur\" : le nom de l'auteur, eventuellement corrige si j'ai oublie des accents ou une faute de frappe\n",
    "- \"certitude\" : le pourcentage de certitude de 0 Ã  100, un entier\n",
    "- \"analyse\" : une analyse de la requete google\n",
    "\n",
    "je ne veux pas d'autres choses que ce dictionnaire car je veux utiliser telle quelle ta reponse pour la suite de mon programme ecrit en python\n",
    "\n",
    "ca veut dire que tu dois commencer ta reponse par un \"{\" et la terminer par un \"}\" et que tu ne dois pas ajouter de texte supplementaire\n",
    "\"\"\"\n",
    "\n",
    "answer = llm.complete(prompt_incertitude_auteur).text\n",
    "\n",
    "import ast\n",
    "\n",
    "answer_dict = ast.literal_eval(answer)\n",
    "answer_dict[\"certitude\"], answer_dict[\"auteur\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# synthese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specification algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bon on va partir d'un episode\n",
    "\n",
    "On va demander a un agent de sortir tous les livres et auteurs (on ne va pas regarder les auteurs mentionnes sans livres) mentionnes dans la transcription\n",
    "\n",
    "Et le jeu est d'avoir la bonne orthographe pour les auteurs : on va donc pour chaque auteur identifie\n",
    "\n",
    "- E1 - on extrait tous les noms de titre + description sous forme de liste avec gpt-4o-mini avec structure_response\n",
    "\n",
    "- si l'auteur est dans la liste (thefuzz, on arrete)\n",
    "\n",
    "- sinon on extrait tous les auteurs de la table Auteurs sous forme de liste\n",
    "\n",
    "- si l'auteur est dans la liste (thefuzz, on arrete)\n",
    "\n",
    "- sinon (parce que tout simplement l'auteur n'apparait pas dans titre ou description, surout sur les vieux episodes) on retourne une liste d'auteurs ressemblants en utilisant gpt-4o-mini avec structure_response\n",
    "\n",
    "- si l'auteur est dans la liste (thefuzz, on arrete)\n",
    "\n",
    "- sinon (peut-etre que l'auteur n'etait pas connu au moment de la creation du modele gpt-4o-mini) on fait une recherche sous google avec cet auteur inconnu et en analysant la reponse avec gpt-4o-mini avec structure_response, et on demande un niveau de certitude sur le fait que cet auteur inconnu est rellement un auteur.\n",
    "\n",
    "- si la certitude est forte, GO\n",
    "\n",
    "- sinon cet auteur sera ignore.\n",
    "\n",
    "Si l'auteur n'est pas ignore, alors on peut instancier AuteurDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AuthorChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from typing import List, Tuple\n",
    "\n",
    "score_fuzz_threshold = 80\n",
    "\n",
    "\n",
    "class AuthorFuzzMatcher:\n",
    "    def __init__(self, reference_authors: List[str] = None):\n",
    "        \"\"\"Initialize with a list of known author names\"\"\"\n",
    "        self.reference_authors = set(reference_authors) if reference_authors else set()\n",
    "\n",
    "    def add_reference_author(self, author: str) -> None:\n",
    "        \"\"\"Add a new reference author to the set\"\"\"\n",
    "        self.reference_authors.add(author.strip())\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Find the best matching reference author for a given name\n",
    "        Returns: (best_match, score)\n",
    "        \"\"\"\n",
    "        if not name or not self.reference_authors:\n",
    "            return None, 0\n",
    "        # Find best match using token set ratio for better partial matching\n",
    "        best_match, score = process.extractOne(\n",
    "            name, self.reference_authors, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mongo import Auteur\n",
    "from mongo_episode import Episode\n",
    "from llm import get_azure_llm\n",
    "from llama_index.core.llms import ChatMessage, ChatResponse\n",
    "import json\n",
    "\n",
    "\n",
    "class AuthorChecker:\n",
    "\n",
    "    def __init__(self, episode: Episode):\n",
    "        self.episode = episode\n",
    "        self.llm_structured_output = get_azure_llm(\"gpt-4o-mini\")\n",
    "        self.llm = get_azure_llm()\n",
    "        self.authors_titre_description = self._get_authors_from_titre_description()\n",
    "\n",
    "    def _get_authors_from_titre_description(self):\n",
    "        response_schema = {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"AuthorTitreDescriptionList\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"Authors_TitreDescription\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"A list of names from title and description\",\n",
    "                            },\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"Authors_TitreDescription\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        response = self.llm_structured_output.chat(\n",
    "            messages=[\n",
    "                ChatMessage(\n",
    "                    role=\"system\",\n",
    "                    content=\"Tu es un assistant utile qui retourne une liste JSON de noms.\",\n",
    "                ),\n",
    "                ChatMessage(\n",
    "                    role=\"user\",\n",
    "                    content=f\"Est-ce que tu peux me lister tous les noms \\\n",
    "                            qui sont citÃ©s dans le titre et la description de l'Ã©pisode suivant : \\\n",
    "                            {self.episode.titre} {self.episode.description}. \",\n",
    "                ),\n",
    "            ],\n",
    "            response_format=response_schema,\n",
    "        )\n",
    "        try:\n",
    "            json_dict = json.loads(response.message.content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error parsing JSON:\", e)\n",
    "            print(\"Raw response:\", json_response)\n",
    "        return json_dict[\"Authors_TitreDescription\"]\n",
    "\n",
    "    def _check_author_source(\n",
    "        self, author: str, authors_list: list[str], method: str\n",
    "    ) -> str | None:\n",
    "        \"\"\"Try to match 'author' against 'authors_list', return best match or None.\"\"\"\n",
    "        matcher = AuthorFuzzMatcher(authors_list)\n",
    "        best_match, score = matcher.find_best_match(author)\n",
    "        if score >= score_fuzz_threshold:\n",
    "            print(f\"TrouvÃ© dans {method}: {best_match}\")\n",
    "            return best_match\n",
    "        else:\n",
    "            print(f\"Non trouvÃ© dans {method}: {author}\")\n",
    "            return None\n",
    "\n",
    "    def check_author(self, author: str) -> str | None:\n",
    "        \"\"\"Check 'author' against both 'titre et description' and known DB authors.\"\"\"\n",
    "        # First, check titre et description\n",
    "        match = self._check_author_source(\n",
    "            author, self.authors_titre_description, \"titre et description\"\n",
    "        )\n",
    "        if match:\n",
    "            return match\n",
    "\n",
    "        # Then, check DB\n",
    "        list_db_auteurs = [auteur.nom for auteur in Auteur.get_entries()]\n",
    "        match = self._check_author_source(\n",
    "            author, list_db_auteurs, \"Auteurs DB (deja connus)\"\n",
    "        )\n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "episode_date = datetime.date(2025, 1, 26)\n",
    "author = \"Jeanne Riviere\"\n",
    "\n",
    "ac = AuthorChecker(Episode.from_date(episode_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrouvÃ© dans titre et description: Jeanne RiviÃ¨re\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jeanne RiviÃ¨re'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.check_author(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non trouvÃ© dans titre et description: Marcel Prout\n",
      "TrouvÃ© dans Auteurs DB (deja connus): Marcel Proust\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Marcel Proust'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je suis drole\n",
    "ac.check_author(\"Marcel Prout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
