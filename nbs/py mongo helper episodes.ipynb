{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp mongo_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6786a219ff4d877f74aaf512'), 'operation': 'update', 'entite': 'episodes', 'desc': '22 Dec 2024 10:59 - Les nouvelles pages de Marc Dugain, Emmanuelle Lambert, Emil Ferris, Fabrice Caro et Mathieu Palain', 'date': datetime.datetime(2025, 1, 14, 18, 42, 49, 496000)}\n",
      "{'_id': ObjectId('6786a210ff4d877f74aaf50c'), 'operation': 'insert', 'entite': 'episodes', 'desc': '12 Jan 2025 10:59 - Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...', 'date': datetime.datetime(2025, 1, 14, 18, 42, 40, 679000)}\n",
      "{'_id': ObjectId('6786a1d1de806a34f3f18d03'), 'operation': 'update', 'entite': 'episodes', 'desc': '22 Dec 2024 10:59 - Les nouvelles pages de Marc Dugain, Emmanuelle Lambert, Emil Ferris, Fabrice Caro et Mathieu Palain', 'date': datetime.datetime(2025, 1, 14, 18, 41, 37, 722000)}\n",
      "{'_id': ObjectId('6786a1c5de806a34f3f18cfd'), 'operation': 'insert', 'entite': 'episodes', 'desc': '12 Jan 2025 10:59 - Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...', 'date': datetime.datetime(2025, 1, 14, 18, 41, 25, 790000)}\n",
      "{'_id': ObjectId('6786a1abde806a34f3f18cfa'), 'operation': 'update', 'entite': 'episodes', 'desc': '12 Jan 2025 10:59 - Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...', 'date': datetime.datetime(2025, 1, 14, 18, 40, 59, 533000)}\n"
     ]
    }
   ],
   "source": [
    "from mongo import print_logs\n",
    "\n",
    "print_logs(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Episode entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "import os\n",
    "from git import Repo\n",
    "\n",
    "AUDIO_PATH = \"audios\"\n",
    "\n",
    "\n",
    "def get_audio_path(audio_path=AUDIO_PATH, year: str = \"2024\"):\n",
    "    \"\"\"\n",
    "    audio_path: str\n",
    "        relative path to audio files\n",
    "    will add year as subdirectory\n",
    "    return full audio path and create dir if it doesn t exist\n",
    "    \"\"\"\n",
    "\n",
    "    def get_git_root(path):\n",
    "        git_repo = Repo(path, search_parent_directories=True)\n",
    "        return git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    project_root = get_git_root(os.getcwd())\n",
    "    full_audio_path = os.path.join(project_root, audio_path, year)\n",
    "\n",
    "    # create dir if it doesn t exist\n",
    "    if not os.path.exists(full_audio_path):\n",
    "        os.makedirs(full_audio_path)\n",
    "\n",
    "    return full_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from bson import ObjectId\n",
    "from mongo import get_collection, get_DB_VARS, mongolog\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S.%f%z\"\n",
    "LOG_DATE_FORMAT = \"%d %b %Y %H:%M\"\n",
    "\n",
    "\n",
    "class Episode:\n",
    "    def __init__(self, date: str, titre: str, collection_name: str = \"episodes\"):\n",
    "        \"\"\"\n",
    "        Episode is a class that represents a generic Episode entity in the database.\n",
    "        :param date: The date for this episode at the format \"2024-12-22T09:59:39.000+00:00\" parsed by \"%Y-%m-%dT%H:%M:%S.%f%z\".\n",
    "        :param titre: The title of this episode.\n",
    "        :param collection_name: The name of the collection. default: \"episodes\".\n",
    "        \"\"\"\n",
    "        DB_HOST, DB_NAME, _ = get_DB_VARS()\n",
    "        self.collection = get_collection(\n",
    "            target_db=DB_HOST, client_name=DB_NAME, collection_name=collection_name\n",
    "        )\n",
    "        self.date = Episode.get_date_from_string(date)\n",
    "        self.titre = titre\n",
    "        self.description = None\n",
    "        self.url_telechargement = None\n",
    "        self.audio_rel_filename = None\n",
    "        self.transcription = None\n",
    "        self.type = None\n",
    "        self.duree = -1  # in seconds\n",
    "\n",
    "    def exists(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the episode exists in the database.\n",
    "        :return: True if the episode exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n",
    "            is not None\n",
    "        )\n",
    "\n",
    "    def keep(self) -> int:\n",
    "        \"\"\"\n",
    "        download the audio file if needed\n",
    "        Keep the episode in the database\n",
    "\n",
    "        retourne 1 si 1 entree est creee en base\n",
    "        0 sinon\n",
    "        \"\"\"\n",
    "        message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n",
    "        if not self.exists():\n",
    "            print(\n",
    "                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} nouveau: Duree: {self.duree}, Type: {self.type}\"\n",
    "            )\n",
    "            mongolog(\"insert\", self.collection.name, message_log)\n",
    "            self.download_audio(verbose=True)\n",
    "            self.collection.insert_one(\n",
    "                {\n",
    "                    \"titre\": self.titre,\n",
    "                    \"date\": self.date,\n",
    "                    \"description\": self.description,\n",
    "                    \"url\": self.url_telechargement,\n",
    "                    \"audio_rel_filename\": self.audio_rel_filename,\n",
    "                    \"transcription\": self.transcription,\n",
    "                    \"type\": self.type,\n",
    "                    \"duree\": self.duree,\n",
    "                }\n",
    "            )\n",
    "            return 1\n",
    "        else:\n",
    "            print(\n",
    "                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} deja existant\"\n",
    "            )\n",
    "            mongolog(\"update\", self.collection.name, message_log)\n",
    "            return 0\n",
    "\n",
    "    def remove(self):\n",
    "        \"\"\"\n",
    "        Remove the episode from the database.\n",
    "        \"\"\"\n",
    "        message_log = f\"{Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} - {self.titre}\"\n",
    "        self.collection.delete_one({\"titre\": self.titre, \"date\": self.date})\n",
    "        mongolog(\"delete\", self.collection.name, message_log)\n",
    "\n",
    "    def get_oid(self) -> ObjectId:\n",
    "        \"\"\"\n",
    "        Get the object id of the episode.\n",
    "        :return: The object id of the episode. (bson.ObjectId)\n",
    "        None if does not exist.\n",
    "        \"\"\"\n",
    "        document = self.collection.find_one({\"titre\": self.titre, \"date\": self.date})\n",
    "        if document:\n",
    "            return document[\"_id\"]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_date_from_string(date: str) -> datetime:\n",
    "        \"\"\"\n",
    "        Get the datetime object from a string.\n",
    "        :param date: The date string.\n",
    "        :return: The datetime object.\n",
    "        \"\"\"\n",
    "        return datetime.strptime(date, DATE_FORMAT)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_string_from_date(date: datetime, format: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Get the string from a datetime object.\n",
    "        :param date: The datetime object.\n",
    "        :param format: The format of the string. default: None and DATE_FORMAT will be used.\n",
    "        :return: The date string.\n",
    "        \"\"\"\n",
    "        if format is not None:\n",
    "            return date.strftime(format)\n",
    "        else:\n",
    "            return date.strftime(DATE_FORMAT)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "        Date: {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)}\n",
    "        Titre: {self.titre}\n",
    "        Description: {self.description}\n",
    "        URL de téléchargement: {self.url_telechargement}\n",
    "        Fichier audio: {self.audio_rel_filename}\n",
    "        Duree: {self.duree} en secondes \n",
    "        \"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def download_audio(self, verbose=False):\n",
    "        \"\"\"\n",
    "        based on url_telechargement\n",
    "        will download audio file and store in AUDIO_PATH/year\n",
    "        \"\"\"\n",
    "        if self.url_telechargement is None:\n",
    "            return\n",
    "        year = str(self.date.year)\n",
    "        full_audio_path = get_audio_path(AUDIO_PATH, year)\n",
    "        full_filename = os.path.join(\n",
    "            full_audio_path, os.path.basename(self.url_telechargement)\n",
    "        )\n",
    "        self.audio_rel_filename = os.path.relpath(\n",
    "            full_filename, get_audio_path(AUDIO_PATH, year=\"\")\n",
    "        )\n",
    "        # Vérification si le fichier existe déjà\n",
    "        if not os.path.exists(full_filename):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Téléchargement de {self.url_telechargement} vers {full_filename}\"\n",
    "                )\n",
    "            response = requests.get(self.url_telechargement)\n",
    "            with open(full_filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Le fichier {full_filename} existe déjà. Ignoré.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from feedparser.util import FeedParserDict\n",
    "from transformers import pipeline\n",
    "\n",
    "RSS_DUREE_MINI_MINUTES = 15\n",
    "RSS_DATE_FORMAT = \"%a, %d %b %Y %H:%M:%S %z\"  # \"Sun, 29 Dec 2024 10:59:39 +0100\"\n",
    "\n",
    "\n",
    "class RSS_episode(Episode):\n",
    "    def __init__(self, date: str, titre: str):\n",
    "        \"\"\"\n",
    "        RSS_episode is a class that represents an RSS episode in the database episodes.\n",
    "        :param date: The date for this episode at the format \"2024-12-22T09:59:39.000+00:00\" parsed by \"%Y-%m-%dT%H:%M:%S.%f%z\".\n",
    "        :param titre: The title of this episode.\n",
    "        \"\"\"\n",
    "        super().__init__(date, titre)\n",
    "\n",
    "    @classmethod\n",
    "    def from_feed_entry(cls, feed_entry: FeedParserDict) -> \"RSS_episode\":\n",
    "        \"\"\"\n",
    "        Create an RSS episode from a feed entry.\n",
    "        :param feed_entry: The feed entry.\n",
    "        :return: The RSS episode.\n",
    "        \"\"\"\n",
    "\n",
    "        date_rss = datetime.strptime(feed_entry.published, RSS_DATE_FORMAT)\n",
    "        date_rss_str = cls.get_string_from_date(date_rss, DATE_FORMAT)\n",
    "        inst = cls(\n",
    "            date=date_rss_str,\n",
    "            titre=feed_entry.title,\n",
    "        )\n",
    "        inst.description = feed_entry.summary\n",
    "\n",
    "        for link in feed_entry.links:\n",
    "            if link.type == \"audio/mpeg\":\n",
    "                inst.url_telechargement = link.href\n",
    "                break\n",
    "\n",
    "        # self.audio_rel_filename = None\n",
    "        # self.transcription = None\n",
    "        inst.type = cls.set_titre(inst.titre + \" \" + inst.description)\n",
    "        inst.duree = cls.get_duree_in_seconds(feed_entry.itunes_duration)  # in seconds\n",
    "\n",
    "        return inst\n",
    "\n",
    "    @staticmethod\n",
    "    def get_duree_in_seconds(duree: str) -> int:\n",
    "        \"\"\"\n",
    "        Get the duration in seconds from a string.\n",
    "        :param duree: The duration string at the format \"HH:MM:SS\" or \"HH:MM\".\n",
    "        :return: The duration in seconds.\n",
    "        \"\"\"\n",
    "        duree = duree.split(\":\")\n",
    "        if len(duree) == 3:\n",
    "            return int(duree[0]) * 3600 + int(duree[1]) * 60 + int(duree[2])\n",
    "        elif len(duree) == 2:\n",
    "            return int(duree[0]) * 60 + int(duree[1])\n",
    "        else:\n",
    "            return int(duree[0])\n",
    "\n",
    "    def keep(self) -> int:\n",
    "        \"\"\"\n",
    "        Keep the episode in the database.\n",
    "        only if duration > RSS_DUREE_MINI_MINUTES * 60\n",
    "        only if type == livres\n",
    "\n",
    "        retourne 1 si 1 entree est creee en base\n",
    "        0 sinon\n",
    "        \"\"\"\n",
    "        if (self.duree > RSS_DUREE_MINI_MINUTES * 60) & (self.type == \"livres\"):\n",
    "            return super().keep()\n",
    "        else:\n",
    "            print(\n",
    "                f\"Episode du {Episode.get_string_from_date(self.date, format=LOG_DATE_FORMAT)} ignored: Duree: {self.duree}, Type: {self.type}\"\n",
    "            )\n",
    "            return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def set_titre(description: str) -> str:\n",
    "        \"\"\"\n",
    "        use bart meta model from huggingface to classify episodes from\n",
    "        [\"livres\", \"films\", \"pièces de théâtre\"]\n",
    "        \"\"\"\n",
    "        # Charger le pipeline de classification de texte\n",
    "        classifier = pipeline(\n",
    "            \"zero-shot-classification\", model=\"facebook/bart-large-mnli\"\n",
    "        )\n",
    "        # Labels possibles\n",
    "        labels = [\"livres\", \"films\", \"pièces de théâtre\"]\n",
    "\n",
    "        result = classifier(description, labels)\n",
    "        return result[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est-ce que l episode existe ? False\n",
      "Episode du 14 Jan 2025 18:45 nouveau: Duree: 4000, Type: livres\n",
      "et maintenant, st-ce que rss1 existe ? True\n",
      "et voici l'id de rss1 : 6786a2c1f4481d81a88185e4\n",
      "après nettoyage, est-ce que rss1 existe ? False\n",
      "et son oid : None\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "now = datetime.now(tz=pytz.timezone(\"Europe/Paris\"))\n",
    "\n",
    "rss1 = RSS_episode(RSS_episode.get_string_from_date(now), \"test RSS 1\")\n",
    "print(f\"Est-ce que l episode existe ? {rss1.exists()}\")\n",
    "\n",
    "rss1.duree = 4000\n",
    "rss1.type = \"livres\"\n",
    "rss1.keep()\n",
    "print(f\"et maintenant, st-ce que rss1 existe ? {rss1.exists()}\")\n",
    "print(f\"et voici l'id de rss1 : {rss1.get_oid()}\")\n",
    "\n",
    "rss1.remove()\n",
    "print(f\"après nettoyage, est-ce que rss1 existe ? {rss1.exists()}\")\n",
    "print(f\"et son oid : {rss1.get_oid()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        Date: 12 Jan 2025 10:59\n",
       "        Titre: Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...\n",
       "        Description: durée : 00:48:41 - Le Masque et la Plume - par : Rebecca Manzoni - Un passé nazi qui refait surface ; une cité magique abrite un amour perdu ; un cinéaste entre un tournage en Afrique et la chute d'un homme nu ; un danseur offre à son fils adoptif la quête d'un héritage familial mouvementé ; un jeune père se confronte à son propre passé douloureux. - invités : Raphaelle Leyris, Hubert ARTUS, Jean-Marc Proust, Elisabeth Philippe - Raphaëlle Leyris : Journaliste au Monde, critique littéraire, Hubert Artus : Journaliste et chroniqueur littéraire, Jean-Marc Proust : Auteur et critique (Slate), Elisabeth Philippe : Critique littéraire (L'Obs) - réalisé par : Guillaume Girault\n",
       "        URL de téléchargement: https://rf.proxycast.org/ad97aa2e-ebfc-4d00-8739-4ca72192e726/14007-12.01.2025-ITEMA_23993269-2025F4007S0012-22.mp3\n",
       "        Fichier audio: None\n",
       "        Duree: 2921 en secondes \n",
       "        "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "from rss import get_RSS_URL\n",
    "\n",
    "parsed_flow = feedparser.parse(get_RSS_URL())\n",
    "\n",
    "rss2 = RSS_episode.from_feed_entry(parsed_flow.entries[0])\n",
    "rss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode du 12 Jan 2025 10:59 deja existant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss2.keep()\n",
    "rss2.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rss2.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6786a2c6f4481d81a88185e9'), 'operation': 'update', 'entite': 'episodes', 'desc': '12 Jan 2025 10:59 - Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...', 'date': datetime.datetime(2025, 1, 14, 18, 45, 42, 384000)}\n",
      "{'_id': ObjectId('6786a2c1f4481d81a88185e6'), 'operation': 'delete', 'entite': 'episodes', 'desc': '14 Jan 2025 18:45 - test RSS 1', 'date': datetime.datetime(2025, 1, 14, 18, 45, 37, 158000)}\n",
      "{'_id': ObjectId('6786a2c1f4481d81a88185e3'), 'operation': 'insert', 'entite': 'episodes', 'desc': '14 Jan 2025 18:45 - test RSS 1', 'date': datetime.datetime(2025, 1, 14, 18, 45, 37, 145000)}\n",
      "{'_id': ObjectId('6786a219ff4d877f74aaf512'), 'operation': 'update', 'entite': 'episodes', 'desc': '22 Dec 2024 10:59 - Les nouvelles pages de Marc Dugain, Emmanuelle Lambert, Emil Ferris, Fabrice Caro et Mathieu Palain', 'date': datetime.datetime(2025, 1, 14, 18, 42, 49, 496000)}\n",
      "{'_id': ObjectId('6786a210ff4d877f74aaf50c'), 'operation': 'insert', 'entite': 'episodes', 'desc': '12 Jan 2025 10:59 - Les nouvelles pages de Vanessa Springora, Haruki Murakami, Jean Echenoz, Amanda Sthers...', 'date': datetime.datetime(2025, 1, 14, 18, 42, 40, 679000)}\n"
     ]
    }
   ],
   "source": [
    "print_logs(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export\n",
    "\n",
    "nb_export(\"py mongo helper episodes.ipynb\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
