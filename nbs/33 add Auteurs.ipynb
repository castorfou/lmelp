{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "je vais manipuler des noms d'auteurs que je vais extraire d'une transcription. la transcription a ete cree a partir d'un enregistrement audio donc le risque est d'avoir des erreurs dans l'orthographe de cet auteur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for Author Name Handling System\n",
    "- Create a class to handle author names with fuzzy matching\n",
    "- Store reference names in a dictionary/database\n",
    "- Implement fuzzy string matching using Levenshtein distance\n",
    "- Add methods to suggest corrections for misspelled names\n",
    "- Include confidence scoring for matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Viktor Hugo\n",
      "Best match: Victor Hugo (score: 91)\n",
      "\n",
      "Suggestions:\n",
      "- Victor Hugo (score: 91)\n",
      "- Simone de Beauvoir (score: 34)\n",
      "- Émile Zola (score: 20)\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self, reference_authors: List[str] = None):\n",
    "        \"\"\"Initialize with a list of known author names\"\"\"\n",
    "        self.reference_authors = set(reference_authors) if reference_authors else set()\n",
    "\n",
    "    def add_reference_author(self, author: str) -> None:\n",
    "        \"\"\"Add a new reference author to the set\"\"\"\n",
    "        self.reference_authors.add(author.strip())\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Find the best matching reference author for a given name\n",
    "        Returns: (best_match, score)\n",
    "        \"\"\"\n",
    "        if not name or not self.reference_authors:\n",
    "            return None, 0\n",
    "\n",
    "        # Find best match using token set ratio for better partial matching\n",
    "        best_match, score = process.extractOne(\n",
    "            name, self.reference_authors, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        if not name or not self.reference_authors:\n",
    "            return []\n",
    "\n",
    "        # Get top N matches with scores\n",
    "        matches = process.extract(\n",
    "            name, self.reference_authors, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with some reference authors\n",
    "    reference_authors = [\n",
    "        \"Victor Hugo\",\n",
    "        \"Albert Camus\",\n",
    "        \"Simone de Beauvoir\",\n",
    "        \"Marcel Proust\",\n",
    "        \"Émile Zola\",\n",
    "    ]\n",
    "\n",
    "    matcher = AuthorMatcher(reference_authors)\n",
    "\n",
    "    # Test with a misspelled name\n",
    "    test_name = \"Viktor Hugo\"\n",
    "    best_match, score = matcher.find_best_match(test_name)\n",
    "    print(f\"Input: {test_name}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "\n",
    "    # Get suggestions\n",
    "    suggestions = matcher.suggest_corrections(test_name)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pas mal mais l'inconvenient c'est qu'il faut les auteurs de reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avec un llm pour obtenir la liste d'auteurs de reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import get_gemini_llm\n",
    "\n",
    "llm = get_gemini_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, it's ab\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate_content(\"Explain how AI works\")\n",
    "print(response.text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Viktor Hugo\n",
      "Best match: Victor Hugo (score: 91)\n",
      "\n",
      "Suggestions:\n",
      "- Victor Hugo (score: 91)\n",
      "- Victor Segalen (score: 56)\n",
      "- Siri Hustvedt (score: 42)\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_gemini_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self, cache_file: str = \"french_authors_cache.json\"):\n",
    "        \"\"\"Initialize with gemini client and cache\"\"\"\n",
    "        self.client = get_gemini_llm()\n",
    "        self.cache_file = Path(cache_file)\n",
    "        self.reference_authors = self._load_or_fetch_authors()\n",
    "\n",
    "    def _load_or_fetch_authors(self) -> List[str]:\n",
    "        \"\"\"Load authors from cache or fetch from OpenAI\"\"\"\n",
    "        if self.cache_file.exists():\n",
    "            with open(self.cache_file, \"r\") as f:\n",
    "                return json.load(f)\n",
    "\n",
    "        # Fetch from OpenAI if cache doesn't exist\n",
    "        prompt = \"\"\"\n",
    "        You are a literary expert assistant.\n",
    "\n",
    "        Give me a list of 100 important French authors, including contemporary ones, \n",
    "        that might be discussed in \"Le Masque et la Plume\". \n",
    "        Return only a JSON array of names, no other text.\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.client.generate_content(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        # complete avec la logique de cache\n",
    "        with open(self.cache_file, \"w\") as f:\n",
    "            json.dump(authors, f)\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference author\"\"\"\n",
    "        if not name:\n",
    "            return None, 0\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            name, self.reference_authors, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        return process.extract(\n",
    "            name, self.reference_authors, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "\n",
    "def test_auteur(autor):\n",
    "    matcher = AuthorMatcher()\n",
    "    best_match, score = matcher.find_best_match(autor)\n",
    "    print(f\"Input: {autor}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "    suggestions = matcher.suggest_corrections(autor)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")\n",
    "\n",
    "\n",
    "test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le probleme c'est que si j'utilise un auteur moins connu qui n'est pas dans les 100 ca ne va pas marcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Frederic Beigbeder\n",
      "Best match: None (score: 45)\n",
      "\n",
      "Suggestions:\n",
      "- Georges Perec (score: 45)\n",
      "- Simone de Beauvoir (score: 44)\n",
      "- Pierre Corneille (score: 41)\n"
     ]
    }
   ],
   "source": [
    "test_auteur(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et avec des accents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Gael Faye\n",
      "Best match: Gaël Faye (score: 94)\n",
      "\n",
      "Suggestions:\n",
      "- Gaël Faye (score: 94)\n",
      "- Gustave Flaubert (score: 56)\n",
      "- Françoise Sagan (score: 52)\n"
     ]
    }
   ],
   "source": [
    "test_auteur(\"Gael Faye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca ca marche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avec un llm pour retourner les auteurs dont le nom ressemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Viktor Hugo\n",
      "Best match: Victor Hugo (score: 91)\n",
      "\n",
      "Suggestions:\n",
      "- Victor Hugo (score: 91)\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_gemini_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorMatcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with gemini client\"\"\"\n",
    "        self.client = get_gemini_llm()\n",
    "\n",
    "    def _fetch_author(self, autor) -> List[str]:\n",
    "        \"\"\"fetch from gemini\"\"\"\n",
    "\n",
    "        # Fetch from gemini\n",
    "        prompt = (\n",
    "            \"\"\"\n",
    "        Tu es un agent expert en littérature.\n",
    "        Donne moi quelques auteurs dont le nom s'approche de celui-ci : \"\"\"\n",
    "            + autor\n",
    "            + \"\"\"\n",
    "\n",
    "        S'il s'agit deja d'un auteur connu, retourne moi juste son nom. S'il y a une erreur dans le nom que je t'ai donne, corrige moi en me donnant le nom de l'auteur que tu penses que j'ai voulu dire.\n",
    "\n",
    "        Je veux que tu me donnes le prenom puis le nom dans cet ordre. Par exemple \"Marcel Pagnol\" ou \"Victor Hugo\".\n",
    "        Ces auteurs sont susceptibles d'etre discutes dans \"Le Masque et la Plume\".\n",
    "\n",
    "        Si tu me retournes plusieurs auteurs, fais le sous forme de liste par exemple si tu as identifie \"auteur 1\" et \"auteur 2\" alors retourne [\"auteur 1\", \"auteur 2\"]\n",
    "\n",
    "        Retourne uniquement un tableau JSON de noms, pas de texte supplémentaire.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        response = self.client.generate_content(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, name: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference author\"\"\"\n",
    "        if not name:\n",
    "            return None, 0\n",
    "\n",
    "        fetch_author = self._fetch_author(name)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return None, 0\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            name, fetch_author, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def suggest_corrections(self, name: str, limit: int = 3) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Suggest possible corrections for a name\"\"\"\n",
    "        fetch_author = self._fetch_author(name)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return []\n",
    "        return process.extract(\n",
    "            name, fetch_author, limit=limit, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "\n",
    "def test_auteur(autor):\n",
    "    matcher = AuthorMatcher()\n",
    "    best_match, score = matcher.find_best_match(autor)\n",
    "    print(f\"Input: {autor}\")\n",
    "    print(f\"Best match: {best_match} (score: {score})\")\n",
    "    suggestions = matcher.suggest_corrections(autor)\n",
    "    print(\"\\nSuggestions:\")\n",
    "    for name, score in suggestions:\n",
    "        print(f\"- {name} (score: {score})\")\n",
    "\n",
    "\n",
    "test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Frederic Beigbeder\n",
      "Best match: Frédéric Beigbeder (score: 94)\n",
      "\n",
      "Suggestions:\n",
      "- Frédéric Beigbeder (score: 94)\n"
     ]
    }
   ],
   "source": [
    "test_auteur(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "est-ce que ca marche avec des auteurs recents ? premiers romans ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Jeanne Rivière\n",
      "Best match: None (score: 55)\n",
      "\n",
      "Suggestions:\n"
     ]
    }
   ],
   "source": [
    "test_auteur(\"Jeanne Rivière\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeanne Hersch']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = AuthorMatcher()\n",
    "matcher._fetch_author(\"Jeanne Rivière\")\n",
    "# matcher._fetch_author(\"Frederic Beigbeder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ca ne marche pas du tout avec les auteurs recents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# en fournissant la description de l'episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on va tester avec l'episode du 26 janvier 2025 \n",
    "\n",
    "et \"Jeanne Rivière\" qui vient d'ecrire son 1er roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mongo_episode import Episode\n",
    "import datetime\n",
    "\n",
    "episode_26janv2025 = Episode.from_date(datetime.date(2025, 1, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"durée : 00:47:56 - Le Masque et la Plume - par : Rebecca Manzoni - Une saga familiale à travers trois générations de femmes, entre le Maroc et la France\\xa0; une histoire d'amour et une réflexion sur la judéité\\xa0; un roman filial et d'espionnage dans la Guerre Froide\\xa0; amitié, désir, musique punk sans les années 90 ; littérature et amour en Sardaigne. - invités : Arnaud Viviant, Laurent CHALUMEAU, Patricia Martin, Elisabeth Philippe - Arnaud Viviant : Critique littéraire (Revue Regards), Laurent Chalumeau : Journaliste rock, scénariste, dialoguiste, romancier, Patricia Martin : Journaliste, critique littéraire et productrice chez France Inter, Elisabeth Philippe : Critique littéraire (L'Obs) - réalisé par : Guillaume Girault\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_26janv2025.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from llm import get_gemini_llm\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class AuthorEpisodeMatcher:\n",
    "    def __init__(self, episode: Episode):\n",
    "        \"\"\"un agent qui va verifier les auteurs d'un episode\n",
    "        episode : episode qui contient notamment un titre et une description\n",
    "        \"\"\"\n",
    "        self.client = get_gemini_llm()\n",
    "        self.episode = episode\n",
    "\n",
    "    def _potentiels_auteurs(self, auteur: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        on cherche avec llm une liste de potentiels auteurs qui pourraient correspondre à l'auteur donné\n",
    "        auteur : ce qu'on cherche\n",
    "\n",
    "        cette liste sera utilise par find_best_match pour trouver le meilleur match\n",
    "        \"\"\"\n",
    "\n",
    "        description = (\n",
    "            \" titre : \" + self.episode.titre\n",
    "        )  # + \" \\n description : \" + self.episode.description\n",
    "\n",
    "        # prompt pour llm\n",
    "        prompt = (\n",
    "            \"\"\"\n",
    "        Tu es un agent expert en littérature.\n",
    "\n",
    "        J'ai entendu parler d'un auteur evoque dans un episode du \"Masque et la Plume\" dont le nom ressemble à celui-ci : \"\"\"\n",
    "            + auteur\n",
    "            + \"\"\"\n",
    "\n",
    "        Je dis ressemble parce que j'ai entendu le nom à la radio et je ne suis pas sûr de l'orthographe exacte de son nom.\n",
    "\n",
    "        J'ai aussi le titre et lq description de cet episode du \"Masque et la Plume\" qui peuvent t'aider à trouver cet auteur. \n",
    "        Les voici : \"\"\"\n",
    "            + description\n",
    "            + \"\"\"\n",
    "\n",
    "        Il est possible que le nom apparaisse dans le titre ou la description, dans ce cas utilise le car ces sources sont plus fiables que le nom que je t'ai donne.\n",
    "        \n",
    "        Cependant il est possible que le nom n'y apparaisse pas, dans ce cas recherche dans ce que tu connais en tant qu'expert en littérature.\n",
    "        \n",
    "        S'il s'agit deja d'un auteur que tu connaissais, retourne moi juste son nom. S'il y a une erreur dans le nom que je t'ai donne, corrige moi en me donnant le nom de l'auteur que tu penses que j'ai voulu dire.\n",
    "\n",
    "        Je veux que tu me donnes le prenom puis le nom dans cet ordre. Par exemple \"Marcel Pagnol\" ou \"Victor Hugo\".\n",
    "\n",
    "        Si tu me retournes plusieurs auteurs car tu as des doutes, fais le sous forme de liste par exemple si tu as identifie \"auteur 1\" et \"auteur 2\" alors retourne [\"auteur 1\", \"auteur 2\"]\n",
    "\n",
    "        Retourne uniquement un tableau JSON de noms, pas de texte supplémentaire.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        response = self.client.generate_content(prompt)\n",
    "\n",
    "        try:\n",
    "            # Extract JSON from response text\n",
    "            # Remove any markdown formatting or extra text\n",
    "            response_text = response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text.split(\"```json\")[1]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text.split(\"```\")[0]\n",
    "\n",
    "            authors = json.loads(response_text.strip())\n",
    "\n",
    "            # Validate response format\n",
    "            if not isinstance(authors, list):\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "            if not all(isinstance(x, str) for x in authors):\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "                raise ValueError(\"Not all elements are strings\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            print(f\"Raw response: {response.text}\")\n",
    "            return []\n",
    "\n",
    "        return authors\n",
    "\n",
    "    def find_best_match(self, auteur: str, min_score: int = 80) -> Tuple[str, int]:\n",
    "        \"\"\"Find best matching reference auteur\n",
    "        en utilisant thefuzz process.extractOne\n",
    "\n",
    "        retourne None, 0 si aucun auteur n'est renseigné\n",
    "        retourne None, -1 si aucun auteur de reference n'est trouvé\n",
    "        retourne None, score si le score est inferieur à min_score\n",
    "\n",
    "        et sinon retourne le meilleur match et son score\n",
    "\n",
    "        Returns: (best_match, score)\n",
    "        \"\"\"\n",
    "        if not auteur:\n",
    "            return None, 0\n",
    "\n",
    "        fetch_author = self._potentiels_auteurs(auteur)\n",
    "\n",
    "        if not fetch_author:\n",
    "            return None, -1\n",
    "\n",
    "        best_match, score = process.extractOne(\n",
    "            auteur, fetch_author, scorer=fuzz.token_set_ratio\n",
    "        )\n",
    "\n",
    "        if score >= min_score:\n",
    "            return best_match, score\n",
    "        return None, score\n",
    "\n",
    "    def test_auteur(self, autor):\n",
    "        best_match, score = self.find_best_match(autor)\n",
    "        print(f\"Input: {autor}\")\n",
    "        print(f\"fetch autors : {self._potentiels_auteurs(autor)}\")\n",
    "        print(f\"Best match: {best_match} (score: {score})\")\n",
    "\n",
    "\n",
    "matcher_26janv2025 = AuthorEpisodeMatcher(episode_26janv2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Viktor Hugo\n",
      "fetch autors : ['Victor Hugo']\n",
      "Best match: Victor Hugo (score: 91)\n"
     ]
    }
   ],
   "source": [
    "matcher_26janv2025.test_auteur(\"Viktor Hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Jeanne Rivière\n",
      "fetch autors : ['Jeanne Rivière']\n",
      "Best match: Jeanne Rivière (score: 100)\n"
     ]
    }
   ],
   "source": [
    "matcher_26janv2025.test_auteur(\"Jeanne Rivière\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Jeanne Riviere\n",
      "fetch autors : ['Jeanne Rivière']\n",
      "Best match: Jeanne Rivière (score: 96)\n"
     ]
    }
   ],
   "source": [
    "matcher_26janv2025.test_auteur(\"Jeanne Riviere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c'est pas parfait c'est le cote un peu schostastique du llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essayons avec la transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = episode_26janv2025.transcription\n",
    "\n",
    "prompt_transcription = f\"\"\"\n",
    "\n",
    "Je vais te donner la transcription d'un episode d'une emission de radio qui s'appelle le masque et la plume sur France Inter.\n",
    "Cet episode dure 1h et porte sur des livres. Il y a des intervenants qui parlent des livres qu'ils ont lus. Ils ne sont parfois pas d'accord.\n",
    "\n",
    "Voici la transcription:\n",
    "{transcription}\n",
    "\n",
    "Je veux que tu identifies l'ensemble des livres dont on parle dans cette emission.\n",
    "Et que tu me restitues cette liste de livres en separant auteur et titre. Si l'editeur est mentionne tu peux aussi le noter.\n",
    "\n",
    "Tu me restitueras cette liste sous la forme d'un tableau au format markdown. Avec une colonne pour l'auteur, une colonne pour le titre et une colonne pour l'editeur si il est mentionne.\n",
    "\n",
    "Et tu me donneras une lsite au format python des auteurs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Voici le tableau markdown listant les livres mentionnés dans la transcription, avec auteur, titre et éditeur:\\n\\n| Auteur             | Titre                      | Éditeur          |\\n|----------------------|-----------------------------|-------------------|\\n| Haruki Murakami     | La Cité aux murs incertains |                  |\\n| Constantin Alexandrakis | L\\'Hospitalité au démon     |                  |\\n| Leila Slimani        | J\\'emporterai le feu        | Gallimard         |\\n| Nathalie Azoulay     | Toutes les vies de Théo     | POL               |\\n| Pierre Lemaitre      | Un avenir radieux           | Calmann Lévy      |\\n| Jeanne Rivière       | Lorraine Brulle             | Gallimard         |\\n| Milena Agus          | Le vent passe et la nuit aussi | Liana Lévy       |\\n| Christian Laval      | Marx en Amérique            | Chambon           |\\n| Guillaume Lebrun     | Ravagé de splendeur         | Bourgois          |\\n| Sally Rooney         | Normal People               | Livre de Poche    |\\n| Jean-Patrick Manchette | Ecrire contre               | Gallimard         |\\n\\n\\nEt voici la liste des auteurs au format Python:\\n\\n```python\\nauteurs = [\"Haruki Murakami\", \"Constantin Alexandrakis\", \"Leila Slimani\", \"Nathalie Azoulay\", \"Pierre Lemaitre\", \"Jeanne Rivière\", \"Milena Agus\", \"Christian Laval\", \"Guillaume Lebrun\", \"Sally Rooney\", \"Jean-Patrick Manchette\"]\\n```\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = get_gemini_llm()\n",
    "\n",
    "llm.generate_content(prompt_transcription).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Voici le tableau markdown listant les livres mentionnés dans l\\'émission, avec auteur, titre et éditeur :\\n\\n\n",
    "\n",
    "| Auteur             | Titre                         | Éditeur           |\n",
    "|----------------------|---------------------------------|--------------------|\n",
    "| Haruki Murakami     | La Cité aux murs incertains      |                    |\n",
    "| Constantin Alexandrakis | L\\'Hospitalité au démon         |                    |\n",
    "| Leila Slimani        | J\\'emporterai le feu            | Gallimard          |\n",
    "| Nathalie Azoulay     | Toutes les vies de Théo        | POL                |\n",
    "| Johann Svar          | (Titre non spécifié)            |                    |\n",
    "| Pierre Lemaitre     | Un avenir radieux              | Calmann Lévy       |\n",
    "| Jeanne Rivière       | Lorraine Brulle                | Gallimard (collection Signe) |\n",
    "| Milena Agus          | Le vent passe et la nuit aussi | Liana Lévy         |\n",
    "| Christian Laval      | Marx en Amérique               | Chambon             |\n",
    "| Guillaume Lebrun     | Ravagé de splendeur            | Bourgois           |\n",
    "| Sally Rooney         | Normal People                  | Livre de Poche     |\n",
    "| Jean-Patrick Manchette | (Titre non spécifié, biographie)| Gallimard          |\n",
    "| Bob Dylan            | (Titre non spécifié, biographie)|                    |\n",
    "\n",
    "\n",
    "Voici la liste des auteurs au format Python\n",
    "\n",
    "```python\n",
    "auteurs = [\"Haruki Murakami\", \"Constantin Alexandrakis\", \"Leila Slimani\", \"Nathalie Azoulay\", \"Johann Svar\", \"Pierre Lemaitre\", \"Jeanne Rivière\", \"Milena Agus\", \"Christian Laval\", \"Guillaume Lebrun\", \"Sally Rooney\", \"Jean-Patrick Manchette\", \"Bob Dylan\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Haruki Murakami\n",
      "fetch autors : ['Haruki Murakami']\n",
      "Best match: Haruki Murakami (score: 100)\n",
      "Input: Constantin Alexandrakis\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m auteurs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaruki Murakami\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstantin Alexandrakis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeila Slimani\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNathalie Azoulay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJohann Svar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPierre Lemaitre\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJeanne Rivière\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMilena Agus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChristian Laval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuillaume Lebrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSally Rooney\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJean-Patrick Manchette\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBob Dylan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m auteur \u001b[38;5;129;01min\u001b[39;00m auteurs:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmatcher_26janv2025\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_auteur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauteur\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 111\u001b[0m, in \u001b[0;36mAuthorEpisodeMatcher.test_auteur\u001b[0;34m(self, autor)\u001b[0m\n\u001b[1;32m    109\u001b[0m best_match, score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_best_match(autor)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch autors : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_potentiels_auteurs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_match\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[48], line 51\u001b[0m, in \u001b[0;36mAuthorEpisodeMatcher._potentiels_auteurs\u001b[0;34m(self, auteur)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# prompt pour llm \u001b[39;00m\n\u001b[1;32m     28\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124mTu es un agent expert en littérature.\u001b[39m\n\u001b[1;32m     30\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124mRetourne uniquement un tableau JSON de noms, pas de texte supplémentaire.\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 51\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Extract JSON from response text\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Remove any markdown formatting or extra text\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/whisper/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "auteurs = [\n",
    "    \"Haruki Murakami\",\n",
    "    \"Constantin Alexandrakis\",\n",
    "    \"Leila Slimani\",\n",
    "    \"Nathalie Azoulay\",\n",
    "    \"Johann Svar\",\n",
    "    \"Pierre Lemaitre\",\n",
    "    \"Jeanne Rivière\",\n",
    "    \"Milena Agus\",\n",
    "    \"Christian Laval\",\n",
    "    \"Guillaume Lebrun\",\n",
    "    \"Sally Rooney\",\n",
    "    \"Jean-Patrick Manchette\",\n",
    "    \"Bob Dylan\",\n",
    "]\n",
    "\n",
    "for auteur in auteurs:\n",
    "    matcher_26janv2025.test_auteur(auteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
