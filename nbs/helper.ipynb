{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "def get_gemini_api_key():\n",
    "    load_env()\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    return gemini_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_key = get_gemini_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "def get_gemini_llm(model=\"gemini-1.5-flash\"):\n",
    "    genai.configure(api_key=get_gemini_api_key())\n",
    "    llm = genai.GenerativeModel(model)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI works by mimicking human intelligence processes through machines, particularly computer systems. \n"
     ]
    }
   ],
   "source": [
    "llm = get_gemini_llm()\n",
    "response = llm.generate_content(\"Explain how AI works\")\n",
    "print(response.text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get gemini llamaindex llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "def get_gemini_llamaindex_llm(model=\"models/gemini-1.5-flash\"):\n",
    "    genai.configure(api_key=get_gemini_api_key())\n",
    "    llm = Gemini(model=model, api_key=get_gemini_api_key())\n",
    "    Settings.llm = llm\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A backpack worn, of woven thread,\n",
      "Not leather tough, nor canvas spread,\n",
      "But shimmering silk, a mystic hue,\n",
      "With silver clasp, and starlight dew.\n",
      "\n",
      "Within its depths, a world untold,\n",
      "Of wonders bright, and stories old.\n",
      "A compass spins, to guide the way,\n",
      "Through tangled paths, where shadows play.\n",
      "\n",
      "A flask of air, for mountain high,\n",
      "A sunbeam warm, when skies are nigh.\n",
      "A feather light, to ease the climb,\n",
      "A whispered word, to conquer time.\n",
      "\n",
      "A map unfolds, of lands unseen,\n",
      "Where dragons soar, and faeries glean.\n",
      "A tiny seed, a giant tree,\n",
      "A whispered wish, for you and me.\n",
      "\n",
      "But heed the warning, softly spun,\n",
      "This magic bag, for one is won.\n",
      "Its power vast, its secrets deep,\n",
      "A treasure held, while secrets sleep.\n",
      "\n",
      "So carry it well, with careful hand,\n",
      "Across the lands, across the sand.\n",
      "For in this pack, a magic lies,\n",
      "Reflected bright, in your own eyes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = get_gemini_llamaindex_llm()\n",
    "resp = llm.complete(\"Write a poem about a magic backpack\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export\n",
    "\n",
    "nb_export(\"helper.ipynb\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
