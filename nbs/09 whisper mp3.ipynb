{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "AUDIO_PATH = \"audios\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list mp3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from mongo_episode import get_audio_path\n",
    "import os, glob\n",
    "\n",
    "\n",
    "def list_mp3_files(audio_path=AUDIO_PATH):\n",
    "    fullpath = get_audio_path(audio_path, year=\"\")\n",
    "\n",
    "    return glob.glob(os.path.join(fullpath, \"**/*.mp3\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/f279814/git/lmelp/audios/2016/14007-13.11.2016-ITEMA_21134385-0.mp3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_mp3_files()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def extract_whisper(mp3_filename):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "    generate_kwargs = {\n",
    "        \"language\": \"french\",\n",
    "    }\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "        chunk_length_s=30,\n",
    "        batch_size=16,  # batch size for inference - set based on your device\n",
    "        generate_kwargs=generate_kwargs,\n",
    "    )\n",
    "\n",
    "    dataset = load_dataset(\n",
    "        \"distil-whisper/librispeech_long\", \"clean\", split=\"validation\"\n",
    "    )\n",
    "    sample = dataset[0][\"audio\"]\n",
    "\n",
    "    result = pipe(\n",
    "        mp3_filename,\n",
    "        return_timestamps=True,\n",
    "    )\n",
    "\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/guillaume/miniconda/envs/whisper/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed language=french, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=french.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Musique Le masque et la plume Musique Bonsoir à tous, bienvenue en public au studio Sacha Guitry de la maison de Radio France pour un masqué la plume'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3_1 = list_mp3_files()[0]\n",
    "\n",
    "whisper = extract_whisper(mp3_1)\n",
    "\n",
    "whisper[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store whisper in db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "from bson import ObjectId\n",
    "\n",
    "\n",
    "def store_whisper_in_db(whisper, collection, oid, force=False, verbose=False):\n",
    "    \"\"\"\n",
    "    whisper: str, la transcription du fichier audio\n",
    "    collection: pymongo collection\n",
    "    oid: str, l'identifiant de l episode\n",
    "    force: bool, si True, on ecrase le whisper existant\n",
    "\n",
    "    return True si le whisper a ete stocke, False sinon\n",
    "    \"\"\"\n",
    "\n",
    "    # Récupération du document\n",
    "    document_entry = collection.find_one({\"_id\": ObjectId(oid)})\n",
    "\n",
    "    if document_entry is None:\n",
    "        if verbose:\n",
    "            print(f\"Document avec l'oid {oid} non trouvé\")\n",
    "        return False\n",
    "\n",
    "    if \"whisper\" in document_entry and not force:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Whisper déjà stocké pour l'oid {oid}m et on ne force pas le stockage\"\n",
    "            )\n",
    "        return False\n",
    "    else:\n",
    "        document_entry[\"whisper\"] = whisper\n",
    "        collection.update_one({\"_id\": ObjectId(oid)}, {\"$set\": document_entry})\n",
    "        if verbose:\n",
    "            print(f\"Whisper stocké pour l'oid {oid}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper stocké pour l'oid 6773e32258fc5717f3516b98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from connection import get_collection\n",
    "\n",
    "col = get_collection()\n",
    "oid = \"6773e32258fc5717f3516b98\"\n",
    "store_whisper_in_db(\"test whisper\", col, oid, force=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export\n",
    "\n",
    "nb_export(\"09 whisper mp3.ipynb\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
