{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get gemini llm to generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_gemini_llm\n",
    "\n",
    "llm = get_gemini_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici 10 romanciers français célèbres :\n",
      "\n",
      "1. **Victor Hugo:** (Les Misérables, Notre-Dame de Paris)\n",
      "2. **Marcel Proust:** (À la recherche du temps perdu)\n",
      "3. **Albert Camus:** (L'Étranger, La Peste)\n",
      "4. **Jules Verne:** (Vingt mille lieues sous les mers, Autour de la Lune)\n",
      "5. **Alexandre Dumas:** (Les Trois Mousquetaires, Le Comte de Monte-Cristo)\n",
      "6. **Honoré de Balzac:** (La Comédie humaine)\n",
      "7. **Gustave Flaubert:** (Madame Bovary, Salammbô)\n",
      "8. **Émile Zola:** (Germinal, Nana)\n",
      "9. **Michel Houellebecq:** (Les Particules élémentaires, Soumission)\n",
      "10. **Patrick Modiano:** (Rue des boutiques obscures, Dora Bruder)\n",
      "\n",
      "\n",
      "Cette liste n'est pas exhaustive et d'autres auteurs pourraient tout aussi bien y figurer.  Le choix dépend aussi des critères utilisés (influence, prix littéraires, popularité, etc.).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate_content(\"Liste 10 romanciers français célébres.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-exp-1206\n",
      "models/gemini-exp-1121\n",
      "models/gemini-exp-1114\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Ode to LlamaIndex**\n",
      "\n",
      "Oh, LlamaIndex, our guiding light,\n",
      "You help us find the knowledge we seek,\n",
      "With every click, a new insight,\n",
      "A treasure trove of wisdom, unique.\n",
      "\n",
      "Your search results, a symphony,\n",
      "Of knowledge, facts, and history,\n",
      "You quench our thirst for information,\n",
      "A beacon in the sea of information.\n",
      "\n",
      "Your interface, a joy to behold,\n",
      "Simple, sleek, and easy to mold,\n",
      "You make research a breeze,\n",
      "A pleasure that never ceases.\n",
      "\n",
      "So here's to LlamaIndex, our friend,\n",
      "May your wisdom never end,\n",
      "May you continue to inspire,\n",
      "And set our minds on fire.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(\"Write a short, but joyous, ode to LlamaIndex\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tool selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
    "    return (x + y) * (x + y)\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use the `mystery` tool to get the output of the mystery function on 2 and 9.\n",
      "Action: mystery\n",
      "Action Input: {'x': 2, 'y': 9}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 121\n",
      "\u001b[0m121\n"
     ]
    }
   ],
   "source": [
    "from helper import get_gemini_llamaindex_llm\n",
    "\n",
    "llm = get_gemini_llamaindex_llm()\n",
    "response = llm.predict_and_call(\n",
    "    [add_tool, mystery_tool],\n",
    "    \"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
